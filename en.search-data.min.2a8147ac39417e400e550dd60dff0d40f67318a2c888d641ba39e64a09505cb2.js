'use strict';(function(){const t={cache:!0};t.doc={id:"id",field:["title","content"],store:["title","href","section"]};const e=FlexSearch.create("balance",t);window.bookSearchIndex=e,e.add({id:0,href:"/docs/",title:"User Documentation",section:"Packit",content:"Documentation #   About - Key principles of Packit. Onboarding Guide - How to start using Packit. Testing Farm - Guide to Packit\u0026rsquo;s service for running tests. Frequently Asked Questions - Whys, Whats, contacts. Source-git - Source-git concept and how to work with it. Configuration for packit - Configuration file description. Packit CLI - Commands description. Actions - Further customize Packit\u0026rsquo;s behaviour. Generated code in upstream archives - When your release tarballs contain generated code and you need to patch it downstream.  "}),e.add({id:1,href:"/docs/configuration/examples/",title:"Examples",section:"Configuration",content:"Configuration examples #  Examples for actions #  You can find detailed documentation for actions here.\nGetting version #  Getting version from specfile get-current-version:  - grep -oP \u0026#39;^Version:\\s+\\K\\S+\u0026#39; my-package.spec or with a command from rpm-build package that will honor the macros:\nget-current-version:  - rpmspec -q --queryformat \u0026#34;%{VERSION}\\n\u0026#34; *spec |head -n1    Getting version for Python packages with setup.py get-current-version:  - python3 setup.py --version    Getting version for Ruby packages from the gemspec get-current-version:  - ruby -rrubygems -e \u0026#39;puts Gem::Specification::load(Dir.glob(\u0026#34;*.gemspec\u0026#34;).first).version\u0026#39;    Manipulating spec file #  Downloading specfile from the dist-git repo post-upstream-clone:  - \u0026#34;wget https://src.fedoraproject.org/rpms/my-package/raw/main/f/my-package.spec -O my-package.spec\u0026#34;    Setting the Sources correctly in case of multiple Sources fix-spec-file:  # define one of the Source variables correctly  - sed -i my_specfile_path -e \u0026#34;s/https.*only-vendor.tar.xz/my_correct_tarball_path/\u0026#34;  # fill in %release as if packit would have done it  - bash -c \u0026#34;sed -i my_specfile_path -r \\\u0026#34;s/Release:(\\s*)\\S+/Release:\\1${PACKIT_RPMSPEC_RELEASE}%{?dist}/\\\u0026#34;\u0026#34;    Custom archive creation #  Creating archive with custom make target create-archive:  - make release  - bash -c \u0026#34;ls -1t ./my-package-*.tar.gz | head -n 1\u0026#34;    Creating archive for Python packages with setup.py create-archive:  - python3 setup.py sdist --dist-dir .  - bash -c \u0026#34;ls -1t ./my-package-*.tar.gz | head -n 1\u0026#34;    Custom changelog generation #  Using changelog entry from a file changelog-entry:  - cat .changelog_entry    Examples for jobs #  You can find detailed documentation for jobs here.\nBuilds #  Running builds in Copr - job: copr_build  trigger: pull_request  targets:  - fedora-all    Running builds in custom Copr project Configuring building in Copr project @oamg/convert2rhel:\n- job: copr_build  trigger: commit  branch: main  owner: \u0026#34;@oamg\u0026#34;  project: convert2rhel  targets:  - epel-6-x86_64  - epel-7-x86_64  - epel-8-x86_64    Running more types of builds in Copr jobs: - job: copr_build  trigger: pull_request  identifier: fedora  targets:  - fedora-all  - job: copr_build   trigger: pull_request  specfile_path: epel8/python-specfile.spec  identifier: epel8  actions:  create-archive:  - python3 setup.py sdist --dist-dir ./epel8/  - bash -c \u0026#34;ls -1t ./epel8/*.tar.gz | head -n 1\u0026#34;  targets:  - epel-8    Running builds in Koji - job: upstream_koji_build  trigger: pull_request  targets:  - fedora-all    Tests #  Running tests in Testing Farm - job: tests  trigger: pull_request  targets:  - fedora-all    Running tests in internal Testing Farm instance Please, let us know if you want to use the internal Testing Farm; we have to enable it for you.\n- job: tests  targets:  centos-stream-9-x86_64:  distros: [RHEL-9.3.0-Nightly]  use_internal_tf: True    Running only tests (without builds) - job: tests  targets:  - fedora-all  skip_build: True    Defining mapping between build and test targets - job: tests  targets:  epel-7-x86_64:  distros: [centos-7, oraclelinux-7]  epel-8-x86_64:  distros: [centos-8, oraclelinux-8]    Specifying where the FMF metadata are placed (other than default) - job: tests  trigger: pull_request  targets:  - fedora-all  fmf_url: \u0026#34;https://gitlab.cee.redhat.com/baseos-qe/tmt.git\u0026#34;  fmf_ref: main    Running more types of tests jobs: - job: tests  trigger: pull_request  targets:  - fedora-all  - job: tests  trigger: pull_request  identifier: \u0026#34;internal-tests\u0026#34;  targets:  - fedora-all  use_internal_tf: True    Providing custom tmt context - job: tests  trigger: pull_request  targets:  - fedora-all  tf_extra_params:  environments:  - tmt:  context:  how: \u0026#34;full\u0026#34;    Fedora release automation #  Creating dist-git pull requests on upstream releases - job: propose_downstream  trigger: release  dist_git_branches:  - fedora-all    Creating dist-git pull requests on upstream releases defined in the dist-git repository upstream_project_url: https://github.com/packit/packit ... jobs: - job: pull_from_upstream  trigger: release  dist_git_branches:  - fedora-all    Running Koji builds when the Packit pull requests in dist-git are merged - job: koji_build  trigger: commit  dist_git_branches:  - fedora-all    Running Koji builds as a reaction to merging PRs or committing in dist-git by specified users - job: koji_build  trigger: commit  dist_git_branches:  - fedora-all  allowed_pr_authors:  - packit  - the-fas-username-to-allow  allowed_committers:  - packit  - another-fas-username-to-allow    Creating Bodhi updates automatically for successful Koji builds - job: bodhi_update  trigger: commit  dist_git_branches:  - fedora-branched # rawhide updates are created automatically    Get inspired #  You can also look directly into configuration files of some other projects using Packit:\n Systemd Anaconda Ogr Convert2rhel Cockpit project Tmt Osbuild Leapp repository  "}),e.add({id:2,href:"/docs/about/",title:"About Packit",section:"User Documentation",content:"About Packit #  The key principles of packit #    Packit aims to make things easy and right. But if the default behavior is not the right for you, there is still a way around, but may not be that simple. For example you can use actions to replace packit\u0026rsquo;s default behavior with a script of yours.\n  Reuse existing tools and services where it makes sense: don\u0026rsquo;t reinvent the wheel.\n  You can consume packit in two forms:\n Packit tool can run on your laptop, and you run commands you want. Packit service reacts to events and performs actions which you defined in your packit.yaml.    We don\u0026rsquo;t break backward compatibility just like that.\n  Packit has a deprecation policy:\n We can mark a behaviour as deprecated. Deprecated content can be removed or changed after at least 3 minor releases. Deprecated content is advertised in our changelog, printed in the terminal or tracked in your issue tracker.    We care about artifacts which Fedora supports: at the moment it\u0026rsquo;s RPMs, modules and container images.\n Our initial focus is solely on RPMs.    Packit respects Fedora guidelines.\n  We want the latest content in Fedora Rawhide, but only if it works (the new content can be built and tests are passing).\n  Any task done by the automation system must be able to be performed by a human when that is required. Packit service must be capable of recovering from such situation.\n  Packit developers must be able to iterate on all parts packit (testing a change, merging a change, deploying to production) at a pace of at least every two weeks. To accomplish this, the release and validation processes are completely automated.\n  All tests are passing in CI systems for the main branches for all our projects. No excuses.\n  Contributions to packit must be possible by any developer, maintainer, tester, or other engineer. Any Fedora developer or tester should be able to reproduce a bot locally on their machine, given appropriate credentials.\n  Why packit? #    Our intent is to bring downstream and upstream communities closer: provide feedback from downstream to upstream. (e.g. \u0026ldquo;Hello \u0026lt;upstream project Y\u0026gt;, your newest release doesn\u0026rsquo;t work in Fedora Rawhide, it breaks \u0026lt;Z\u0026gt;, here is a link to logs.\u0026rdquo;)\n  We want to only merge, build and compose components which integrate well with the rest of the operating system. The biggest impact of such behavior will be on Fedora Rawhide and when working on a new Fedora release.\n  Automatically pull and validate new upstream releases. This can be a trivial thing to do, why should maintainers waste their times on work which can be automated.\n  Developing in dist-git is cumbersome. Editing patch files and moving tarballs around is not fun. Why not work with the source code itself? With source-git, you\u0026rsquo;ll have upstream git history and the dist-git content combined in a single repository.\n  Let\u0026rsquo;s use modern development techniques such as pull requests, code review, modern git forges, automation and continuous integration. We have computers to do all the mundane tasks. Why should we, as humans, do such work?\n  We want dist-git to be \u0026ldquo;a database of content in a release\u0026rdquo; rather a place to do actual work. On the other hand, you\u0026rsquo;ll still be able to interact with dist-git the same way. We are not taking that away. Source-git is meant to be the modern, better alternative.\n  DevConf.cz \u0026ldquo;Auto-maintain your package\u0026rdquo; talk.\n"}),e.add({id:3,href:"/source-git/design/",title:"Source-git design",section:"Source-git",content:"Source-git design #  This document serves as a detailed description of source-git. Please bear in mind that some things are a subject to change. Paragraphs marked with \u0026ldquo;‼️💣️\u0026rdquo; are known to require further work to be better defined.\nWhat is source-git? #  Source-git is a repository format and the related processes, tooling and bots, that are intended to enable using forks of the upstream projects to maintain, update and build packages in a distribution. By \u0026ldquo;distribution\u0026rdquo; we mean distributions in the RHEL ecosystem (Fedora Linux, CentOS Stream and RHEL), but the tools and processes probably could be applied to any RPM based distribution.\nMotivation #  Traditionally dist-git is the format used to maintain, develop and release software in these distributions. In dist-git the source archive of an upstream release is stored in the lookaside cache, while downstream (distribution specific) changes are checked-in as patch files in Git. This layout resembles SRPMs, and so it\u0026rsquo;s easily consumed by build systems, but it makes it somewhat difficult for humans to make sense of the content. Additionally, transforming upstream content (which most of the time originates from a Git repo) to dist-git has become a tedious activity, with a plethora of tooling available to do very similar things.\nThe dist-git format also has the side effect of making the adoption of modern Git-workflows somewhat more difficult (reviewing changes in patch-files requires a higher cognitive effort) and raising the bar for new contributors, who know how to contribute using Git, but need to learn about dist-git before touching any package.\nWith source-git the goal is to:\n Enable using these well-known Git-workflows in packaging activities. Automate and standardize the tedious task of converting from one repository format to the other.  If you think about it, \u0026ldquo;source-git\u0026rdquo; is really just good old plain \u0026ldquo;Git\u0026rdquo;, used as it meant to be used by Linus.\nPremises #  One of the fundamentally useless manual activities when maintaining a package in Fedora is transforming source code from one Git repository format to another. Git is distributed. Dist-git content is mostly boilerplate or regurgitated data.\nUsing an upstream format during packaging makes collaboration easier, and lowers the entry barrier for new contributors by enabling a development workflow which they are already familiar with.\nLinux distributions gain an advantage from having patches incorporated upstream and not carrying them downstream.\nHuman effort should not be focused on repetitive, automatable tasks related to churn and moving code around.\nDist-git is used as a store of state for build tools (like Koji). Reinventing dist-git itself fundamentally, would mean reinventing a lot of tooling.\nAn addon to dist-git #  We recognize, that an extensive ecosystem of tooling and services was developed to work with dist-git, and because of this replacing dist-git in the immediate future is not feasible. On the long run though, once source-git proved itself, this can become possible.\nThis is why we think about source-git as an addon to dist-git.\nContent of source-git repository is equivalent to dist-git, but uses upstream format: source files instead of tarballs, Git commits instead of patches.\nBots are responsible to transform and maintain content in dist-git, so that humans can do all the work in source-git. If bots fail, humans can still step in and do the work. Bots and humans use the same tools to do the transformation.\nAll tooling already in place that interacts with dist-git continues to interact with dist-git. Bots are responsible to bring CI results from dist-git to source-git for convenience.\nThis means that using source-git to maintain a package adds an overhead compared to directly working in dist-git. Though on the positive side, enables packagers and contributors to use a Git workflow they are already familiar with from upstream projects.\nSource-git might not be a solution for many packages at the early stages, and might not be a solution at all for some packages. This is why, source-git is opt-in, and can be opted out at any point in time if so decided.\nRepository location #  Source-git repositories are hosted and shared in a Git forge chosen by the distribution. This helps the community developing the distribution to be in control of these repositories.\nTeams of developers maintaining packages in multiple distributions can choose to have a single repository at a location of their choice, have dedicated branches for each distribution, and sync these branches to the source-git repositories of each distribution.\nLayout #  A source-git repository is based on a fork of the upstream project.\nThe files required to create the package for the distribution are stored in the .distro directory.\nThis includes:\n the spec file, other files required to be present in dist-git (test files, scripts used in building the package, package configuration etc.), a source-git.yaml file to configure how the content of the repo should be transformed to dist-git.  History and branching #  By default, branching in source-git mirrors branching in dist-git. In a source-git context, let\u0026rsquo;s call these branches \u0026ldquo;downstream branches\u0026rdquo;.\nDownstream branches share their history with the upstream release they are based upon, and contain additional commits to add the .distro directory and its content, and to introduce downstream changes to the upstream source code.\nWhen transforming content to dist-git, tooling\n prepares and uploads the source archive to dist-git\u0026rsquo;s lookaside cache; generates patch files for downstream changes, if any, and updates the spec file accordingly (changes to .distro are filtered out); updates other files in dist-git with the content of .distro (except source-git.yaml).  The way patch files are generated and included in the spec file is controlled by Git-trailers in the commit messages of downstream commits.\nConfiguration #  .distro/source-git.yaml tells tooling how to interact with the source-git repo, including:\n where to pull upstream changes from; how the content of the source-git repo should be transformed to dist-git;  how to generate or get the source archive to be uploaded to the lookaside cache; how to generate patches from downstream commits;   the dist-git repo and branch tracked.  The configuration format is based on the Packit configuration.\nPlacing this configuration file in a branch in source-git indicates that the source-git branch should be auto-maintained. The configuration file may be removed to turn off auto-maintenance of the branch.\nFor an example see Configure syncing to distgit.\n‼️💣️ Content from a source-git repository can be committed to a dist-git repository only if the target dist-git branch makes a reference to the source-git repo and branch from which the update originates.\n TODO: have an explicit documentation of source-git.yaml.\n Workflows #  Contribution to source-git happens through pull requests (aka. merge requests).\nBots create mirror PRs in dist-git for each source-git PR opened, and make CI results of those mirror PRs available in source-git.\n‼️💣️ Changes merged in source-git are synced to dist-git.\nUpdates created in dist-git are synced back to source-git via pull requests opened by bots. This functionality serves to accommodate changes done by provenpackagers across multiple repositories.\nCommits need to be signed in order to be transformed to dist-git.\nBots sign the commits they create.\n TODO: Rebase or merge?\n "}),e.add({id:4,href:"/development-docs/creating-stream-9-repos/",title:"Creating CentOS Stream 9 source-git repositories",section:"Development Documentation",content:"Creating CentOS Stream 9 source-git repositories #  Source-git repos for CentOS Stream 9 are stored as separate repositories in https://gitlab.com/redhat/centos-stream/src in c9s branches.\nHere is how the repositories should be set up:\n  They are open to the public (for contributions).\n  Issues are disabled (BZ is the official bug tracker).\n  Merge requests are enabled.\n  Description is set:\nSource repo for CentOS Stream package $package. You can contribute here by following https://wiki.centos.org/Contribute/CentOSStream/   c9s branch is protected, though force-pushes are allowed from maintainers (for sake of rebasing).\n  How to create such repo #  using packit source-git init\nPushing the repository to GitLab #  We have an identity, centos-stream-packit, which has permissions to create new repositories in the namespace.\nHere comes a sample script utilizing ogr and python-gitlab to create a new repo to satisfy the requirements above:\nimport ogr import os TARGET_GROUP = \u0026#34;redhat/centos-stream/src\u0026#34; GITLAB_TOKEN = os.getenv(\u0026#34;GITLAB_TOKEN\u0026#34;) gitlab_service = ogr.GitlabService(GITLAB_TOKEN) target_group = gitlab_service.gitlab_instance.groups.get(TARGET_GROUP) repo_name = \u0026#34;edk2\u0026#34; project = gitlab_service.gitlab_instance.projects.create({ \u0026#34;name\u0026#34;: repo_name, \u0026#34;namespace_id\u0026#34;: target_group.id, \u0026#34;description\u0026#34;: ( f\u0026#34;Source repo for CentOS Stream package \\\u0026#34;{repo_name}\\\u0026#34;. \u0026#34; \u0026#34;You can contribute here by following https://wiki.centos.org/Contribute/CentOSStream/\u0026#34; ), \u0026#34;issues_enabled\u0026#34;: False, \u0026#34;visibility\u0026#34;: \u0026#34;public\u0026#34;, }) project.protectedbranches.create( {\u0026#34;name\u0026#34;: \u0026#34;c9s\u0026#34;, \u0026#34;push_access_level\u0026#34;: \u0026#34;40\u0026#34;, \u0026#34;merge_access_level\u0026#34;: \u0026#34;40\u0026#34;} ) "}),e.add({id:5,href:"/docs/cli/source-git/init/",title:"init",section:"source-git",content:"packit source-git init #  Initialize a repository to serve as a source-git repo.\nThe biggest advantage of this command is the functionality to create source-git repos. Here\u0026rsquo;s a quick rundown what packit does:\n Fetches specfile and additional sources from Fedora or CentOS dist-git. Apply downstream patches as commits. Add source-git configuration to control future syncing to dist-git.  We have a guide on how to create source-git repos manually if you want to understand the steps performed.\nPrerequisites #   A clone of the upstream repo with checked out branch which matches the base ref. The git ref of the upstream repo used as a base. A clean dist-git repository.  Tutorial #  As an example, let\u0026rsquo;s create a source-git repo out of systemd. The project uses a dedicated repository to provide backports for actively maintained stable releases.\nFirst step is to clone the respective dist-git repo (we\u0026rsquo;ll use Fedora Rawhide in our case):\n$ cd $FEDORA_DIST_GIT_REPOS $ fedpkg clone systemd $ cd systemd  We should now determine the version in the specfile\n$ rpmspec -q --qf \u0026quot;%{version}\u0026quot; ./systemd.spec 249.4  Since systemd-stable prefixes the backport releases with v, we know that we want to base our source-git repo on the v249.4 tag:\n$ cd $FEDORA_SOURCE_GIT_REPOS $ git clone https://github.com/systemd/systemd-stable $ cd systemd-stable $ git checkout 'v249.4'  All the prereqs should be met now! We have the upstream clone with the proper tag checked out and the respective dist-git repo. We can now run the source-git init command:\n$ packit source-git init v249.4 $FEDORA_SOURCE_GIT_REPOS/systemd-stable $FEDORA_DIST_GIT_REPOS/systemd  Once the command finishes successfully, your source-git repo is available for you at $FEDORA_SOURCE_GIT_REPOS/systemd-stable. Please head on to a section in this documentation which covers working with source-git repos.\nBy default, using %autosetup in the %prep section of the specfile is required. You can use --ignore-missing-autosetup option to enforce running the command without using %autosetup, but Packit then cannot guarantee that the patches will be properly applied. Therefore, please make sure that running %prep produces a git repository with patches applied on top when using this option. It will be the base of your source-git repository.\nHelp #  $ packit source-git init --help Usage: packit source-git init [OPTIONS] UPSTREAM_REF SOURCE_GIT DIST_GIT Initialize SOURCE_GIT as a source-git repo by applying downstream patches from DIST_GIT as Git commits on top of UPSTREAM_REF. SOURCE_GIT needs to be an existing clone of the upstream repository. UPSTREAM_REF is a tag, branch or commit from SOURCE_GIT. SOURCE_GIT and DIST_GIT are paths to the source-git and dist-git repos. Branch names can be specified, separated by colons. If a branch name is specified for SOURCE_GIT, the branch is checked out and reset to UPSTREAM_REF. If a branch name is specified for DIST_GIT, the branch is checked out before setting up the source-git repo. This branch is expected to exist. Each Git commit created in SOURCE_GIT will have a 'From-dist-git-commit' trailer to mark the hash of the dist-git commit from which it is created. To learn more about source-git, please check https://packit.dev/docs/source-git/ Examples: $ packit source-git init v2.3.1 src/acl:rawhide rpms/acl:rawhide $ packit source-git init --pkg-tool centpkg v2.3.1 src/acl rpms/acl Options: --upstream-url TEXT Git URL of the upstream repository. It is saved in the source-git configuration if it is specified. --upstream-remote TEXT Name of the remote pointing to the upstream repository. If --upstream-url is not specified, the fetch URL of this remote is saved in the source-git configuration as the Git URL of the upstream project. Defaults to 'origin'. --pkg-tool TEXT Name or path of the packaging tool used to work with sources in the dist-git repo. A variant of 'rpkg'. Defaults to 'fedpkg' or the tool configured in the Packit configuration. --pkg-name TEXT The name of the package in the distro. Defaults to the directory name of DIST_GIT. --ignore-missing-autosetup Do not require %autosetup macro to be used in %prep section of specfile. By default, %autosetup is required. -h, --help Show this message and exit.  "}),e.add({id:6,href:"/source-git/",title:"Source-git",section:"Packit",content:"Source-git documentation #  Source-git is an addon on top of dist-git, and aims to provide an alternative to maintain packages using an upstream format.\nMany packages are already maintained like this (ex: kernel, systemd), and teams created their own workflows and tooling to support their specific use case. This makes adapting the workflow by other packages challenging.\nOur goal is to create an implementation which is configurable, easy to start with, and to provide both command-line tooling and the related bots to help to adopt and use the workflow.\n Before you continue reading, we assume you are familiar with the Fedora Maintenance Guide.\n Source-git is a Git repository which contains upstream sources and downstream-specific files: for packaging and code changes specific to a distribution, in our case Fedora Linux, CentOS Stream and Red Hat Enterprise Linux.\nFor more info continue with:\n Source-git design Working with source-git  "}),e.add({id:7,href:"/docs/guide/",title:"Packit Onboarding Guide",section:"User Documentation",content:"Packit Onboarding Guide #  Let\u0026rsquo;s take a look on how to start using Packit and how to get the most out of it.\nThis guide is focused on the service use-case, but Packit is also available as a CLI tool, so you can always try things locally on your own. Note that running tests in Testing farm infrastructure is not currently supported with the CLI tool. Unlike the service, CLI uses your own identities when connecting to other service like Copr or Fedora dist-git. Packit CLI is NOT a client of the Packit GitHub app, packit command directly interacts with the services.\nTo start using Packit, you need to do three things:\n set up integration (so Packit is notified about your activities and can provide feedback) be approved (self-done mapping of your forge identity to FAS identity, so we know who you are) configure the wanted features  1. Set up Packit integration #  The integration is dependent on the service the upstream project is hosted on. In case you want to use Packit on your downstream repository for downstream jobs (Koji build and Bodhi update), you don\u0026rsquo;t need to enable anything. Just place your config file into the dist-git repository.\nHere are the supported git-forges:\nGitHub #  The majority of Packit users host their projects on GitHub, therefore we focus mainly on supporting the GitHub App. All of our workflows are supported and tested on GitHub. We utilize the majority of new GitHub features that can be used in GitHub Apps.\nHow to set up Packit on GitHub #   Navigate to the \u0026ldquo;Packit-as-a-Service\u0026rdquo; GitHub application.  Under \u0026ldquo;Pricing and setup\u0026rdquo;, click \u0026ldquo;Install it for free\u0026rdquo;.  Click \u0026ldquo;Complete order and begin installation\u0026rdquo;.  Install the \u0026ldquo;Packit-as-a-Service\u0026rdquo; to repositories of your choice.   Once installed, you will see the \u0026ldquo;Packit-as-a-Service\u0026rdquo; GitHub application in your project settings. In the left sidebar, click \u0026ldquo;Integration \u0026amp; services\u0026rdquo; and you will see the application displayed there.\nStaging instance #  Packit-as-a-Service-stg GitHub App runs the latest code. It can be used to verify the latest changes until they get (every Tuesday) into the production instance. If you want to enjoy the freshest features and help us with the development, see more details here.\nGitLab #  GitLab support is mainly experimental and is influenced by the presence of CentOS Stream source-git workflow. We do not verify the functionality of the GitLab support on a day-to-day basis as we do with the GitHub App. Most of the code is forge-independent so you can use the very same functionality both on GitHub and GitLab. The only difference is the setup and small UI differences because of the limits of the specific forge. You can use Packit on any GitLab instance, if:\n The GitLab instance is publically available. Packit has an identity for that instance. (Currently only gitlab.com, gitlab.freedesktop.org and gitlab.gnome.org, but let us know if you need any other instance to be supported.)  How to set up Packit on GitLab #  GitLab doesn\u0026rsquo;t have an app functionality, and we don\u0026rsquo;t use the Integrations as it doesn\u0026rsquo;t solve authentication. To enable Packit, you need to manually configure a webhook.\n Go to Settings → Webhooks and add https://prod.packit.dev/api/webhooks/gitlab or https://stg.packit.dev/api/webhooks/gitlab as the URL.  Select Push events, Comments, Issues events, Merge request events and Release events as the Triggers. Do not provide Secret token yet and click Add webhook. You should see the created hook at the bottom of the page now.  Select Test and for example Push event. At the top of the page appears a red Hook executed successfully but returned HTTP 401 \u0026quot;X-Gitlab-Token not in request.headers\u0026quot;. Wait a bit and check Issues of the project and after a while there should be a new confidential Packit-Service Authentication issue with the instructions how to finish the setup. (You need to give Packit user maintainer permissions to the project and attach a provided token to the webhooks.)  GitLab Pipelines #  With some limitations (but tweakability) you can also use Packit as a GitLab pipeline using the Packit\u0026rsquo;s CLI from the regularly built quay.io/packit/packit image. As you can see in the following example, it\u0026rsquo;s really straightforward and explicit:\nimage: quay.io/packit/packit  srpm_build:  stage: build  script:  - packit srpm  artifacts:  paths:  - \u0026#34;*.src.rpm\u0026#34;  expire_in: 1 week Pagure #  We have rudimentary support for the Pagure instances since they are used in the downstream workflow. Packit cannot be set up as a CI (in the same sense as on GitHub or GitLab) on Pagure instances, since the demand for this feature is not significant. The differences between GitHub/GitLab and Pagure APIs would result in many workarounds having to be implemented, if it would be possible at all. You can track the progress in the related issue on GitHub.\n2. Approval #  As a next step, you need to have a valid Fedora Account System account to be able to start using Packit Service in an upstream project. For GitHub, we have an automated way of self-approval, for other instances, contact us, and we will approve you manually. We require our new users to have GitHub Username field set in the FAS account so that we can automatically check for the match between the GitHub Username field in the FAS account and the GitHub account that triggers the verification. (If you don\u0026rsquo;t know, where to set this value, the URL looks like this: https://accounts.fedoraproject.org/user/\u0026lt;my-fas-username\u0026gt;/settings/profile/#github.)\nDuring the installation, we try to check the FAS account with the same username as the GitHub account that triggers the installation and if the check fails, we create a new issue in our allowlist tracker. (You will be tagged in that issue and should get a GitHub notification about that.)\nYou can provide the FAS account in a comment as /packit verify-fas \u0026lt;my-fas-username\u0026gt; in the issue we create for your installation. This will trigger the automatic check. Until that, you will get a neutral status with Namespace is not allowed! message on your commits.\nBesides that:\n If you want to configure builds via Packit, your software needs to comply with Copr guidelines since we use Fedora Copr for the builds. Therefore, please, make sure you read them before configuring the Packit build job. If you are interested in using internal instance of the Testing Farm to run your tests in, please, reach out to us, since for this job, an additional approval on our side is needed. For retrying the build and test jobs via /packit build and /packit test pull request comments, you need to have write access to the repository or be the author of the pull request. Similarly, for retrying the propose downstream job via /packit propose-downstream issue comment, you need to have write access to the repository.  3. Configuration #  Packit uses a configuration file to let Packit know what to do, when to do it and how. As a format, it uses YAML and here are all the valid names:\n .packit.yaml .packit.yml packit.yaml packit.yml  And where do you need to place this config file? Whenever you need to use Packit \u0026ndash; the concept is easy: Packit loads the config file from the repository and commit related to the event it reacts to. E.g. if Packit reacts to a pull request, it takes config from the HEAD commit of the pull request, if Packit works with releases, the release commit is used and if Packit works with downstream Koji build, the respective dist-git commit is used.\nYou know how to call this file, where to put it, but what should you fill inside?\nIn the following parts, we will cover some basic concepts used in the Packit config file. More details can be found on a dedicated configuration page.\nBasic configuration #  You need to provide some basic information to let Packit understand your project and package. You can use packit init command (when running Packit locally) to get a basic structure. It will look like this (name of the package is guessed from the directory name):\n# See the documentation for more information: # https://packit.dev/docs/configuration/  specfile_path: package.spec  # add or remove files that should be synced files_to_sync:  - package.spec  - .packit.yaml  # name in upstream package repository/registry (e.g. in PyPI) upstream_package_name: package # downstream (Fedora) RPM package name downstream_package_name: package We know that every project is a bit different and Packit can\u0026rsquo;t guess everything so you can (re)define various other options. The full list can be found here.\nVersion handling #  There are a few version-related config options you might need to set:\n upstream_tag_template: Specifies a format of upstream tags if it doesn\u0026rsquo;t contain just a version. get-current-version action: Command to get a project version in the current state of the project. release_suffix: Used to influence release field of artifacts provided by Packit. update_release: Whether to modify release when creating SRPM.  Jobs #  Packit\u0026rsquo;s feature set is really wide and does not need to be used as a whole pipeline. To let user decide what and when should run, Packit uses concept of so-called jobs. Each job represents a feature of Packit. All the jobs are defined under the jobs key. For each job you need to specify the following information:\n job: the type of the job, the feature you want Packit to do. trigger: when the job is run (pull_request, commit or release). additional information needed for the job (like what targets to build, for what branch to run the job,\u0026hellip;)  (Note that for each job, not all the triggers are supported.)\nAs an example you can take a look at the following config snippet (these are also the default jobs used if you don\u0026rsquo;t set the jobs key):\njobs: - job: copr_build  trigger: pull_request  targets: [fedora-stable]  - job: tests  trigger: pull_request  targets: [fedora-stable]  - job: propose_downstream  trigger: release  dist_git_branches:  - fedora-all Most of the attributes can be defined both on global level (outside the jobs key) or for a single job only (like e.g. targets in the snippet above). More about this overriding mechanism can be found here. Another useful feature are aliases used to avoid hardcoded values that changes when there is a new distribution release.\nAvailable jobs #   copr_build: An RPM build triggered for pull-requests, new branch commits or releases. (Can be used to verify that package is buildable, to easily install package including the proposed change or to provide long-term Copr repositories.) tests: Test suit using TMT/FMF definition run in the Testing Farm (Can be used as a next step to Copr build or without build at all.) upstream_koji_build: A scratch Koji build triggered for the upstream state of project. propose_downstream: For upstream release, Packit prepares a Fedora release. (Source is saved to the Lookaside Cache and a dist-git pull-request is created for each configured branch.) koji_build: A downstream Koji build triggered when there is a new dist-git commit in a given branch. bodhi_update: A Bodhi update created for a successfully finished Koji build.  More about the jobs and how to tweak them can be found on a configuration page.\nActions #  Actions are a way how to redefine or tweak the Packit\u0026rsquo;s workflows. These are user-defined commands that can replace a part of Packit\u0026rsquo;s job (e.g. to get version, or to create a tarball) or are run in a particular step as a hook (with no action run by default).\nTake a look at the tables here to know what actions are available for each job.\nUsers #  Packit checks if the user has sufficient permissions to complete a job (this depends on the job type). For this reason the profile of a Packit user has to be accessible. For example, on Github this means that the membership of a user to their team has to be public (see https://github.com/orgs/[org_name]/people/[user_name] ).\nHow to try that for real #  In order to start using Packit, we suggest you install the tooling locally. All the logic is baked inside the packit command - so once packit srpm (the command to create a source RPM locally from the current snapshot of the project) starts passing for you, it should work inside packit service as well.\nRPM builds pass on your laptop #  Packit needs an RPM spec file to build your package. The spec file does not need to be included in the upstream repo and can be generated on the fly or downloaded (e.g. from Fedora dist-git). Please check out our FAQ to read about some other common questions.\nYou can also read more about the SRPM process in the document dedicated to the srpm command.\nRunning from the dist-git repository #  When you are not allowed or do not want to run packit command from the upstream git repository, you can run commands from the cloned dist-git repository in the same way as you do from upstream. Make sure, that you specify the upstream_project_url in your configuration.\nIs your packit srpm finally passing? If not, feel free to reach out to us. If yes, let\u0026rsquo;s proceed to the next level.\nThe project has successful builds inside the service #  If a SRPM can be created locally, all should be good in the service as well. That\u0026rsquo;s the theory. In practice, your laptop and packit service environment are vastly different. In the service you can specify the requirements with the srpm_build_deps option. In any case, feel free to reach out to us if you are having troubles, and we\u0026rsquo;d be glad to help.\nAs described above, Packit supports various functions in form of jobs you can configure. Let\u0026rsquo;s try the most favourite one: Copr build. In order to get RPM builds for every change in your project, you need to add a section jobs inside your .packit.yaml and set up a copr_build job to do RPM builds for every change in a PR:\njobs: - job: copr_build  trigger: pull_request  targets:  - fedora-all fedora-all stands for all currently available Fedora releases.\nJobs are nicely described over here.\nIf you are looking for an inspiration for your .packit.yaml, check packit\u0026rsquo;s config file since we try to use all the latest features.\nCheck that Packit works #  With the configuration above, Packit will build your changes and provide them as RPMs. Once you create a pull request, Packit will:\n Check out the PR. Merge it to the target branch (this can be configured by the merge_pr_in_ci configuration option). Submit a build using the code that results from the merge in the Copr build system in Packit\u0026rsquo;s namespace. Report results about the Copr build status to the pull request.  An example of Packit\u0026rsquo;s checks in a pull request:\nHow to re-trigger Packit actions in your pull request? #  In general, you can put a /packit \u0026lt;job-you-want-to-trigger\u0026gt; comment to trigger the Packit job manually.\nSo for Copr builds, Packit is able to trigger new builds based on a pull request comment:\n/packit copr-build  or the shorter version\n/packit build  So whenever you run into a flake or feel like you want to retrigger, just type that comment into the PR and enjoy some fine, fresh builds.\nFor propose_downstream, you need to place that comment to any issue.\nThe requirements stated above apply, so if you see this message\nOnly users with write or admin permissions to the repository can trigger Packit-as-a-Service  it means the author of the pull request does not have write access to the repository so the build cannot be scheduled. This is a perfect case for maintainers of the repository to post /packit build in the PR to get a build.\nIn GitHub Checks interface, it is also possible to re-trigger a specific task just by clicking on Re-run for the particular check:\nOr it is possible to re-trigger every failed task using a pull request comment\n/packit rebuild-failed  which builds only failed builds and similar for testing farm\n/packit retest-failed  to re-trigger every failed test.\nPackit handles Fedora updates for you. #  So you already have a jobs section in your config. Let\u0026rsquo;s extend it with another jobs that will handle the Fedora updates: propose_downstream/pull_from_upstream, koji_build and bodhi_udpate. These are explained in detail in our release guide.\nAnd that\u0026rsquo;s about it. Now you should be able to use the core features of the Packit. If you have any questions, feel free to reach out to us.\nWe welcome all kinds of suggestions to this guide, feel free to open a new issue here.\n"}),e.add({id:8,href:"/development-docs/patch-metadata/",title:"Source-git patch metadata",section:"Development Documentation",content:"Source-git patch metadata #  Patch metadata have been superseded by Git-native trailers. This old patch metadata format is still supported if none of the Git-trailers are found in any of the commits.\nThe metadata are a way for users and creators of source-git repos to be in control of how packit generates patch files from downstream commits. Users are not meant to set most of these - our tooling does that: dist2src and packit source-git init.\nIdeally maintainers would just commit changes to source-git repos and have %autosetup to apply all the patches during %prep.\nExample of patch metadata in one of commits in systemd source-git for CentOS Stream 8:\n$ git log HEAD commit 38e6b5b3059410530e0d5287de595cbf4574988b (HEAD -\u0026gt; c8s, upstream/c8s) Author: Lennart Poettering \u0026lt;lennart@poettering.net\u0026gt; Date: Mon Feb 4 10:23:43 2019 +0100 pam-systemd: use secure_getenv() rather than getenv() And explain why in a comment. (cherry picked from commit 83d4ab55336ff8a0643c6aa627b31e351a24040a) CVE-2019-3842 Resolves: #1687514 patch_name: 0563-pam-systemd-use-secure_getenv-rather-than-getenv.patch present_in_specfile: true location_in_specfile: 563 diff --git a/src/login/pam_systemd.c b/src/login/pam_systemd.c ... You can see the patch metadata are stored in the commit message on the last 3 lines.\nMetadata #  The metadata are stored in commit messages and have a key-value format parsed as yaml. The list of keys follows.\npatch_name #  Type: str\nDefault: the default comes from git-format-patch: \u0026ldquo;By default, each output file is numbered sequentially from 1, and uses the first line of the commit message\u0026rdquo;\nContent: file name of the patch\nExample: \u0026ldquo;my-fancy.patch\u0026rdquo;\nPatch file generated from the commit will have this name. This is useful when a patch is already defined in the spec file and we need to make the patch file match that Patch spec file entry.\nIt is also used to merge multiple adjacent commits to a single patch file, by setting the same value for patch_name in their metadata.\ndescription #  Type: str\nDefault: empty string\nExample: \u0026ldquo;This patch is cherry-picked from upstream commit ea45faaa and resolves build failures on arm.\u0026rdquo;\nHuman-friendly description of the patch file to be put above the spec file entry.\npresent_in_specfile #  Type: bool\nDefault: false (the default behaviour does not expect the patch is defined in the spec)\nExample: false\nIs the patch present in spec? If yes, then don\u0026rsquo;t create a new entry in the spec file. If no, add it to the spec.\nignore #  Type: bool\nDefault: false\nExample: true\nSkip this git commit when processing patches. This is handy for commits which change files in source-git repos but are not in an archive or are not meant to be utilized in %prep.\nsquash_commits (deprecated) #  Type: bool\nDefault: false\nExample: false\nThis key is deprecated as of packit 0.35.0, and replaced by setting the same patch_name in the commit message of adjacent commits, which should end up in the same patch file.\nThis option is meant to be used to support git-am patch applications. git-am enables you to have multiple git commits for a single patch file. When creating source-git repos with packit source-git init, only the last commit of a patch would be annotated with metadata.\nExample:\n40c3a04 (HEAD -\u0026gt; main) patch 3, commit 3 ┃ this is a single patch file 61647c6 patch 3, commit 2 ┃ consisting of 3 commits 89e9eff patch 3, commit 1\\n\\nsquash_commits: true ┣━ because all leading commits are merged into the first patch 8afd939 patch 2, commit 1\\n\\nsquash_commits: true ┣━ a single commit patch 3a2cff0 patch 1, commit 2\\n\\nsquash_commits: true ┣━ commit 1 and commit 2 are part of the first patch b2b8e06 patch 1, commit 1 ┃ d689043 downstream packaging\\n\\nignore: true b677988 (tag: 0.1.0) upstream release 0.1.0 no_prefix #  Type: bool\nDefault: false\nExample: true\nDo not prepend leading a/ or b/ in the patch files. Use this when applying patches with %patch -p1.\nDropped metadata #  location_in_specfile #  This attribute meant to represent ID of the patch within a spec file but it never worked like that so we dropped it completely. The problem was that rpm does not provide such information when applying patches: it provides a number which is an unrelated internal iterator. We are planning to supersede location_in_specfile with patch_id: https://issues.redhat.com/browse/PACKIT-1376\n"}),e.add({id:9,href:"/docs/cli/source-git/status/",title:"status",section:"source-git",content:"packit source-git status #  Examine the sync status of a source-git and a dist-git repository.\nThis command informs whether the commits in source-git and dist-git are in sync or about the ranges of commit that need to be synchronized using update-source-git and update-dist-git commands in order to make them synced. If possible, the status command aims to provide instructions on how to sync the repositories.\nHelp #  $ packit source-git status --help Usage: packit source-git status [OPTIONS] SOURCE_GIT DIST_GIT Tell the synchronization status of a source-git and a dist-git repo. This command checks the commit history in the provided source-git and dist- git repos and informs about the range of commits to be synchronized from dist-git to source-git or the other way around, or informs that the repositories are in sync. If possible, the status command also provides instructions on how to synchronize the repositories. Options: -h, --help Show this message and exit.  "}),e.add({id:10,href:"/docs/cli/build/koji/",title:"in-koji",section:"build",content:"packit build in-koji #  Submit a Koji build for the selected branch in Fedora dist-git.\nRequirements #   Upstream git repository on GitHub. Packit config file placed in the upstream repository. Valid Fedora Kerberos ticket.  Tutorial #    Place a config file for packit in the root of your upstream repository.\n  The command below would perform fedpkg build in the Fedora dist-git main branch.\n$ cd my/ustream/project/ $ packit build in-koji   Help #  Usage: packit build in-koji [OPTIONS] [PATH_OR_URL] Build selected upstream project in Fedora. By default, packit checks out the respective dist-git repository and performs `fedpkg build` for the selected branch. With `--from-upstream`, packit creates a SRPM out of the current checkout and sends it to koji. PATH_OR_URL argument is a local path or a URL to the upstream git repository, it defaults to the current working directory Options: --dist-git-branch TEXT Comma separated list of target branches in dist- git to release into. (defaults to repo's default branch) --dist-git-path TEXT Path to dist-git repo to work in. Otherwise clone the repo in a temporary directory. --from-upstream Build the project in koji directly from the upstream repository --koji-target TEXT Koji target to build inside (see `koji list- targets`). --scratch Submit a scratch koji build --nowait Don't wait on build --release-suffix TEXT Specifies release suffix. Allows to override default generated:{current_time}.{sanitized_curren t_branch}{git_desc_suffix} --default-release-suffix Allows to use default, packit-generated, release suffix when some release_suffix is specified in the configuration. -h, --help Show this message and exit.  "}),e.add({id:11,href:"/docs/cli/init/",title:"init",section:"Packit CLI",content:"packit init #  Initiate a repository to start using packit. By default this command adds .packit.yaml config file to the git repository in the current working directory.\nIf a spec file is found in the git repository, init will set specfile_path to point to it in .packit.yaml. Otherwise, specfile_path is set to \u0026lt;the name of the repository\u0026gt;.spec.\nSee source-git init if you want to initialize a source-git repo.\nHelp #  $ packit init --help Usage: packit init [OPTIONS] [PATH_OR_URL] Create the initial Packit configuration in a repository See 'packit source-git init', if you want to initialize a repository as a source-git repo. Options: -f, --force Reset config to default if already exists. -h, --help Show this message and exit.  "}),e.add({id:12,href:"/docs/cli/source-git/update-dist-git/",title:"update-dist-git",section:"source-git",content:"packit source-git update-dist-git #  Transform the content from a source-git repository in a dist-git format, and update the corresponding dist-git repository.\nHelp #  $ packit source-git update-dist-git --help Usage: packit source-git update-dist-git [OPTIONS] SOURCE_GIT DIST_GIT Update a dist-git repository using content from a source-git repository Update a dist-git repository with patches created from the commits between \u0026lt;upstream_ref\u0026gt; and the current HEAD of the source-git repo. This command, by default, performs only local operations and uses the content of the source-git and dist-git repository as it is: does not checkout branches or fetches remotes. A commit in dist-git is created only if a commit message is provided with --message or --file. This commit will have a 'From-source-git-commit' Git- trailer appended to it, to mark the hash of the source-git commit from which it is created. The source archives are retrieved from the upstream URLs specified in the spec-file and uploaded to the lookaside cache in dist-git only if '--pkg- tool' is specified. Examples: To update a dist-git repo from source-git without uploading the source- archive to the lookaside cache and creating a commit with the updates, run: $ packit source-git update-dist-git src/curl rpms/curl To also commit the changes and upload the source-archive to the lookaside- cache specify -m and --pkg-tool: $ packit source-git update-dist-git -m'Update from source-git' \\ --pkg-tool fedpkg src/curl rpms/curl Options: --upstream-ref TEXT Git ref of the last upstream commit in the current branch from which packit should generate patches (this option implies the repository is source-git). --pkg-tool TEXT Name or path of the packaging tool used to work with sources in the dist-git repo. A variant of 'rpkg'. Skip retrieving and uploading source archives to the lookaside cache if not specified. -m, --message \u0026lt;msg\u0026gt; Commit the changes in the dist-git repository and use \u0026lt;msg\u0026gt; as the commit message. Mutually exclusive with -F. -F, --file \u0026lt;file\u0026gt; Commit the changes in the dist-git repository and take the commit message from \u0026lt;file\u0026gt;. Use - to read from the standard input. -h, --help Show this message and exit.  "}),e.add({id:13,href:"/development-docs/",title:"Development Documentation",section:"Packit",content:"Development Documentation #  This is a home to documentation meant for the Packit team. Everyone is welcome to read.\n Creating and pushing CentOS Stream 9 repositories to GitLab. Patch metadata documentation  "}),e.add({id:14,href:"/docs/testing-farm/",title:"Testing Farm",section:"User Documentation",content:"Testing Farm #  Testing Farm is Packit\u0026rsquo;s testing system. Test execution is managed by tmt tool.\nEnable Testing #  In order to enable test execution simply include tests jobs in the .packit.yaml configuration:\njobs: - job: tests  trigger: pull_request  targets:  - fedora-all The test job by default requires Copr build to be built before running tests, and then it is installed into the testing environment.\nIf you want to run tests without a Copr build, the test job needs to include skip_build (described below) option in the job configuration:\n jobs:  - job: tests  trigger: pull_request  targets:  - fedora-all  skip_build: true Required parameters:\n targets - Specify which \u0026ldquo;builds\u0026rdquo; you want to test. As with copr_build job you can use specific targets such as fedora-34-x86_64. Or just the distro part, like centos-stream-8, in which case the architecture is x86_64.  You can also use the aliases provided by Packit to not need to change the config file when the new system version is released.\nEach target is then mapped to a (tmt) distro and to a Testing farm\u0026rsquo;s compose when submitting a test. You can override the default (target to distro) mapping by specifying targets as a dictionary instead of as a list. In the following example, the epel-8-x86_64 build will be tested on centos-8 distro (otherwise the default would be centos-stream-8) and for epel-7-x86_64 build the default mapping (to centos-7 distro) will be used:\n targets:  epel-8-x86_64:  distros: [centos-8]  epel-7-x86_64: {} Optional parameters:\n fmf_url - Git repository containing the metadata (FMF) tree. Use any format acceptable by the git clone command. fmf_ref - Branch, tag or commit specifying the desired git revision. Defaults to \u0026ldquo;master\u0026rdquo; when fmf_url is specified and fmf_ref is not. tmt_plan - Run plans by the given name. Can be passed as a regular expression. tf_post_install_script - Bash script as a string to run during the guest provisioning. tf_extra_params - a free-form dict that allows specifying extra parameters to Testing Farm. For a complete list of parameters, refer to Testing Farm documentation. The dict must follow the structure of the Testing Farm request. Options specified in the dict have the highest precedence, i.e. can override Packit\u0026rsquo;s defaults. Beware of indentation-sensitivity of the YAML format. You can verify that the option is processed correctly using a YAML parser. Refer to configuration examples for more information. skip_build - Whether to skip the build phase and only run tests (defaults to false). Enabling this will cause no Copr build to be built and installed into the testing environment, only submitting request to Testing Farm (the selected components to be installed should be part of the TMT definitions). env - A dictionary you can use to set any environment variable that will be available in the Testing Farm environment where the tests are run. identifier – Suffix added to the name of a GitHub check run. This is useful when you have multiple tests jobs with different configuration. For example if you set this to e2e-tests, then a check run for Rawhide would be named testing-farm:fedora-rawhide-x86_64:e2e-tests.  There are also environment variables set by Packit:\n PACKIT_FULL_REPO_NAME PACKIT_UPSTREAM_NAME PACKIT_UPSTREAM_URL PACKIT_DOWNSTREAM_NAME PACKIT_DOWNSTREAM_URL PACKIT_PACKAGE_NAME PACKIT_PACKAGE_NVR PACKIT_BUILD_LOG_URL PACKIT_SRPM_URL PACKIT_COMMIT_SHA PACKIT_COPR_PROJECT, e.g. packit/packit-releases PACKIT_COPR_RPMS, space-separated list of RPMs that were built in Copr  And there are also pairs of variables for pull-request jobs:\n PACKIT_SOURCE_SHA and PACKIT_TARGET_SHA PACKIT_SOURCE_BRANCH and PACKIT_TARGET_BRANCH PACKIT_SOURCE_URL and PACKIT_TARGET_URL  Note that some variables do not need to be set if the value is unknown, irrelevant or not-configured.\nRestart Testing #  The testing will automatically start after an update to the pull request (and successful Copr build if skip_build is false). To trigger retesting manually (can come handy in case of infrastructure issues for example), you can use the following comment in the pull request:\n/packit test  Or if you want to re-trigger only failed tests, you can use the following comment in the pull request:\n/packit retest-failed  Running tests with builds from another pull request #  It is also possible to run the tests with Copr builds built by Packit in another pull request (in a different repository). This can be useful when you are working on a change that spans multiple projects and needs to be tested together. These tests are possible to trigger only via a comment containing the argument specifying the pull request as:\n/packit test \u0026lt;namespace\u0026gt;/\u0026lt;repo\u0026gt;#\u0026lt;pr_id\u0026gt;  The requirement is that in the specified PR, there were recent successful builds created by Packit for the targets configured in the repository with the \u0026ldquo;main\u0026rdquo; pull request. This is a new feature, so the behaviour may be adjusted in the future. Please reach out back to us for help or with your suggestions.\nCreating Tests #  The easiest way to get started with defining tests is to use the tmt tool which will help you with the setup. Please follow tmt\u0026rsquo;s guide to get started.\nExample test structure #  Once your project is initialized, this is how your structure can look like:\n$ tmt Found 3 tests: /tests/full, /tests/smoke and /tests_recording. Found 4 plans: /plans/full, /plans/rpmlint, /plans/session-recording and /plans/smoke. Found 0 stories. $ ls -1 plans/ full.fmf main.fmf rpmlint.fmf session-recording.fmf smoke.fmf More Examples #  Get inspiration for a quick start from a couple of real-life examples! These samples live in .fmf files inside tests or plans directories. You can also have a look at tmt examples site.\nUsing Filters #  Use a custom filter in the discover step in order to choose relevant tests only:\ndiscover:  how: fmf  filter: \u0026#34;tier: 1\u0026#34;  url: https://src.fedoraproject.org/tests/selinux Prepare Step #  The prepare step can be used to define how test environment should be prepared before testing. Provide one or more paths to ansible playbooks:\nprepare:  how: ansible  playbook:  - setup/packages.yml Apache Test #  Here is an example of a simple integration test for the web server httpd and curl utility:\nexecute:  script:  - dnf -y install httpd curl  - systemctl start httpd  - echo foo \u0026gt; /var/www/html/index.html  - curl http://localhost/ | grep foo The plan above defines only the execute step. Individual shell commands are provided as a list. Testing will fail if any of the commands returns a non-zero exit status.\nSystemd Tests #  Below you can find a bit more interesting example of a systemd test configuration:\nsummary:  Basic set of quick smoke tests for systemd. discover:  how: fmf  filter: \u0026#34;tier: 1 \u0026amp; distro: rhel-8\u0026#34;  url: \u0026#34;https://github.com/systemd-rhel/tests\u0026#34; prepare:  how: ansible  playbook: [setup/packages.yml] execute:  how: tmt This plan enables a set of Tier 1 tests from the shared systemd tests repository. The meaning of individual attributes is as follows:\n summary — an optional but useful attribute describing high-level purpose of the plan. discover — instructs to fetch tests from given repository and select relevant ones by provided filter. prepare — specifies which ansible playbook should be applied to prepare environment for testing. execute — defines that the tmt should be used for running the tests.  FMF Tests #  Here\u0026rsquo;s a real-life example of tests enabled for the fmf package. There are several plans defined under the plans directory. The smoke plan enables a super basic test checking availability of the fmf command:\nsummary:  Just a basic smoke test execute:  script: fmf --help Plan features is used to execute all available beakerlib tests from the fmf repository:\nsummary:  Essential command line features discover:  how: fmf  url: https://github.com/psss/fmf execute:  how: tmt It is also possible to select only a subset of available tests. This is demonstrated by the docs plan. Use an fmf filter like tier:1 to select tests for execution. You can also reference a specific feature area instead:\nsummary:  Ensure that documentation is present discover:  how: fmf  url: https://github.com/psss/fmf  filter: coverage:/stories/docs.* execute:  how: tmt See the stories directory to get some inspiration for organizing stories and requirements.\nRunning linters #  Running linters on your code is easy to set up using Testing Farm and tmt. Linters are tools which you can install from the distribution, and they usually just require a path to files which they check. Here is a plan which you can use to run rpmlint on your spec file.\nrpmlint #  We are checking our spec files with rpmlint in our project:\n ogr - plans/linters.fmf Packit - plans/rpmlint.fmf  summary:  Execute rpmlint on the spec file discover:  how: shell  tests:  - name: rpmlint  test: rpmlint packit.spec prepare:  - name: packages  how: install  package:  - rpmlint execute:  how: tmt rpminspect #  rpminspect can analyze your packages and give you information related to licensing, metadata, manpages, desktop app metadata, file ownership \u0026amp; permissions and much much more.\nHere\u0026rsquo;s a tmt plan you can use to have rpminspect invoked on SRPMs produced by Packit:\nsummary:  Check rpm files with rpminspect discover:  how: shell  tests:  - name: rpminspect  test: rpminspect-fedora /tmp/*.src.rpm prepare:  - name: packages  how: install  package:  - rpminspect  - rpminspect-data-fedora  - how: shell  script: cd /tmp \u0026amp;\u0026amp; curl -O ${PACKIT_SRPM_URL} execute:  how: tmt You can run rpminspect also using the CentOS Stream configuration. This should prepare you before opening CentOS Stream dist-git MRs.\nsummary:  Check rpm files with rpminspect discover:  how: shell  tests:  - name: rpminspect SRPM  test: rpminspect-centos -v -t VERIFY --profile=centos-stream-9-devel /tmp/*.src.rpm prepare:  - name: packages  how: install  package:  - rpminspect  - rpminspect-data-centos  - how: shell  script: cd /tmp \u0026amp;\u0026amp; curl -O ${PACKIT_SRPM_URL} execute:  how: tmt Since rpminspect is under active development, you should consider installing the latest version from this Copr project: https://copr.fedorainfracloud.org/coprs/dcantrell/rpminspect/\nYou can also inspect binary RPM files, we will make this easy to do as well in future.\nTesting Farm API #  Packit Service communicates with Testing Farm via its API.\nIssues \u0026amp; RFEs #  If you have found an issue or have an RFE, you can file an issue in nucleus project.\n"}),e.add({id:15,href:"/docs/cli/source-git/update-source-git/",title:"update-source-git",section:"source-git",content:"packit source-git update-source-git #  Sync changes made in a dist-git repository back to the corresponding source-git repository.\nThis is to enable engineers and bots to capture and sync back changes done in dist-git (by provenpackagers during rebuilds, for example). This is why changes to the source and patches are not supported! If a package has a source-git repository set up, the expectation is that the bulk of the packaging work is going to happen there.\nHelp #  $ packit source-git update-source-git --help Usage: packit source-git update-source-git [OPTIONS] DIST_GIT SOURCE_GIT [REVISION_RANGE] Update a source-git repository based on a dist-git repository. Update a source-git repository with the selected checkout of a spec file and additional packaging files from a dist-git repository. Revision range represents part of dist-git history which is supposed to be synchronized. Use `HEAD~..` if you want to synchronize the last commit from dist-git. For more information on possible revision range formats, see gitrevisions(7). If the revision range is not specified, dist-git commits with no counterpart in source-git will be synchronized. If patches or the sources file in the spec file changed, the command exits with return code 2. Such changes are not supported by this command, code changes should happen in the source-git repo. Inapplicable changes to the .gitignore file are ignored since the file may not be synchronized between dist-git and source-git. This command, by default, performs only local operations and uses the content of the source-git and dist-git repositories as it is, no checkout or fetch is performed. After the synchronization is done, packit will inform about the changes it has performed and about differences between source-git and dist-git prior to the synchronization process. Dist-git commit messages are preserved and used when creating new source-git commits, but a 'From-dist-git-commit' trailer is appended to them to mark the hash of the dist-git commit from which they are created. Examples Take the extra (not synchronized) commit(s) of systemd dist-git repo and copy the spec file and other packaging files into the source-git repo: $ packit source-git update-source-git rpms/systemd src/systemd Synchronize changes from the last three dist-git commits: $ packit source-git update-source-git rpms/systemd src/systemd HEAD~3.. Options: -f, --force Don't check the synchronization status of the source-git and dist-git repos prior to performing the update. -h, --help Show this message and exit.  "}),e.add({id:16,href:"/source-git/work-with-source-git/create-source-git/",title:"Create a source-git repo",section:"Working with source-git",content:"How to create a source-git repository? #  This guide walks through the steps to create a source-git repository from an upstream project.\n We have a dedicated command which automates most of the steps described below: packit source-git init\n Consider joining the Fedora Source-git SIG if you are interested in the development of the source-git workflow.\nThe process to construct a source-git repository and a branch to track downstream (distribution) work, which then can be synced to dist-git has the following steps:\n Identify the upstream Git repository and Git commit corresponding to the current version of the software, as available in the distribution. Create and populate a .distro subdirectory in the upstream working tree to hold the files needed to package and test the software in the distribution. Configure syncing to dist-git in .distro/source-git.yaml. Remove the references to the downstream (distribution) patches from the spec-file and apply these patches as Git-commits. Test the source-git repository by trying to sync the content to the corresponding dist-git repository.  As an example, let\u0026rsquo;s see the steps one would need to take to create a source-git repository for acl and a branch to track distribution work in Fedora Rawhide.\nIdentify the upstream Git repository and version #  Let\u0026rsquo;s search for an official project URL for acl in the spec-file for Fedora Rawhide. This could be done by using the web interface for src.fedoraproject.org, too, but as the dist-git repository is needed later on, it makes sense to clone it using fedpkg:\n$ mkdir rpms $ fedpkg clone -a acl rpms/acl Cloning into 'rpms/acl'... remote: Enumerating objects: 699, done. remote: Counting objects: 100% (699/699), done. remote: Compressing objects: 100% (473/473), done. remote: Total 699 (delta 359), reused 442 (delta 207), pack-reused 0 Receiving objects: 100% (699/699), 129.66 KiB | 316.00 KiB/s, done. Resolving deltas: 100% (359/359), done. $ git -C rpms/acl status On branch rawhide Your branch is up to date with 'origin/rawhide'. nothing to commit, working tree clean  The dist-git repo is cloned in an rpms directory, and the corresponding source-git repository will be created in a src directory later on. This directory structure helps to keep multiple dist-git and source-git repositories separate and nicely organized.\nThe URL tag in the spec-file tells, that acl is hosted at https://savannah.nongnu.org/projects/acl. Following the links from that page we can look up the URL of the project\u0026rsquo;s Git repository, and use the https one to clone it:\n$ mkdir src $ git clone https://git.savannah.gnu.org/git/acl.git src/acl Cloning into 'src/acl'... remote: Counting objects: 3687, done. remote: Compressing objects: 100% (962/962), done. remote: Total 3687 (delta 2705), reused 3687 (delta 2705) Receiving objects: 100% (3687/3687), 707.18 KiB | 1.22 MiB/s, done. Resolving deltas: 100% (2705/2705), done. $ git -C src/acl status On branch master Your branch is up to date with 'origin/master'. nothing to commit, working tree clean  From the version field of the spec-file we can tell that Fedora Rawhide has acl version 2.3.1. We search the upstream Git repository for the tag which points to the commit corresponding to this version. This commit is going to be the starting point of the rawhide branch on which the distribution work in Fedora Rawhide is going to be tracked.\n$ cd src/acl $ git tag --list | grep 2.3.1 v2.3.1 $ git checkout -B rawhide v2.3.1 Switched to a new branch 'rawhide'  Create and populate the .distro subdirectory #  In source-git, files required to package and test the software in a distribution are stored in a .distro subdirectory. This allows keeping these files separate from the source code. The distribution agnostic name was chosen in order to enable the easy sharing of the packaging work between different distributions.\nLet\u0026rsquo;s create and populate this directory:\n$ mkdir .distro $ rsync --archive --delete \\ --filter 'exclude *.patch' \\ --filter 'exclude sources' \\ --filter 'exclude .git*' \\ ../../rpms/acl/ .distro/ $ tree -a .distro/ .distro/ ├── acl-2.3.1.tar.gz.sig ├── acl.spec └── tests ├── cmd-line-options │ ├── Makefile │ ├── PURPOSE │ ├── runtest.sh │ └── test-core.sh └── tests.yml 2 directories, 7 files  A quick explanation of the filters used in the rsync-command above:\n Patch-files are not copied from dist-git. They will become part of the source-git repository as Git commits at a later step. The sources file, used in dist-git to reference the source-archives in the lookaside-cache is excluded. Upstream sources are part of the working tree in source-git. The .git directory of the dist-git repo, and other .git* files are excluded. These are specific to the dist-git repository. They are re-created later on, as needed, using a content specific to source-git.  As gitignore rules in the upstream repo and dist-git might be different, we need to reset these for the .distro directory. In the case of acl for example the top-level .gitignore has a rule to exclude Makefiles, but the tests in dist-git have a Makefile, which need to become part of the source-git repo.\nBecause the .gitignore file in dist-git has no other ignore rules than the one for the source-code archives, there are no other rules to be added to .distro/.gitignore.\n$ cat \u0026gt; .distro/.gitignore # Reset gitignore rules !*  Configure syncing to dist-git #  Now, let\u0026rsquo;s create the configuration which is going to be used when syncing content to dist-git. This is used to control certain aspects of syncing content to dist-git when using packit source-git update-dist-git.\nCreate a file called .distro/source-git.yaml with the following content:\n--- upstream_project_url: https://git.savannah.nongnu.org/git/acl.git upstream_ref: v2.3.1 downstream_package_name: acl specfile_path: .distro/acl.spec patch_generation_ignore_paths:  - .distro/ patch_generation_patch_id_digits: 1 sync_changelog: true files_to_sync:  - src: .distro/  dest: .  delete: true  filters:  - \u0026#34;protect .git*\u0026#34;  - \u0026#34;protect sources\u0026#34;  - \u0026#34;exclude source-git.yaml\u0026#34;  - \u0026#34;exclude .gitignore\u0026#34; upstream_project_url is the URL of the upstream repository. This is saved to be used by future operations.\nupstream_ref is the Git ref to be used to tell where upstream history ends and downstream history starts. Packit uses this value to tell which version of the source-archive to download from the URL specified in Source, in order to be uploaded to dist-git\u0026rsquo;s lookaside-cache.\ndownstream_package_name tells packit the name of the package.\nspecfile_path specifies where the specfile is to be found.\npatch_generation_ignore_paths lists the paths which should be ignored when generating downstream patches, to be added in dist-git. As .distro is the place where the files related to packaging are stored, set the configuration to ignore this path, so that there are no patch files generated for it.\npatch_generation_patch_id_digits tells Packit how many digits are used, at minimum, when adding PatchN tags to the spec-file. The patch in acl is in the form of Patch1, doesn\u0026rsquo;t have a minimum width, so set this value to 0.\nSetting sync_changelog to true tells Packit to sync the changelog in the spec-file as is. This disables Packit\u0026rsquo;s functionality to automatically update the changelog when syncing to dist-git.\nfiles_to_sync controls the way files are synced when updating dist-git. In the context of the current source-git structure this means to syncing the content of .distro with the root of the dist-git repo. This is what the src and dest fields configure.\ndelete: true causes files not in src to be deleted from dest.\nfilters is a list of rsync filters to be used to protect paths in dest and exclude paths in src from the sync operation.\nYou can think about the files_to_sync section as describing the reverse of the rsync-command used to copy content from dist-git to .distro.\nWe plan to make most of this configuration implicit, so most of it might not be required in the future.\nUpdate the spec-file and apply the downstream patches #  In dist-git downstream changes are stored as patch-files, which then are referenced in the spec-file and applied during %prep when building the package. In source-git we want the same changes to become Git commits in the repository. This also means, that it would be semantically weird to reference the patch-files in the spec-file. As there are no patch-files in the source-git repo.\nSo let\u0026rsquo;s remove the following lines from .distro/acl.spec:\n# avoid permission denied problem with LD_PRELOAD in the test-suite Patch1: 0001-acl-2.2.53-test-runwrapper.patch Pay attention not to modify any other part of the spec-file, except deleting these lines. Saving .distro/acl.spec with an editor which is configured to strip white-space from the end of lines will result in unnecessary diff-chunks when syncing content back to dist-git.\nNote, that acl is using %autosetup to apply the patches in %prep, this is why the %prep section doesn\u0026rsquo;t need an update. Because packit source-git update-dist-git doesn\u0026rsquo;t support adding the %patch macros when adding patches to the spec-file during syncing, currently only packages using %autosetup are supported. At the time of writing, adding support for %setup is still not decided.\nAt this point, the .distro directory is ready, and can be commited as the first commit on the rawhide branch.\n$ git add .distro/ $ git commit -m'Initialize as a source-git repository' [rawhide c333206] Initialize as a source-git repository 9 files changed, 736 insertions(+) create mode 100644 .distro/.gitignore create mode 100644 .distro/acl-2.3.1.tar.gz.sig create mode 100644 .distro/acl.spec create mode 100644 .distro/source-git.yaml create mode 100644 .distro/tests/cmd-line-options/Makefile create mode 100644 .distro/tests/cmd-line-options/PURPOSE create mode 100755 .distro/tests/cmd-line-options/runtest.sh create mode 100755 .distro/tests/cmd-line-options/test-core.sh create mode 100644 .distro/tests/tests.yml  The rawhide branch in the source-git repo has its first downstream commit now:\n$ git log --oneline v2.3.1.. c333206 (HEAD -\u0026gt; rawhide) Initialize as a source-git repository  Now, apply the only downstream patch from dist-git. We\u0026rsquo;re using git am in this case, but depending on the type of the patch-files in dist-git, you might need to use git apply:\n$ git am ../../rpms/acl/0001-acl-2.2.53-test-runwrapper.patch  The rawhide branch now also has the downstream change in the source-code as a commit:\n$ git log --oneline v2.3.1.. 7054794 (HEAD -\u0026gt; rawhide) test/runwrapper: copy the preloaded library c333206 Initialize as a source-git repository  The only thing left to do is to make sure that the patch-file generated from this commit is going to keep its name (and not use the default name generated by git format-patch), and that the patch status line is going to be included above the patch when it\u0026rsquo;s added back to the spec-file while syncing to dist-git.\nPackit understands Git-trailers which can be included in the commit message, and used to tweak how patch-files are generated and included in the spec-file. You can include the patch status with the help of the Patch-status field, and specify the patch-file name with Patch-name.\nOne more Git-trailer that should be added in this step is From-dist-git-commit, which can be used later on to tell which dist-git commit was used to create this source-git repository.\nAmend the last commit\u0026hellip;\n$ git commit --amend  \u0026hellip;and edit the commit message to include this field at the end of it.\ntest/runwrapper: copy the preloaded library ... to a temporary directory because the original location might not be accessible by other users. Patch-name: 0001-acl-2.2.53-test-runwrapper.patch Patch-status: |- avoid permission denied problem with LD_PRELOAD in the test-suite From-dist-git-commit: 08c7e74d0a58c9483d2f4f55a3fba2baffb09c3a # Please enter the commit message for your changes. Lines starting # with \u0026#39;#\u0026#39; will be ignored, and an empty message aborts the commit. # # Author: Kamil Dudka \u0026lt;kdudka@redhat.com\u0026gt; # Date: Tue Jul 3 10:46:58 2018 +0200 # # On branch rawhide # Changes to be committed: #	modified: test/runwrapper # Save and exit.\nTest the source-git repository #  Try creating an update in the dist-git repository from the source-git repository you\u0026rsquo;ve just created. All the changes below are local.\n$ cd ../../ $ packit --config src/acl/.distro/source-git.yaml source-git update-dist-git --pkg-tool fedpkg src/acl rpms/acl 2021-05-21 17:19:49.158 api.py INFO Won't be doing kinit, no credentials provided. 2021-05-21 15:19:50.103 distgit.py INFO Archive 'acl-2.3.1.tar.gz' found in lookaside cache (skipping upload).  Now check the dist-git repo to see if there are any changes:\n$ git -C rpms/acl status On branch rawhide Your branch is up to date with 'origin/rawhide'. nothing to commit, working tree clean  A clean working tree in this case means, that the transformation of source-git to dist-git resulted in the same content. Which is good.\nTry adding a new, dummy, change in source-git and update dist-git again, to see a new patch being added:\n$ cd src/acl $ echo 'A dummy change' \u0026gt;\u0026gt; README $ git diff diff --git a/README b/README index abcfdc6..05c4af6 100644 --- a/README +++ b/README @@ -11,3 +11,4 @@ information and references to other related manual pages. For more information on the build process, please refer to doc/PORTING. +A dummy change $ git commit -aF- (reading log message from standard input) Add a dummy change description: a patch to try things out [rawhide fb34af6] Add a dummy change 1 file changed, 1 insertion(+) $ cd ../../ $ packit --config src/acl/.distro/source-git.yaml source-git update-dist-git --pkg-tool fedpkg src/acl rpms/acl 2021-05-27 16:46:38.574 api.py INFO Won't be doing kinit, no credentials provided. 2021-05-27 14:46:39.747 distgit.py INFO Archive 'acl-2.3.1.tar.gz' found in lookaside cache (skipping upload).  Check the diff in dist-git and the new patch generated from source-git:\n$ git -C rpms/acl diff diff --git a/acl.spec b/acl.spec index 2bf7182..ac7bc75 100644 --- a/acl.spec +++ b/acl.spec @@ -15,6 +15,9 @@ Source: https://download-mirror.savannah.gnu.org/releases/acl/acl-%{version}.tar # avoid permission denied problem with LD_PRELOAD in the test-suite Patch1: 0001-acl-2.2.53-test-runwrapper.patch +# a patch to try things out +Patch2: 0002-Add-a-dummy-change.patch + License: GPLv2+ URL: https://savannah.nongnu.org/projects/acl $ cat rpms/acl/0002-Add-a-dummy-change.patch From fb34af687e2b650920775647a7c8d149c60403eb Mon Sep 17 00:00:00 2001 From: =?UTF-8?q?Hunor=20Csomort=C3=A1ni?= \u0026lt;csomh@redhat.com\u0026gt; Date: Thu, 27 May 2021 16:42:19 +0200 Subject: [PATCH 2/2] Add a dummy change description: a patch to try things out --- README | 1 + 1 file changed, 1 insertion(+) diff --git a/README b/README index abcfdc6..05c4af6 100644 --- a/README +++ b/README @@ -11,3 +11,4 @@ information and references to other related manual pages. For more information on the build process, please refer to doc/PORTING. +A dummy change -- 2.31.1  "}),e.add({id:17,href:"/docs/faq/",title:"FAQ",section:"User Documentation",content:"FAQ #  Can I use the packit service as soon as I install it into my repository? #  Thanks for your interest in Packit Service! In order to start using the service, your repository or namespace needs to be allowed. Just be aware that we are now onboarding Fedora contributors who have a valid Fedora Account System account. For more details on how to get allowed for our service, please read about the process here.\nCan I use packit service for any GitHub repository? #  Since Packit Service builds your PRs in Fedora COPR build service, by using Packit-as-a-service, your software needs to comply with COPR rules. If any of these points are violated, we\u0026rsquo;ll remove the builds and may put you on a blocklist, so you won\u0026rsquo;t be able to use the service again.\nHow can I contact you? #  If you encounter a problem while using packit or Packit Service, please open an upstream issue. In case of any other questions, feel free to contact us:\n #packit on Libera.Chat hello@packit.dev  Why do I have to maintain .packit.yaml and a spec file upstream? #  We are working on simplifying the .packit.yaml so it\u0026rsquo;s as small as possible. We will also handle all potentially backward incompatible changes of .packit.yaml. Spec file can be downloaded (see specific question below) from Fedora Pagure instead of having it included in the upstream repository.\nBut what are the benefits? #  Packit makes it trivial to run your project as part of an OS. It provides feedback to your project at the time when the changes are being developed so you can fix incompatible code when you are working on it, not when it\u0026rsquo;s already released. When you push commits to a pull request, you\u0026rsquo;ll get RPM build and test results right away.\nWhy Fedora? #  We\u0026rsquo;ve started with Fedora Linux because we work for Red Hat and we ❤ Fedora.\nHow is Packit different from other services? #  Packit connects the existing services (Copr, Fedora dist-git, Koji, Bodhi) together.\nCan we use Packit with Gitlab? #  Yes! You can find instructions at the Packit Service page.\nHow can I download RPM spec file if it is not part of upstream repository? #  If you do not want to have the RPM spec file in your upstream repository, you can download it in actions section.\nAdd actions section to your packit.yaml configuration file and download the spec file in a hook post_upstream_clone. The environment where these commands are run is limited, so make sure to install relevant packages using the srpm_build_deps option.\nThe configuration file with downloading the RPM spec file now looks like this:\nspecfile_path: packit.spec files_to_sync:  - packit.spec  - .packit.yaml upstream_package_name: packitos downstream_package_name: packit actions:  post-upstream-clone: \u0026#34;wget https://src.fedoraproject.org/rpms/packit/raw/main/f/packit.spec -O packit.spec\u0026#34; srpm_build_deps:  - wget I have a template of a spec file in my repo: can packit work with it? #  Yes!\nThe solution is, again, actions and hooks. Just render the spec after the upstream repo is cloned:\nspecfile_path: my-project.spec upstream_package_name: my-project-src downstream_package_name: my-project actions:  post-upstream-clone: \u0026#34;make generate-spec\u0026#34; Where the \u0026ldquo;generate-spec\u0026rdquo; make target could look like this:\ngenerate-spec: sed -e 's/@@VERSION@@/$(VERSION)/g' my-project.spec.template \u0026gt;my-project.spec  As a practical example, cockpit-podman project is using this functionality.\nCan I use CentOS Stream with packit service? #  Yes, you can! It\u0026rsquo;s very simple, just add centos-stream-8-x86_64 as a target for the copr_build job:\njobs: - job: copr_build  trigger: pull_request  targets:  - centos-stream-8-x86_64 After adding tests I see error \u0026lsquo;No FMF metadata found.\u0026rsquo; #  If you encounter this error when running tests via Testing Farm, it means you forgot to initialize the metadata tree with fmf init and include the .fmf directory in the pull request. See Testing Farm documentation for more information.\nDoes packit work with rpmautospec? #  Good that you ask. It does, packit works with rpmautospec quite nicely.\nBefore you start, please make sure that you follow latest documentation for rpmautospec.\nrpmautospec utilizes two RPM macros:\n autorelease — to populate Release autochangelog — to figure out changelog  If you want your upstream spec file to also work well when rpmautospec-rpm-macros is not installed, set Release to this:\nRelease: %{?autorelease}%{!?autorelease:1%{?dist}}  This construct uses autorelease macro if it\u0026rsquo;s defined, and if it\u0026rsquo;s not, it sets release to 1%{?dist}.\nFor %changelog, you don\u0026rsquo;t need to include the changelog file upstream. You can have it downstream only, which makes sense - changelog is specific to a release.\nHow do I install dependencies for my commands in packit-service? #  For installations made before September 6, 2022, Packit runs all the commands, defined by you, in a sandbox which is locked-down.\nAs for the actions needed during SRPM builds, we are transitioning into a solution where SRPMs are built directly in Copr and therefore for these actions, you can define your dependencies via srpm_build_deps key in the configuration file. You can read more about this transition here.\nA command failed in packit-service: how do I reproduce it locally? #  Please read this document on how to reproduce locally.\n"}),e.add({id:18,href:"/docs/cli/create-update/",title:"create-update",section:"Packit CLI",content:"packit create-update #  Create a new bodhi update for the latest Fedora build of the upstream project.\nRequirements #   Upstream git repository on GitHub. Packit config file placed in the upstream repository.  Tutorial #    Place a config file for packit in the root of your upstream repository..\n  Once the builds are done, you can run the create-update command. If you don\u0026rsquo;t specify the koji builds packit takes latest build.\n$ packit create-update --dist-git-branch f35 https://github.com/packit/packit.git Bodhi OIDC authentication follows. Authenticating... Please open your browser to: https://id.fedoraproject.org/openidc/Authorization?response_type=code... Paste here the code that you got after logging in: code=d4d8e70c-ea... Login successful! Bodhi update FEDORA-2019-b72add0dcd: - https://bodhi.fedoraproject.org/updates/FEDORA-2019-b72add0dcd - stable_karma: 3 - unstable_karma: -3 - notes: \u0026#34;New upstream release 0.42.0\u0026#34;   If you are not authenticated with the bodhi server, please make sure that you navigate in your browser to the URL provided by the bodhi-client and then paste the code=XX... to the terminal when prompted.\nIf you set fas_user and kerberos_realm in your \u0026ldquo;~/.config/packit.yaml\u0026rdquo; and have an active Kerberos TGT, you will be automatically authenticated.\nHelp #  Usage: packit create-update [OPTIONS] [PATH_OR_URL] Create a bodhi update for the selected upstream project PATH_OR_URL argument is a local path or a URL to the upstream git repository, it defaults to the current working directory Options: --dist-git-branch TEXT Comma separated list of target branches in dist-git to create bodhi update in. (defaults to repo's default branch) --koji-build TEXT Koji build (NVR) to add to the bodhi update (can be specified multiple times) --update-notes TEXT Bodhi update notes --update-type [security|bugfix|enhancement|newpackage] Type of the bodhi update -b, --resolve-bugzillas BUGZILLA_IDS Bugzilla IDs that are resolved with the update -h, --help Show this message and exit.  "}),e.add({id:19,href:"/docs/configuration/",title:"Configuration",section:"User Documentation",content:"Configuration #  Packit uses a configuration file in the upstream repository. The config file is written in YAML language.\nYou should place the file in the root of your upstream repo. Packit accepts these names:\n .packit.yaml .packit.yml packit.yaml packit.yml  Both Packit Service and packit tool use this configuration file.\nTop level keys #  specfile_path #  (string) Relative path to a spec file within the upstream repository. If not specified, defaults to:\n downstream_package_name.spec if downstream_package_name is set. (deprecated) Else recursively search the tree and use the first spec file found.  If there are only test jobs with skip_build option defined (more about it here), spec file doesn\u0026rsquo;t need to be present and its path doesn\u0026rsquo;t need to be defined in the config.\nThe functionality to recursively search for a specfile is deprecated and it\u0026rsquo;s going to be removed in a future version (\u0026gt;0.64.0) of Packit. We recommend projects to explicitly set specfile_path or rely on the \u0026lt;downstream_package_name\u0026gt;.spec default, by setting downstream_package_name.\nupstream_project_name (deprecated) #  (string) Deprecated since packit-0.7.0, use upstream_package_name instead.\nupstream_package_name #  (string) Name of the upstream repository (e.g. in PyPI), defaults to the name of the GitHub repository; it\u0026rsquo;s used when working with the upstream project, as a release archive name and as a directory name in that archive.\nupstream_project_url #  (string) URL of the upstream git project (e.g. https://github.com/packit/packit).\ncreate_pr (only in CLI) #  (bool) When doing a new update in Fedora dist-git, should packit create a new pull request (defaults to true) or push directly to dist-git (if set to false). This option can be used only locally in the CLI, but can be overriden via --pr/--no-pr option. Deployed Packit (on GitHub or GitLab) ignores this setting, because Packit Team does not endorse automated release from created release to the Bodhi update without any quality assurance.\nmerge_pr_in_ci #  (bool) When Packit clones your repository while creating RPMs from your pull requests, it by default merges the pull request checkout into the main repository branch to be sure the changes are up to date. You can disable this behaviour by setting this field to false which will make Packit to work with your pull request git ref as it is.\nsync_changelog #  (bool) When doing a new update in Fedora dist-git, the specfile changelog is synchronized when set to true. By default (false), everything but the changelog part is synchronized. Use this only when your changelogs are in sync since this overwrites the changelog in the downstream.\nsynced_files (deprecated) #  (list of strings or dicts) A list of relative paths to files in the upstream repo which are meant to be copied to dist-git during an update (spec file path and config file path are set every time by default).\nIt is now deprecated in favor of files_to_sync.\nupdate_release #  (bool) Packit by default modifies Release in the spec file when creating a SRPM. If you don\u0026rsquo;t want this, you can prevent it with\nupdate_release: false  This option only applies to SRPM creation and doesn\u0026rsquo;t affect propose_downstream and pull_from_upstream jobs.\nrelease_suffix #  (templated string) String that can be used to override the default release suffix generated by Packit. The suffix will be expanded, and you can use following variables:\n PACKIT_PROJECT_VERSION - version from git describe PACKIT_RPMSPEC_RELEASE - release from specfile PACKIT_PROJECT_COMMIT - commit SHA from which the SRPM is built PACKIT_PROJECT_BRANCH - branch from which the SRPM is built  Example usage:\nrelease_suffix: \u0026quot;dev.{PACKIT_PROJECT_BRANCH}\u0026quot;  When unset, default release suffix that is generated by Packit is following:\n{original_release_number}.{current_time}.{sanitized_current_branch}{git_desc_suffix}  It is also possible to define release_suffix at the top-level of your packit config. In that situation all jobs and SRPM, Copr, Koji and RPM build from CLI will inherit the release_suffix that you have set. We advise caution when doing such thing, because inheriting the release suffix value by Copr or Koji build may easily cause confusion, break the ordering of the NVRs of the RPMs and also may cause usage of RPMs that are not meant for production use. In such scenarios, please try to make sure RPMs built by Packit are easily distinguishable from the RPMs meant for production use. To prevent the inheritance, you can define:\nrelease_suffix: null  If you don\u0026rsquo;t want the release to be modified at all, see update_release.\nThis option only applies to SRPM creation and doesn\u0026rsquo;t affect propose_downstream and pull_from_upstream jobs.\nfiles_to_sync #  (list of strings or dicts) A list of relative paths to files in the upstream repo which are meant to be copied to dist-git during an update.\nSpec file path and config file path are always included by packit init but can be manually removed from the list.\nUnder the hood this will use rsync --archive to synchronise the paths between the upstream and the dist-git repo.\nThe fields for a dictionary item in the list are the following:\n src: A single path or a list of paths in the upstream repo that should be synced to dist-git. dest: Path in the dist-git repo, where paths in src should be synced to. mkpath: Flag to indicate if missing path components in dest should be created or not (default: false). delete: Flag to indicate if extra content from dest should be deleted (default: false). filters: List of rsync filter rules to be used during syncing.  Examples: #  Copy a file from root of the upstream repo to dist-git:\nfiles_to_sync:  - packit.spec If you copy packit.yaml downstream, you can then take advantage of sync-from-downstream command:\nfiles_to_sync:  - .packit.yaml Rename or change the path of the synced file in dist-git:\nfiles_to_sync:  - src: packit.spec  dest: redhat/packit.spec Paths also support globs. Copy everything from fedora-packaging folder and put it to the root of the dist-git repo:\nfiles_to_sync:  - src: fedora-packaging/*  dest: . Sync the entire content of the fedora-packaging directory, and delete extra content found in the root of the dist-git repo; protect .git* files and the sources file from deletion:\nfiles_to_sync:  - src: fedora-packaging/  dest: .  delete: true  filters:  - \u0026#34;protect .git*\u0026#34;  - \u0026#34;protect sources\u0026#34; Specify multiple source files to copy:\nfiles_to_sync:  - src:  - package.spec  - some-file  dest: . Set mkpath to true to create missing path components in dist-git. In the example below, subdir is created if missing.\nfiles_to_sync:  - src: some.file  dest: subdir/some.file  mkpath: true create_sync_note #  (bool) Create or update a README.packit file in dist-git when doing a new update, telling that the repository is maintained by Packit and marking the version of packit creating the update. By default, this option is set to true. When set to false, README.packit is not created or updated. (A previously created README.packit needs to be removed manually).\nupstream_ref #  (string) Git reference to last upstream git commit (for source-git repos). Can be set to commit hash, tag or a branch name. You can also use globbing pattern to find a tag. In case you want to use globbing pattern for a branch, prefix the pattern with branches/, e.g. for a branch matching *-release set to branches/*-release.\ndownstream_package_name #  (string) Name of the RPM package in Fedora, defaults to the name of the GitHub repository.\ndist_git_namespace #  (string) Namespace in dist-git URL (defaults to rpms).\ndist_git_base_url #  (string) URL of dist-git server, defaults to https://src.fedoraproject.org/ (has to end with a slash).\ncreate_tarball_command (deprecated) #  Please use create-archive action\ncurrent_version_command (deprecated) #  Please use get-current-version action\nactions #  (string) Custom actions/hooks overwriting the default behavior of packit (more in Actions).\njobs #  (list of dicts) A list of job definitions for packit service: see below for details.\nallowed_gpg_keys #  (list of string) A list of gpg-key fingerprints; if specified, one of the configured keys have to sign the last commit when updating in downstream; add GitHub key (5DE3E0509C47EA3CF04A42D34AEE18F83AFDEB23) if you want to use this on code merged via GitHub web interface.\nspec_source_id #  (int or string) Numeric ID of Source inside spec file which packit should change when setting path to the newly generated tarball, can be also full name of the macro. Defaults to Source0 or Source, whichever is found first in the spec file.\nupstream_tag_template #  (string) Packit by default expects git tags to match versions (e.g. when doing the propose-downstream command) - if you are using a different tagging scheme, let\u0026rsquo;s say v1.2.3 you can then set this parameter to v{version} and packit will fill in the version argument.\narchive_root_dir_template #  (string) In the fix-spec-file action Packit changes first %setup (or %autosetup) macro in %prep and adds -n so the generated tarball can be unpacked. For this purpose, it requires the name of the directory in the source archive. For tar archives with one directory, Packit gets it automatically. If Packit is not able to extract it from the archive with the tar python module, it is possible to specify it explicitly with this option.\nDefault value is {upstream_pkg_name}-{version}.\nYou can use following tags in string:\n {upstream_pkg_name} - name of the upstream package {version} - package version  patch_generation_ignore_paths #  (list of strings) In a source-git repo, when packit is generating patches, it excludes changes to the spec file and packit.yaml by default: with this option you can precisely specify paths to exclude.\npatch_generation_patch_id_digits #  (integer) The number of digits (minimum width) used for patch IDs when adding PatchN tags to a spec-file while updating dist-git from a source-git repository. Defaults to 4, that is, patches will look like PatchNNNN: \u0026lt;patch_name\u0026gt;, and leading zeros are added, if needed. A value of 0 means \u0026ldquo;no minimum width\u0026rdquo;.\nnotifications #  There is only one notification configuration you can set up right now: enable the \u0026ldquo;Congratulations!\u0026rdquo; comment which will packit send after a successful build of a pull request is done.\nThe default behaviour is not to send the comment with instructions how to install a package with the change implemented in the pull request:\nnotifications:  pull_request:  successful_build: false You can enable the commenting by setting successful_build to true.\nissue_repository #  Use this key to be notified about errors of the downstream jobs (Koji build, Bodhi update, pull from upstream). The value can be a URL of any GitHub/GitLab/Pagure project including dist-git where issues are enabled and Packit has an identity on that git forger instance. Alternatively, you can set up a dedicated project for receiving such notifications. (Let us know if you need another instance to be supported.) It does not need to be an upstream repository, you can also enable an issue tracker for the dist-git repository and use this as a place for those notifications. Or, you can set up a dedicated project for receiving such notifications.\nBy default, no issue will be created so Packit doesn\u0026rsquo;t unintentionally spam any repository. (E.g. Since those jobs are defined in downstream, upstream project does not need to be aware of Packit.)\nBy enabling this setting, Packit will either create a new issue or add a comment to an already existing issue. In that case, the issue will be reused and a new comment will be added.\nWhen a downstream job (e.g. Koji build or Bodhi update) fails, you can re-trigger the failed job by\n/packit koji-build or /packit create-update comment in the opened issue by Packit. The Packit app has to be installed in the issue repository and the user, who commented, needs to have write permissions into the repository in order for the retriggering to work.\ncopy_upstream_release_description #  (bool) When doing a new update in Fedora dist-git, the GitHub upstream release description is copied to the specfile changelog when set to true. By default (false), commit message titles (first line of a commit message) are copied. But be aware that the release description is copied as is, without any processing and the result needs to fulfill the spec-file syntax. Be specially careful when using characters like % that can be interpreted as macros. Also, use - for bullet points instead of * so the line is not interpreted as a new changelog entry.\ne.g.\n copy_upstream_release_description = True:  %changelog * Thu Oct 15 2020 Packit Service \u0026lt;user-cont-team+packit-service@redhat.com\u0026gt; - 0.18.0-1 Packit got new archive_root_dir_template config option to get custom archive root dir. You can find more info in the documentation.  copy_upstream_release_description = False (default):  %changelog * Thu Oct 15 2020 Packit Service \u0026lt;user-cont-team+packit-service@redhat.com\u0026gt; - 0.18.0-1 - Use inner archive directory in %setup macro - Use archive_root_dir_template sources #  (list of dicts) A list of sources to override the URLs of SourceX entries in the spec-file.\nsources:  - path: rsync-3.1.3.tar.gz  url: https://git.centos.org/sources/rsync/c8s/82e7829c0b3cefbd33c233005341e2073c425629 path is the path relative to the directory with sources where the source will be placed. If a SourceX entry with corresponding basename exists in the spec-file, the source will be downloaded from the url found in the configuration instead of the location defined in the spec-file.\nsrpm_build_deps #  (list of strings) A list of RPM dependencies that are needed for your actions to be run when building a SRPM. The dependencies are installed into the Copr build environment each time the build is triggered.\npackit_instances #  (list of strings) If you want to help us with catching issues or need some feature sooner than other users, you can use our staging instance that has the freshest code we have. For that, you can specify the instance(s) that will react to your jobs by using this configuration option. It uses [\u0026quot;prod\u0026quot;] as the default, but you can set both ([\u0026quot;prod\u0026quot;, \u0026quot;stg\u0026quot;]) or just stage ([\u0026quot;stg\u0026quot;]). You can also have a different setup for each job \u0026ndash; see how the overriding works in the config file.\nJust be aware that:\n You still need to install the staging GitHub application. Staging application has fewer resources and can be a bit slower in responses. If you use both instances, you will have twice the number of commit statuses. Picking just one instance might be better for downstream jobs since both instances will work with the production instances of Fedora systems.  Please, let us know when something looks weird or does not work with the staging app. By doing that, you are helping us to be sure that we don\u0026rsquo;t break your use-case.\nPackit-as-a-Service #  Packit service doesn\u0026rsquo;t have any web interface to configure it, so the only way to change its behaviour is via the config file you just read about.\nWhen you open a pull request against your upstream repository, packit service picks up configuration file from your pull request, not from the branch against the PR is opened. This way, you can polish your .packit.yaml and see the results right away. (for more info, please see packit-service#48)\nPackit service jobs #  Once the service starts handling events of your repository, it needs to have a clear definition of what it should do.\nThe tasks the packit service should do are defined in section jobs. The section is a list of dicts:\njobs: - {key: value} - {} If there is no jobs section in the configuration file, jobs default to:\njobs: - job: copr_build  trigger: pull_request  targets: [fedora-stable]  - job: tests  trigger: pull_request  targets: [fedora-stable]  - job: propose_downstream  trigger: release  dist_git_branches:  - fedora-all If you do not want to use the jobs then the jobs section in the configuration file should be empty:\njobs: [] Packit configuration supports YAML Merge Key syntax, which can be used to reduce duplication of configuration. Please see the example:\n# before jobs: - job: copr_build  trigger: pull_request  targets:  - centos-stream-8-x86_64  - centos-stream-9-x86_64  - fedora-all  - job: copr_build  trigger: commit  branch: main  targets:  - centos-stream-8-x86_64  - centos-stream-9-x86_64  - fedora-all  # after jobs: - \u0026amp;copr  job: copr_build  trigger: pull_request  targets:  - centos-stream-8-x86_64  - centos-stream-9-x86_64  - fedora-all  - \u0026lt;\u0026lt;: *copr  trigger: commit  branch: main Every job has two mandatory keys:\n job - name of the job (you can imagine this as a CLI command) trigger - what is the trigger for the job?  Every job only supports a specific set of triggers.\nOverriding global parameters #  You are able to override your global parameters (such as specfile_path, downstream_package_name, actions\u0026hellip;) for every job. This is very useful when you want to set up a build or a test matrix using different parameters or configuration. It\u0026rsquo;s also useful when your release workflow differs between Fedora and EPEL.\nIn order to do such a thing, just set a value you want to override in the respective job.\nExample:\nspecfile_path: package.spec jobs: - job: some-job  trigger: ran-out-of-beer  targets: [fedora-stable]  specfile_path: somewhere/else/package.spec In this example, the job some-job would override specfile_path to somewhere/else/package.spec instead of using ./package.spec.\nAliases #  To not need to change the config file when the new system version is released, Packit provides multiple aliases to reference a subset of the active Fedora Linux releases:\n fedora-all - all active releases, which includes released and branched versions and Rawhide (e.g. fedora-34, fedora-35, fedora-36, fedora-rawhide). fedora-stable — the current (two or three) released and supported versions (e.g. fedora-34, fedora-35). fedora-development — development versions of Fedora; the branched version is used only when available (e.g. fedora-36, fedora-rawhide) fedora-latest — the last versioned Fedora (not a Rawhide), regardless if it\u0026rsquo;s released or still under development. fedora-latest-stable — the latest released Fedora version (e.g. fedora-35). fedora-branched — all branched releases, that is: everything, except Rawhide (e.g. fedora-34, fedora-35, fedora-36).  Additionally, epel-all can be used as an alias for the current active EPEL versions (e.g. epel-7, epel-8, epel-9)\nThe aliases above can be used both to specify targets when building in Copr or running tests, and to reference dist-git branches of different system versions (e.g. for propose_downstream job or downstream jobs like koji_build or bodhi_update).\nThe information about releases is retrieved from Bodhi and because of the cache and required availability on Copr, it might take a while to get the newest state.\nSupported jobs #  copr_build #  Create a SRPM and submit an RPM build to Fedora COPR build system.\nSupported triggers:\n pull_request \u0026ndash; check out content of the pull request commit \u0026ndash; reacts to new commits to the specified branch release \u0026ndash; check out content of the tag associated with the release  Required parameters:\n targets - (a list of) mock chroot(s) where the build is going to be executed (example fedora-rawhide-x86_64, defaults to fedora-stable): for more info see below. Does not need to be defined if using a custom Copr project (we fetch targets from the Copr settings). branch - the name of the branch we want to build for when using commit trigger  Optional parameters:\n timeout - (seconds) give up watching a build after timeout, defaults to 7200s, i.e. 2 hours owner - a namespace in Copr where the build should happen (defaults to packit). Prefix with @ in case of a group. project - a name of the Copr project (defaults to \u0026quot;{github_namespace}-{repository_name}-{pr_id}\u0026quot;) additional_repos - a list of additional buildroot repositories list_on_homepage \u0026ndash; The project will be shown on Copr frontend homepage if set to True. Defaults to False. The value is represented as unlisted_on_hp in Copr project settings. preserve_project \u0026ndash; The project will not be removed after 60 days if set to True. Defaults to False. The value is represented as delete_after_days in Copr project settings (True is -1 and False is 60). enable_net \u0026ndash; Specifies whether created Copr build should have access to network during its build. Defaults to False (Copr default, switched to False in June 2022). identifier \u0026ndash; Suffix added to the name of a GitHub check run. This is useful when you have multiple copr_build jobs with different configuration. For example if you set this to \u0026ldquo;mock\u0026rdquo;, then a check run for Rawhide would be named \u0026ldquo;rpm-build:fedora-rawhide-x86_64:mock\u0026rdquo;. module_hotfixes \u0026ndash; The project will have module_hotfixes=1 in the Copr generated repo files. This is useful when you build packages that need to be installed in a modular context. Defaults to False.  Using a custom Copr project #  When using a custom Copr project (by specifying project and owner), the GitHub repo has to be listed in the Packit allowed forge projects field in the Copr project settings so that the Copr builds can be actually run. As an example the string github.com/osbuild/osbuild has to be inserted into https://copr.fedorainfracloud.org/coprs/g/osbuild/osbuild/edit/#packit_forge_projects_allowed.\nWhen using a custom owner, Packit Service asks for builder permission the first time it tries to build in the project. In case the configuration of the Copr project (e.g. adding new targets) need to be updated, Packit Service asks for admin permission. You need to approve these requests in the Copr project settings.\nIf you do not want to give us admin permission, you can update the project settings manually in Copr based on the guidance Packit Service gives.\nYou can also directly edit the permissions yourself without waiting for the Packit request by running:\n$ copr-cli edit-permissions --builder packit [--admin packit] \u0026lt;project\u0026gt;  Boolean values (list_on_homepage and preserve_project) are not updated when you use custom owner.\nExample\njobs: - job: copr_build  trigger: pull_request  targets:  - fedora-stable  - centos-stream-8-x86_64 With this configuration, you\u0026rsquo;ll get builds in all stable fedora releases (excluding rawhide) and the CentOS stream.\nTarget-specific configuration #  You can define a specific build configuration for different targets (chroots in context of Copr). For example, there are packages that are architecture specific and not available for all architectures. Or you may want modules enabled for builds in CentOS Stream 8.\nCopr allows specifying additional packages, modules and repos for individual targets.\nSetting this in packit.yaml requires targets to be a mapping. If you require this functionality, this is the preferred solution over specifying multiple jobs. Example:\njobs - job: copr_build  trigger: pull_request  targets:  centos-stream-8:  additional_repos:  - http://koji.katello.org/releases/yum/foreman-nightly/el8/x86_64/  additional_modules: \u0026#34;foreman:el8,ruby:2.7,nodejs:12,postgresql:12\u0026#34;  fedora-rawhide: {}  fedora-37: {} In this case, both Fedora targets don\u0026rsquo;t have anything specific and would use packages and modules from the base distro, while CentOS Stream 8 will use a custom yum repo and 4 specific modules.\nYou can define these three options:\n additional_packages (list) – install additional packages before the build additional_repos (list) – enable these yum repositories before installing any packages additional_modules (str) – enable these modules before installing packages, specified as comma-separated string: MODULE:STREAM,MODULE2:STREAM2,...  Available COPR build targets #  There are multiple places where you can get the latest list of available build targets:\n  Open your COPR project, then click \u0026ldquo;Settings\u0026rdquo; \u0026gt; \u0026ldquo;Build options\u0026rdquo; \u0026gt; \u0026ldquo;Chroots\u0026rdquo; - these are the same values packit accepts.\n  Install package copr-cli and run:\n  $ copr-cli list-chroots centos-stream-8-aarch64 centos-stream-8-x86_64 custom-1-i386 custom-1-x86_64 epel-6-i386 epel-6-x86_64 epel-7-aarch64 epel-7-x86_64 epel-8-aarch64 epel-8-x86_64 fedora-32-aarch64 fedora-32-armhfp ...   You can also use the aliases provided by Packit to not need to change the config file when the new system version is released.\nBy default, the x86_64 architecture will be used, but you you can override the default e.g. fedora-stable-aarch64.\n  If you are using custom Copr repository for your Copr builds, you don\u0026rsquo;t have to define the targets at all and they will be deduced from your custom Copr project.\n  tests #  See more about tests here.\nupstream_koji_build #  Create a SRPM from upstream and submit a scratch RPM build to Fedora Koji build system.\nAt the moment it is not possible to run non-scratch Koji builds from upstream. For more info, please see the following issue.\nIf you want to do official Koji builds, the sources need to be present in dist-git: job koji_build can take care of that.\n(The job used to be called production_build but we are deprecating that name in favour of the more explicit upstream_koji_build.)\nSupported triggers:\n pull_request \u0026ndash; check out content of the pull request commit \u0026ndash; reacts to new commits to the specified branch release \u0026ndash; check out content of the tag associated with the release  Required parameters:\n branch \u0026ndash; the name of the branch we want to build for when using commit trigger.  Optional parameters:\n targets \u0026ndash; (a list of) targets we want to build for, list of supported targets can be listed using with koji list-targets. You can also use the aliases provided by Packit to not need to change the config file when the new system version is released.  propose_downstream #  Land a new upstream release in Fedora. This job only makes sure the changes happen in Fedora dist-git - no builds. A pull request is created as a result.\nSupported triggers: release.\nOptional parameters:\n dist_git_branches - a (list of) branch(es) in dist-git where packit should work (defaults to main). You can also use the aliases provided by Packit to not need to change the config file when the new system version is released.  Example\njobs: - job: propose_downstream  trigger: release - job: propose_downstream  trigger: release  dist_git_branches:  - f35 This config would update Fedora Rawhide and Fedora 35 dist-git branches.\nIf you need to do any change in the pull request, you need to locally fetch the source branch of the Packit\u0026rsquo;s pull request and push it (with a fix) to your fork (as it is not possible to push to the branch created in the Packit\u0026rsquo;s fork):\ngit fetch ssh://$USER.fedoraproject.org/forks/packit/rpms/$YOUR_PACKAGE.git refs/heads/*:refs/remotes/packit/* git cherry-pick packit/$VERSION-$BRANCH-update-propose_downstream  pull_from_upstream #  A dist-git only job that opens a new dist-git pull request in src.fedoraproject.org when a new upstream release happens using a notification from release-monitoring.org.\nThis job utilizes the same logic as propose_downstream with the only exception that it is defined and executed in dist-git.\nUse issue_repository option to get information about possible failures during the update process.\nRequirements:\n The job is defined in a Packit config in the default branch of the dist-git repository (rawhide). Packit configs on other branches are ignored. Upstream release monitoring is active for the package. The monitoring status in dist-git should be set to Monitoring). upstream_project_url is defined in the configuration.  Upstreams (defined in upstream_project_url) hosted in these Git forges are currently supported: https://github.com, https://gitlab.com, https://gitlab.freedesktop.org, https://gitlab.gnome.org, https://salsa.debian.org. Support for working with upstreams in all Git forges is planned to be worked on shortly (see).  Supported triggers: release.\nOptional parameters:\n dist_git_branches - a (list of) branch(es) in dist-git where packit should work (defaults to main). You can also use the aliases provided by Packit to not need to change the config file when the new system version is released.  Example\nupstream_project_url: https://github.com/packit/packit ... jobs: - job: pull_from_upstream  trigger: release  dist_git_branches:  - fedora-all  - epel-9 Once a new upstream release happens, Packit will open a pull request with it in all active Fedora releases and EPEL 9.\nIf you need to do any change in the pull request, you need to locally fetch the source branch of the Packit\u0026rsquo;s pull request and push it (with a fix) to your fork (as it is not possible to push to the branch created in the Packit\u0026rsquo;s fork):\ngit fetch ssh://$USER.fedoraproject.org/forks/packit/rpms/$YOUR_PACKAGE.git refs/heads/*:refs/remotes/packit/* git cherry-pick packit/$VERSION-$BRANCH-update-pull_from_upstream  For more details, check our release guide.\nkoji_build #  Trigger the build in Fedora Koji build system as a reaction to a new dist-git commit. A Packit config file needs to be in the dist-git repository to allow this job to be triggered. Packit loads the config from the newly pushed commit.\nThe build is triggered only for commits with a spec-file change.\nBy default, only merged pull requests created by Packit are being acted upon so the proven packager workflow is preserved, details here. You can override this behaviour by specifying allowed_pr_authors and/or allowed_committers in the job configuration (see below). For direct pushes, the committer needs to be specified in the allowed_committers and for merged pull requests the author of the PR needs to be specified in the allowed_pr_authors .\nThere is no UI provided by Packit for the job, but it is visible across Fedora systems (as you can see in the following image). The koji build behaves as it was created manually, and you can utilise Fedora Notifications to be informed about the builds. Also, you can configure a repository where should we open issues in case of errors during the job via issue_repository configuration key.\nFor retriggering the job, see our release guide.\nFor Koji builds from upstream, see upstream_koji_build.\nSupported triggers:\n commit \u0026ndash; reacts to new commits to the specified branch (in dist-git)  Required parameters:\n dist_git_branches \u0026ndash; the name of the dist-git branch we want to build for when using commit trigger. You can also use the aliases provided by Packit to not need to change the config file when the new system version is released.  Optional parameters:\n scratch \u0026ndash; defaults to false, use to create scratch (test) builds instead of the real production builds allowed_pr_authors - a list of FAS accounts of PR authors whose merged pull requests will trigger koji builds (defaults to ['packit']). allowed_committers - a list of FAS accounts of committers whose pushes to dist-git will trigger koji builds (defaults to an empty list).  Example\njobs: - job: koji_build  trigger: commit  dist_git_branches:  - fedora-all  - epel-8 bodhi_update #  Create a new update in Fedora Bodhi for successful Koji build. A Packit config file needs to be in the dist-git repository to allow this job to be triggered. Packit loads the config from the commit the build is triggered from.\nFor now, the Bodhi update is created only for builds submitted by the Packit FAS user. (See koji_build job for more details on how to set this up.) This is just for the early stage of this job, and we can easily turn off that filter. Let us know if you need this condition to be removed.\nThere is no UI provided by Packit for the job, but it is visible across Fedora systems like a manually created Bodhi update, and you can utilise Fedora Notifications to tweak the notifications settings.\nFor retriggering the job, see our release guide.\nNote that this job is really new and not mature yet \u0026ndash; let us know if you find anything problematic or any improvement we can implement.\nSupported triggers:\n commit \u0026ndash; Packit uses the original action as a config trigger, so you need to use commit as a trigger. The real trigger is a successful Koji build (that was triggered from a commit).  Required parameters:\n dist_git_branches \u0026ndash; the name of the dist-git branch(es) the build we want to use is coming from. You can also use the aliases provided by Packit to not need to change the config file when the new system version is released.  Example\njobs: - job: bodhi_update  trigger: commit  dist_git_branches:  - fedora-stable # rawhide updates are created automatically  - epel-8 vm_image_build #  Supported triggers:\n pull_request  Image Parameters (Packit does not sanitize these and just passes them to Image Builder; check Image Builder\u0026rsquo;s API documentation for details).\n image_request \u0026ndash; values passed to the \u0026ldquo;image_requests\u0026rdquo; field of Image Builder\u0026rsquo;s API image_customizations \u0026ndash; values passed to the \u0026ldquo;customizations\u0026rdquo; field of Image Builder\u0026rsquo;s API image_distribution \u0026ndash; name of the \u0026ldquo;base image\u0026rdquo; (examples: rhel-90, fedora-36)  Required parameters:\n copr_chroot \u0026ndash; name of the chroot to use for installing packages in the image owner \u0026ndash; Copr project owner project \u0026ndash; Copr project name  Image builds are only triggered after a collaborator places a comment /packit vm-image-build in a pull request. The image builds are NOT submitted automatically. This is a subject to change as we improve the integration in future.\nExample\njobs: - job: vm_image_build  trigger: pull_request  image_request:  architecture: x86_64  image_type: aws  upload_request:  type: aws  options:  share_with_accounts: [\u0026#34;123456789\u0026#34;]  image_customizations:  packages: [foo-bar]  image_distribution: fedora-36  owner: john-foo  project: foo-bar-martini  copr_chroot: fedora-36-x86_64 User configuration file #  When running packit as a tool locally, it is convenient to use a configuration file to provide data such as API tokens. Packit respects XDG_CONFIG_HOME environment variable. If not set, it looks inside ~/.config/ directory.\nThe acceptable names are the same as for the package config:\n .packit.yaml .packit.yml .packit.json packit.yaml packit.yml packit.json  Values #     Key name Type Description     debug bool enable debug logs   fas_user string username in Fedora account system; this is utilized when authenticating with Bodhi using Kerberos   kerberos_realm string Kerberos realm to use for authentication, example \u0026ldquo;FEDORAPROJECT.ORG\u0026rdquo;   authentication dict tokens for services (GitHub, Pagure)   upstream_git_remote string name of the git remote to discover upstream project URL from   redhat_api_refresh_token string Red Hat API token, can be obtained here    The authentication is a dictionary where:\n key is a hostname, url or name that can be mapped to a service-type, for example github.com or pagure value is a dictionary with keys: token and instance_url (optional)  e.g.:\nauthentication:  github.com:  token: mnbvcxz123456  pagure:  token: qwertyuiop098765  instance_url: https://src.fedoraproject.org The GitHub token is needed when packit interacts with GitHub API, get it at https://github.com/settings/tokens (getting full read \u0026amp; write repo scope should be enough). The Pagure token needed to access REST API, get it at https://src.fedoraproject.org/settings#nav-api-tab\nSpecifying tokens as direct keys github_token and pagure_user_token has been deprecated and will be removed in future versions.\nSince API tokens are a very sensitive information, please do NOT ever store them in a public (such as a GitHub repository). The configuration file here is located on your workstation, please do NOT confuse it with a config file for your project - that one is described above in the first section of this document.\n"}),e.add({id:20,href:"/docs/cli/propose-downstream/",title:"propose-downstream",section:"Packit CLI",content:"packit propose-downstream #  This is a detailed documentation for the update functionality of packit. The command creates a new pull request in Fedora using a selected or latest upstream release.\nRequirements #   Upstream git repository on GitHub. Upstream release (read, git tag) where version in spec file is equivalent to the name of the git tag. Packit config file placed in the upstream repository. Spec file present in the upstream repository and is correct in a given release. Pagure API tokens for Fedora Dist-git. GitHub API token. Valid Fedora Kerberos ticket.  Tutorial #    Place a file called .packit.yaml or packit.yaml in the root of your upstream repository.\n The configuration is described in this document. Please get inspired from an existing config.    Place a spec file into your upstream project (and make sure that specfile_path in the config has a correct value).\n This spec file will be then used to perform the update in Fedora. When you create a new upstream release, you should also update the spec file. Once your upstream release is out (and the spec file is really up to date), you can use packit to release it into Fedora.    Create a new upstream release. The spec file needs to be included in the ref for upstream release, because packit checks out the tag for the upstream release before copying files downstream.\n  Once you have performed the upstream release (and the new archive is up), run packit propose-downstream in a working directory of your upstream repository:\n$ git clone https://github.com/user-cont/colin.git $ cd colin $ packit propose-downstream using \u0026#34;master\u0026#34; dist-git branch syncing ./colin.spec INFO: Downloading file from URL https://files.pythonhosted.org/packages/source/c/colin/colin-0.3.0.tar.gz 100%[=============================\u0026gt;] 3.18M eta 00:00:00 downloaded archive: /tmp/tmpaanrpgjz/colin-0.3.0.tar.gz uploading to the lookaside cache PR created: https://src.fedoraproject.org/rpms/colin/pull-request/4 As you can see, one of the things propose-downstream does is, it downloads the upstream release tarball and uploads it to the lookaside cache. This is required by the Fedora Packaging Guidelines. Then it copies the files listed in files_to_sync (which by default includes the spec file) from the upstream repo to downstream and creates the downstream PR.\n  Help #  Usage: packit propose-downstream [OPTIONS] [PATH_OR_URL] [VERSION] Land a new upstream release in Fedora. PATH_OR_URL argument is a local path or a URL to the upstream git repository, it defaults to the current working directory VERSION argument is optional, the latest upstream version will be used by default Options: --dist-git-branch TEXT Comma separated list of target branches in dist-git to release into. (defaults to all branches) --dist-git-path TEXT Path to dist-git repo to work in. Otherwise clone the repo in a temporary directory. --local-content Do not checkout release tag. Use the current state of the repo. This option is set by default for source-git repos --force-new-sources Upload the new sources also when the archive is already in the lookaside cache. --no-pr Do not create a pull request to downstream repository. --upstream-ref TEXT Git ref of the last upstream commit in the current branch from which packit should generate patches (this option implies the repository is source-git). -f, --force Don't discard changes in the git repo by default, unless this is set. -h, --help Show this message and exit.  "}),e.add({id:21,href:"/docs/cli/",title:"Packit CLI",section:"User Documentation",content:"Packit CLI #  Installation #  There are various ways how to install packit CLI. Pick what suits you the best:\nFedora Linux #  $ sudo dnf install packit  Red Hat Enterprise Linux or CentOS Stream 8 #  On RHEL/CentOS 8 you can install RPM from EPEL repository. On CentOS, some dependencies are in PowerTools repository, so you have to enable it:\n$ sudo dnf install dnf-plugins-core epel-release $ sudo dnf config-manager --set-enabled powertools $ sudo dnf install packit  Via Fedora COPR #  You can also help us test the latest development snapshot by installing packit built from the main branch in Copr:\n$ sudo dnf copr enable packit/packit-dev $ sudo dnf install packit $ # OR in case you have packit already installed from the Fedora repositories: $ sudo dnf upgrade packit  From PyPI #  We publish packit to PyPI and it\u0026rsquo;s available as packitos project — packit at PyPI is something different.\n$ pip install --user packitos  From Source #  \u0026hellip; or installing it directly from GitHub:\n$ pip install --user git+https://github.com/packit/packit  In a container #  If none of the above work for you, try running it in a container from our Fedora based image. It contains packit installed from main branch, i.e. the same you\u0026rsquo;d get by pip installing from GitHub.\n$ podman run -ti --rm -v $PWD:/src:z quay.io/packit/packit bash $ packit Usage: packit [OPTIONS] COMMAND [ARGS]...  Depending on the command you want to perform you need to mount secrets and configuration files, like in the following examples:\nCopr build #  $ podman run -ti --rm -v ~/.config/copr:/root/.config/copr:z -v $PWD:/src:z quay.io/packit/packit bash $ packit build in-copr  Koji build #  $ podman run -ti --rm -v ~/.ssh/:/root/.ssh:z -v $PWD:/src:z quay.io/packit/packit bash $ fkinit -u \u0026lt;Fedora Account username\u0026gt; $ packit build in-koji  Commands #   build create-update init propose-downstream push-updates srpm status sync-from-downstream validate-config source-git init source-git update-dist-git source-git update-source-git source-git status  "}),e.add({id:22,href:"/docs/cli/srpm/",title:"srpm",section:"Packit CLI",content:"packit srpm #  Create a SRPM of the present content in the upstream repository.\nBy default, packit uses git describe --tags --match '*.*' to create a unique version of the snapshot and git archive -o \u0026quot;{package_name}-{version}.tar.gz\u0026quot; --prefix \u0026quot;{package_name}-{version}/\u0026quot; HEAD to create a tarball with upstream sources.\nYou can override the archive and version commands in packit.yaml, e.g. this is what we use in ogr, a library which packit is using:\nactions:  create-archive:  - python3 setup.py sdist --dist-dir ./fedora/  - bash -c \u0026#34;ls -1t ./fedora/*.tar.gz | head -n 1\u0026#34;  get-current-version: python3 setup.py --version Requirements #   Upstream project is using git. Packit config file placed in the upstream repository.  Tutorial #    Place a config file for packit in the root of your upstream repository..\n  Now we would generate a SRPM for ogr project:\n$ packit srpm Version in spec file is \u0026#34;0.0.3\u0026#34;. SRPM: /home/tt/g/user-cont/ogr/python-ogr-0.0.4.dev11+gc9956c9.d20190318-1.fc29.src.rpm We can now build the package:\n$ rpmbuild --rebuild /home/tt/g/user-cont/ogr/python-ogr-0.0.4.dev11+gc9956c9.d20190318-1.fc29.src.rpm Installing /home/tt/g/user-cont/ogr/python-ogr-0.0.4.dev11+gc9956c9.d20190318-1.fc29.src.rpm Executing(%prep): /bin/sh -e /var/tmp/rpm-tmp.95VZ3c + umask 022 + cd /home/tt/rpmbuild/BUILD + cd /home/tt/rpmbuild/BUILD + rm -rf ogr-0.0.4.dev11+gc9956c9.d20190318 + /usr/bin/gzip -dc /home/tt/rpmbuild/SOURCES/ogr-0.0.4.dev11+gc9956c9.d20190318.tar.gz + /usr/bin/tar -xof - + STATUS=0 ... Executing(%build): /bin/sh -e /var/tmp/rpm-tmp.aYyTMP ... Executing(%install): /bin/sh -e /var/tmp/rpm-tmp.fotlPv ... + exit 0 Provides: python3-ogr = 0.0.4.dev11+gc9956c9.d20190318-1.fc29 python3.7dist(ogr) = 0.0.4.dev11+gc9956c9.d20190318 python3dist(ogr) = 0.0.4.dev11+gc9956c9.d20190318 Requires(rpmlib): rpmlib(CompressedFileNames) \u0026lt;= 3.0.4-1 rpmlib(FileDigests) \u0026lt;= 4.6.0-1 rpmlib(PartialHardlinkSets) \u0026lt;= 4.0.4-1 rpmlib(PayloadFilesHavePrefix) \u0026lt;= 4.0-1 Requires: python(abi) = 3.7 python3.7dist(gitpython) python3.7dist(libpagure) python3.7dist(pygithub) python3.7dist(python-gitlab) Checking for unpackaged file(s): /usr/lib/rpm/check-files /home/tt/rpmbuild/BUILDROOT/python-ogr-0.0.4.dev11+gc9956c9.d20190318-1.fc29.x86_64 Wrote: /home/tt/rpmbuild/RPMS/noarch/python3-ogr-0.0.4.dev11+gc9956c9.d20190318-1.fc29.noarch.rpm + exit 0   Help #  Usage: packit srpm [OPTIONS] [PATH_OR_URL] Create new SRPM (.src.rpm file) using content of the upstream repository. PATH_OR_URL argument is a local path or a URL to the upstream git repository, it defaults to the current working directory Options: --output FILE Write the SRPM to FILE instead of current dir. --upstream-ref TEXT Git ref of the last upstream commit in the current branch from which packit should generate patches (this option implies the repository is source-git). -h, --help Show this message and exit.  As you can see, it is possible to create SRPM for source-git repositories as well. Just add an --upstream-ref option to the packit command.\nIf you have a git tag 0.1.0 specifying the upstream code, just run packit srpm --upstream-ref 0.1.0 to create an SRPM file. It will create an archive from the given upstream reference (0.1.0) and following commits will be added as downstream patches.\nJust make sure, that you apply all the patches in the specfile. (Packit only adds the patches after the sources.) You can use a following setup:\n  Define the macro on top of the specfile:\n%global num_patches %{lua: c=0; for i,p in ipairs(patches) do c=c+1; end; print(c);}   Apply the patches in the %prep part:\n%if %{num_patches} git init git config user.email \u0026#34;noreply@example.com\u0026#34; git config user.name \u0026#34;John Foo\u0026#34; git add . git commit -a -q -m \u0026#34;%{version} baseline.\u0026#34; # Apply all the patches. git am %{patches} %endif   "}),e.add({id:23,href:"/docs/cli/prepare-sources/",title:"prepare-sources",section:"Packit CLI",content:"packit prepare-sources #  Prepares sources for a new SRPM build using the content of the upstream repository. Applies the same as for packit srpm, but instead of building a SRPM in the end, prepared sources are moved to the result-dir.\nRequirements #   Upstream project is using git. Packit config file placed in the upstream repository.  Help #  Usage: packit prepare-sources [OPTIONS] [PATH_OR_URL] Prepare sources for a new SRPM build using content of the upstream repository. Determine version, create an archive or download upstream and create patches for sourcegit, fix/update the specfile to use the right archive, download the remote sources. Behaviour can be customized by specifying actions (post-upstream-clone, get-current-version, create- archive, create-patches, fix-spec-file) in the configuration. PATH_OR_URL argument is a local path or a URL to the upstream git repository, it defaults to the current working directory Options: --result-dir DIR Copy the sources into DIR. By default, `prepare_sources_result` directory in the current working directory is created. --upstream-ref TEXT Git ref of the last upstream commit in the current branch from which packit should generate patches (this option implies the repository is source-git). --update-release / --no-update-release Specifies whether to update Release. Defaults to value set in configuration, which defaults to yes. --bump / --no-bump Deprecated. Use --[no-]update-release instead. --release-suffix TEXT Specifies release suffix. Allows to override default generated:{current_time}.{sanitized_ current_branch}{git_desc_suffix} --default-release-suffix Allows to use default, packit-generated, release suffix when some release_suffix is specified in the configuration. --job-config-index INTEGER Internal option to override package config found in the repository with job config with given index (needed for packit service). --ref TEXT Git reference to checkout. --pr-id TEXT Specifies PR to checkout. --merge-pr / --no-merge-pr Specifies whether to merge PR into the base branch in case pr-id is specified. --target-branch TEXT Specifies target branch which PR should be merged into. --create-symlinks / --no-create-symlinks Specifies whether Packit should create symlinks or copy the files (e.g. archive outside specfile dir). -h, --help Show this message and exit.  "}),e.add({id:24,href:"/docs/actions/",title:"Actions",section:"User Documentation",content:"Actions #  You can probably find yourself in a situation where some part of the packit workflow needs to be tweaked for your package.\nPackit supports actions, which can be used to change the default implementation of some steps in the workflow. Packit is able to execute multiple commands for a single action. Each action accepts a list of commands. By default, the commands are executed using python\u0026rsquo;s subprocess module without shell. If you need a shell (e.g. you want to utilize an environment variable, subprocesses, pipelines, expansion or any shell syntax in your command), just wrap your command in a bash process:\nbash -c \u0026#34;my fancy $command| grep success\u0026#34;  It\u0026rsquo;s important to quote the content of the -c option so shell interprets it correctly as a single option input.\n All actions are also executed inside Packit Service. The service creates a new sandbox environment where the command is run.\nActions have a default behaviour which you can override, hooks don\u0026rsquo;t have any - hooks are a way for you to perform operations following a certain packit event, e.g. cloning an upstream repo.\nCurrently, these are the actions you can use:\nCommand matrix #  Syncing the release #  These apply to propose-downstream command/job and pull-from-upstream job.\n    name working directory when run description     [hook] post-upstream-clone upstream git repo after cloning of the upstream repo (main) and before other operations    [hook] pre-sync upstream git repo after cloning and checkout to the correct (release) branch     prepare-files upstream git repo after cloning, checking out of both upstream and dist-git repos replace patching and archive generation    create-patches upstream git repo after sync of upstream files to the downstream replace patching    get-current-version upstream git repo when the current version needs to be found expect version as a stdout parameter    changelog-entry upstream git repo when adding a new changelog entry to the specfile stdout is used as a changelog entry    Creating SRPM #  These apply to the srpm command and building in COPR.\n    name working directory when run description     [hook] post-upstream-clone upstream git repo after cloning of the upstream repo (main) and before other operations     get-current-version upstream git repo when the current version needs to be found expect version as a stdout    create-archive upstream git repo when the archive needs to be created replace the code for creating an archive    create-patches upstream git repo after sync of upstream files to the downstream replace patching    fix-spec-file upstream git repo after creation of a tarball and before running rpmbuild command this action changes spec file to use the new tarball    changelog-entry upstream git repo when adding a new changelog entry to the specfile stdout is used as a changelog entry    Actions details #  All actions are executed in a locked-down OpenShift pod. Your commands are invoked with arbitrary UIDs from a high range. Some tools may experience problems with these UIDs, such as tar. You can observe an error like this:\ntar: value 1021440000 out of uid_t range 0..2097151 tar: Exiting with failure status due to previous errors For tar, it\u0026rsquo;s recommended to use the pax format (tar -H pax).\nIf you run into similar issues with other tools, please consult documentation or maintainers of the project.\ncreate-archive #  It is expected to return a relative path within the repository to the generated archive. If there are more steps, then one of them has to return the archive name. The best practice is to do it from the last step and print it: bash -c 'echo path/to/archive-$VERSION.tar.gz'.\nIf you can, please place the generated archive in the same directory as your spec file.\nIf your project uses multiple archives, you should handle manipulation of your spec file yourself in the fix-spec-file action. You also have to put all the archives (spec file sources) in the same directory as your spec file. Packit expects that project only have a single archive set as Source0 — it does not have a mechanism to manipulate more sources right now.\nfix-spec-file #  By default, this action updates the spec file so it\u0026rsquo;s possible to have a proper reference of the archive in the %prep section and unpack it during the build properly. The action tries to perform 3 operations on a spec file:\n  It replaces Source configured by spec_source_id (default Source0) with a local path to the generated archive.\n  It changes the first %setup (or %autosetup) macro in %prep and adds -n so the generated tarball can be unpacked (it tries to extract the directory name directly from the archive or uses the configured archive_root_dir_template).\n  It updates Version and Release in the spec file.\n  If you provide your own implementation, none of the above happens.\nFor example a package may define multiple Sources. In such a case, the default implementation of fix-spec-file won\u0026rsquo;t be able to update %prep correctly. You can instead use the sed program to set the new Sources correctly, e.g.\nactions:  fix-spec-file:  # define one of the Source variables correctly  - sed -i my_specfile_path -e \u0026#34;s/https.*only-vendor.tar.xz/my_correct_tarball_path/\u0026#34;  # fill in Release as if packit would have done it  - bash -c \u0026#34;sed -i -r \\\u0026#34;s/Release:(\\s*)\\S+/Release:\\1${PACKIT_RPMSPEC_RELEASE}%{?dist}/\\\u0026#34; my_specfile_path\u0026#34; Environment variables set by packit #  Additionally, packit sets a few env vars for specific actions.\nfix-spec-file\nPACKIT_PROJECT_VERSION — current version of the project (coming from git describe)\nPACKIT_PROJECT_COMMIT — commit hash of the top commit\nPACKIT_PROJECT_ARCHIVE — expected name of the archive\nPACKIT_RPMSPEC_RELEASE — value for spec file\u0026rsquo;s %release field which packit would set\ncreate-archive\nPACKIT_PROJECT_VERSION — current version of the project (coming from git describe) PACKIT_PROJECT_NAME_VERSION — current name and version of the project (coming from git describe)\nchangelog-entry\nPACKIT_PROJECT_VERSION — version to be set in the specfile, set when relevant (e.g. when syncing upstream release downstream)\nIf you want to see the content of those variables, you can print using echo in the specific action:\nactions:  fix-spec-file:  - bash -c \u0026#34;echo PACKIT_PROJECT_VERSION=${PACKIT_PROJECT_VERSION}\u0026#34; and then make sure to run packit with the --debug option:\n$ packit --debug srpm ... 2021-09-15 09:01:36.821 commands.py DEBUG Command: bash -c echo PACKIT_PROJECT_VERSION=${PACKIT_PROJECT_VERSION} 2021-09-15 09:01:36.826 logging.py INFO PACKIT_PROJECT_VERSION=0.14.0  Actions can be defined like this in your .packit.yaml:\nspecfile_path: package.spec files_to_sync:  - packit.yaml  - package.spec upstream_package_name: package downstream_package_name: package dist_git_url: https://src.fedoraproject.org/rpms/package.git actions:  prepare-files: \u0026#34;make prepare\u0026#34;  create-archive:  - \u0026#34;make archive\u0026#34;  - bash -c \u0026#34;ls -1 ./package-*.tar.gz\u0026#34;  changelog-entry:  - echo \u0026#34;New release ${PACKIT_PROJECT_VERSION}\u0026#34; "}),e.add({id:25,href:"/docs/cli/sync-from-downstream/",title:"sync-from-downstream",section:"Packit CLI",content:"packit sync-from-downstream #  This is a detailed documentation for the downstream sync functionality of packit. The command creates a new pull request in upstream repository using a selected branch (main by default) from Fedora dist-git repository.\nRequirements #   Fedora dist-git repository. Packit config file placed in the upstream repository. Pagure API tokens for Fedora Dist-git. GitHub API token.  Tutorial #   Starting with packit 0.5.2 and later, you only need to set a single token to interact with dist-git. You needed two in the past. Please populate your local config at ~/.config/packit.yaml for packit so it can talk to the remote services:  # you can obtain the token over here: https://github.com/settings/tokens github_token: 123 # and this one right here: https://src.fedoraproject.org/settings#nav-api-tab pagure_user_token: 456   The files which are synced are listed in .packit.yaml under the files_to_sync configuration key.\n  Once you want to sync Fedora dist-git repo into the upstream repo, run packit sync-from-downstream in a working directory of your upstream repository:\n  $ git clone https://github.com/user-cont/colin.git $ cd colin $ packit sync-from-downstream upstream active branch master Cloning repo: https://src.fedoraproject.org/rpms/colin.git -\u0026gt; /tmp/tmph9npe78e using master dist-git branch syncing /tmp/tmph9npe78e/colin.spec PR created: https://api.github.com/repos/phracek/colin/pulls/3 packit sync-from-downstream \u0026ndash;help #  Usage: packit sync-from-downstream [OPTIONS] [PATH_OR_URL] Copy synced files from Fedora dist-git into upstream by opening a pull request. PATH_OR_URL argument is a local path or a URL to the upstream git repository, it defaults to the current working directory Options: --dist-git-branch TEXT Comma separated list of target branches in dist-git to sync from. (defaults to repo's default branch) --upstream-branch TEXT Target branch in upstream to sync to. (defaults to repo's default branch) --no-pr Do not create a pull request to upstream repository. --fork / --no-fork Push to a fork before creating a pull request. --remote-to-push TEXT Name of the remote where packit should push. If this is not specified, push to a fork if the repo can be forked. -f, --force Don't discard changes in the git repo by default, unless this is set. -x, --exclude TEXT File to exclude from sync -h, --help Show this message and exit.  "}),e.add({id:26,href:"/docs/fedora-releases-guide/",title:"How to do Fedora releases with Packit",section:"User Documentation",content:"How to do Fedora releases with Packit #  Let\u0026rsquo;s split the release process into single steps:\n New upstream release Upload archive to lookaside cache Update dist-git content Koji builds Bodhi updates  Doing Fedora releases with Packit means utilising these jobs:\n propose_downstream or pull_from_upstream koji_build bodhi_update  Every job takes care of a different part of the release process.\nPropose downstream job #  For enabling the propose downstream job, you need to have Packit Service installed and have a propose_downstream job in the configuration file for the given upstream repository (this job is also run by default if there is no jobs section in the configuration, see jobs configuration). The propose_downstream job should be then configured like this:\njobs: - job: propose_downstream  trigger: release  dist_git_branches:  - main You can adjust the dist_git_branches field to include the dist-git branches you want to update and also utilise aliases instead of using hardcoded versions.\nNew upstream release #  The process of releasing a new version starts in the upstream repository by creating a new upstream release. Packit gets the information about the newly created release (not a git tag) from GitHub, loads the config from the release commit and if there is a propose_downstream job defined, the workflow begins.\nUpload archive to lookaside cache #  The upstream archive needs to be downloaded by Packit first and then uploaded to the lookaside cache. By default, Packit downloads sources defined in the specfile that contain URLs. You can override these URLs via sources configuration key.\nFor Python packages, you can use a GitHub action (example setup of Packit itself) that automatically builds and uploads the archive to PyPI on each new release. Then during propose downstream, Packit tries to download the archive from the provided URL. If the download fails because the upstream archive is not available at the time of running the job, the job is scheduled to be retried later.\nUpdate dist-git content #  After saving the archive in the lookaside cache, Packit updates the dist-git content (mainly sources file and spec file) via pull requests for the specified branches. You can configure which files in the upstream repo should be copied to dist-git during an update via files_to_sync configuration key.\nThe version in the spec file is set to the version that Packit gets from the upstream tag corresponding to the release that triggered the job. If the version and tag differ, you can specify the upstream_tag_template configuration option so that Packit can extract the correct version.\nIf you use copy_upstream_release_description: true, the changelog entry will use the GitHub release description field. (Just make sure the formatting is compatible with spec file. E.g. use - instead of * for lists to not create multiple changelog entries.) There is also sync_changelog configuration option to enable syncing the whole changelog.\nDuring proposing a new update, you will get updates of the job status via commit statuses/checks on the release commit. These will provide links to our dashboard where you can find all the information about the job including the logs. You can also check all propose downstream runs in this view.\nAfter Packit successfully creates the dist-git pull requests, it\u0026rsquo;s on downstream CI systems and maintainer(s) to check the changes and merge the pull requests.\nRetriggering #  Users with write or admin permissions to the repository can retrigger an update via a comment in any open issue in the upstream repository:\n/packit propose-downstream  Pull from upstream job #  [NEW] Starting January 2023, we have provided a new way to get fresh upstream releases in Fedora Linux.\nThe pull_from_upstream job is defined in dist-git only and provides the propose_downstream functionality. This means that Packit doesn\u0026rsquo;t need to be set up in the upstream project: everything is configured in Fedora dist-git. So when a new upstream release happens and release-monitoring.org detects it, you\u0026rsquo;ll get dist-git pull requests with it automatically.\nFor customization of the job, you may need to define additional configuration options, most commonly:\n If the version from release monitoring and Git tag differ, you should specify the upstream_tag_template. You can configure which files (if any) in the upstream repo should be copied to dist-git during an update via files_to_sync configuration key. By default, Packit downloads sources defined in the spec file that contain URLs. You can override these URLs via sources configuration key. You may utilise some of the actions for overriding the Packit default behaviour, for example:   for the changelog entry generation, if you do not want the default git log output, you can use your own command(s):\nchangelog-entry: echo \u0026quot;New release ${PACKIT_PROJECT_VERSION}\u0026quot;      You can check all the job runs with details and logs in this view. You can also configure a repository where we should open issues in case of errors during the job via issue_repository configuration key.\nKoji build job #  After having the dist-git content updated, you can easily automate also building in Koji. You can simply configure Packit to react to the new commits in your dist-git repository and create Koji builds by having a Packit configuration (when using propose_downstream job, you can configure Packit to sync the file) in your dist-git repository that includes a koji_build job. Then, if Packit is informed (via fedora-messaging bus) about a new commit in the configured dist-git branch, it submits a new build in Koji like maintainers usually do. (The commits without any spec file change are skipped.)\nBy default, only merged pull requests created by Packit are being acted upon, but you can override this behaviour by specifying allowed_pr_authors and/or allowed_committers in the job configuration.\nThe koji_build job can be configured like this:\njobs: - job: koji_build  trigger: commit  dist_git_branches:  - fedora-all There is no UI provided by Packit for the job, but it is visible across Fedora systems (as you can see in the following image). The koji build behaves as it was created manually, and you can utilise Fedora Notifications to be informed about the builds. Also, you can configure a repository where should we open issues in case of errors during the job via issue_repository configuration key.\nRetriggering #  You can retrigger a build by a comment in a dist-git pull request:\n/packit koji-build  The build will be triggered for the target branch of the pull request. The user who posts this comment needs to be a packager.\nIf Packit created an issue in the configured issue_repository, you can place the same comment in that issue to retrigger the builds (see issue_repository for details).\nBodhi update job #  Lastly, you can again similarly to Koji builds, configure Packit to react to successful Koji builds and create Bodhi updates by having a Packit configuration in your dist-git repository that includes a bodhi_update job. Once Packit is informed (via fedora-messaging bus) about the successful Koji build for the configured branch, it creates a new update for that branch in Bodhi for you.\nThe bodhi_update job can be configured like this:\njobs: - job: bodhi_update  trigger: commit  dist_git_branches:  - fedora-branched # rawhide updates are created automatically The packit config is loaded from the commit the build is triggered from. The issue_repository configuration key mentioned in the Koji build job applies here as well.\nRetriggering #  You can retrigger an update by a comment in a dist-git pull request:\n/packit create-update  The update will be triggered for the target branch of the pull request. The user who posts this comment needs to be a packager and have write access to the dist-git repository.\nIf Packit created an issue in the configured issue_repository, you can place the same comment in that issue to retrigger the updates (see issue_repository for details).\n"}),e.add({id:27,href:"/docs/service-level-objectives/",title:"Service Level Objectives",section:"User Documentation",content:"Service Level Objectives #  Packit is using the concept of Service level objectives defined in Google\u0026rsquo;s SRE book. It means that when we run out of error budget, we stop all the work on new features and start stabilizing the service to get our budget back.\nWe have 3 objectives defined for Packit right now.\nScreenshots below are not being updated in real time. They are just a snapshot of the state in time when this document was written so that you can see some actual numbers.\nSLO1: Changes to GitHub PRs receive the first status update within 15 seconds in 99% of cases #  We want you to know as soon as possible that Packit is working on your request.\nSLO2: 98% of builds have status set to success or failure within 5 minutes after the Copr build has finished #  Once Packit works on a build, you should see that the work is done within a reasonable time.\nSLO3: 95% of test runs have status set to success or failure within 12 hours #  The same as SLO2 except this is for tests. Testing Farm is a more complex system so we reduced the number here.\nIf you are interested, here\u0026rsquo;s the accompanying research: github.com/packit/research/../error-budgets\nUnfortunately, we cannot share our Grafana instance with you since it\u0026rsquo;s hidden behind a firewall.\n"}),e.add({id:28,href:"/docs/reproduce-locally/",title:"Reproduce CI environment locally",section:"User Documentation",content:"Reproduce CI environment locally #  This used to be a question in our FAQ and now we have a dedicated document to cover this.\nSRPM builds locally #  $ packit srpm Packit will create a SRPM out of the current checkout. Simple and clear.\nSRPM builds in Copr #  When your SRPM is being built in Copr (because srpm_build_deps is set in your packit config, or you installed Packit GitHub application after September 6, 2022), this section describes how you can reproduce the build procedure locally.\nWe invoke our CLI command packit prepare-sources in the Copr environment, the command may look like this for a job triggered by a pull request change:\n$ packit prepare-sources --result-dir directory-to-place-sources --pr-id 150 --merge-pr --target-branch main --job-config-index 2 https://github.com/packit/packit As a first step, you can run this command locally on your computer (if you have installed the needed dependencies for your actions) and see whether the sources are correctly prepared.\nThankfully, Copr is very transparent how it performs builds. When you open a build log (e.g. builder-live.log.gz), you\u0026rsquo;ll see a command at the top which Copr invokes to perform a build. Let\u0026rsquo;s do that in a container.\n$ podman run --privileged -ti fedora:36 bash (the reason for running root privileged container is that mock will be used inside and needs capabilities to perform unshare)\nBut first we need to install the package which contains the copr-rpmbuild command:\n[root@f26be2947a15 /]# dnf install -y copr-rpmbuild Now let\u0026rsquo;s rerun locally a build for build-id 3580313:\n[root@f26be2947a15 /]# /usr/bin/copr-rpmbuild --verbose --drop-resultdir --srpm --build-id 3580313 Your changes need to be pushed and a PR needs to be created for this to work. You are welcome to experiment with copr-rpmbuild to get a more efficient workflow (hint --task-file).\nSRPM builds in our sandbox #  Packit by default runs all commands you defined in a sandbox which is a kubernetes pod in a new project. If you need additional packages or binaries present in the sandbox, you should migrate your SRPM builds to be done in Copr using srpm_build_deps.\nYou can reproduce our sandbox environment: Firstly, you should pull our production sandbox image and run commands of your choice inside the container. As an example, this is how we were debugging build problems with anaconda:\n  Clone your upstream git repo.\n  Launch the container and bind-mount the upstream project inside:\n  $ podman run -ti --rm --memory 768MB -v $PWD:/src -w /src quay.io/packit/sandcastle:prod bash Run commands of your choice:  [root@4af5dbd9c828 src]# ./configure checking for a BSD-compatible install... /usr/bin/install -c checking whether build environment is sane... yes checking for a thread-safe mkdir -p... /usr/bin/mkdir -p checking for gawk... gawk checking whether make sets $(MAKE)... yes checking whether make supports nested variables... yes checking whether UID \u0026#39;0\u0026#39; is supported by ustar format... yes checking whether GID \u0026#39;0\u0026#39; is supported by ustar format... yes checking how to create a ustar tar archive... gnutar checking whether make supports nested variables... (cached) yes checking whether make supports the include directive... yes (GNU style) checking for gcc... gcc checking whether the C compiler works... yes ... Our deployment is running in OpenShift ROSA.\nSince OpenShift invokes pods using arbitrary UIDs and as you can see, the command above is invoked as root, it does not match production packit-service. So, if running a local container didn\u0026rsquo;t help you with reproducing the issue, you can try running it in openshift.\nHere is a simple python code how packit-service does it:\nfrom sandcastle import Sandcastle  # this should be the path to your local clone of the upstream project git_repo_path: str = \u0026#34;fill-me\u0026#34; # kubernetes namespace to use k8s_namespace: str = \u0026#34;myproject\u0026#34; command = [\u0026#34;your\u0026#34;, \u0026#34;command\u0026#34;, \u0026#34;of\u0026#34;, \u0026#34;choice\u0026#34;]  # This is how your code gets copied (via rsync) into the openshift pod m_dir = MappedDir(git_repo_path, \u0026#34;/sandcastle\u0026#34;, with_interim_pvc=True)  o = Sandcastle(  image_reference=\u0026#34;docker.io/usercont/sandcastle:prod\u0026#34;,  k8s_namespace_name=k8s_namespace,  mapped_dir=m_dir ) o.run() try:  output = o.exec(command=command)  print(output) finally:  o.delete_pod() This script requires:\n sandcastle installed being logged in an openshift cluster (oc whoami to confirm) rsync binary available  If none of these helped you, please reach out to us and we\u0026rsquo;ll try to help you.\nTesting Farm #  When you open test results, you can see commands which Testing Farm performed to run your test. You can run those locally.\nThe team is also planning to have a solution to fully reproduce the CI testing process locally: teemtee/tmt#1075.\n"}),e.add({id:29,href:"/source-git/work-with-source-git/update-spec/",title:"Update a spec file",section:"Working with source-git",content:"Update a spec file #  Changing a spec file is very straightforward:\n Edit the file. Commit the change locally.   Please make sure that your change complies with Fedora Packaging Guidelines if you intend to bring it to the Fedora ecosystem.\n Once that\u0026rsquo;s done, it\u0026rsquo;s a great practice to create a SRPM and build the spec file change locally.\nIf you are planning to pull an upstream fix, you can read more here.\n"}),e.add({id:30,href:"/source-git/work-with-source-git/",title:"Working with source-git",section:"Source-git",content:"Working with source-git #  For the design concept of source-git, please read here. These pages are focused on how to work source-git repositories using the packit CLI.\n Create a source-git repo Updating a spec file Pulling fixes from upstream Controlling patch generation Building current source-git checkout locally Proposing your source-git content to dist-git Sync back changes made in dist-git Fix diverged history  "}),e.add({id:31,href:"/docs/archive-not-matching-git/",title:"Generated code in upstream archives",section:"User Documentation",content:"When the release archive does not match the upstream git tag checkout #  This document covers a scenario when an upstream project has a script to create release archives and some of the code in the archive is generated. This means that when a downstream distribution has patches of the generated code those patches can\u0026rsquo;t be applied in the upstream repo.\nThe solution #  The provided solution will be performed in a source-git repository.\nWhen all your downstream patches apply cleanly on top of the upstream git repo for the particular git tag, then all is good, and you don\u0026rsquo;t need anything special. You can follow the guide for the source-git init command to create such a source-git repo.\nThere is an issue when the patches require running tooling to regenerate code. Some upstream projects even use tooling which is not available downstream. Sadly, packit is unable to magically solve this scenario. If you cannot regenerate the code downstream, there is nothing that packit can offer. Alternatively you can fork the upstream project and start producing your own tarballs with patches of your choice - packit can help with setting this up, automate testing and the release process.\nAnother variant of this problem is when you need to patch code which is not present in the upstream repo and is present in the release tarball. It means your downstream patches (of the generated code) would not apply within the upstream repo.\nThere are two solutions to this:\n  Use upstream git history, patch regular sources instead and regenerate code in %prep.\n  Create additional commit with changes (run autogen.sh, generate documentation, etc.) so that you can apply the downstream patches.\n  Create the source-git repo from the tarball, not using the upstream git history.\n  Variant 1 #  This still follows the regular source-git repo. The problem may be when regenerating the does not fix the original problem or creates new problems - and you\u0026rsquo;ll really need to patch the generated sources.\nIn such a case, you should follow \u0026ldquo;Variant 3\u0026rdquo; since the code you need to patch is not present in the upstream repo.\nVariant 2 #  It\u0026rsquo;s a manual step to make which ensures that you still have upstream history and at the same time you can comfortably work with the package in the downstream.\nTo make packit ignore commits (so they are not generated as new downstream patches), just append a new line to the commit message:\nignore: true Variant 3 #  There is a tool to achieve this within the packit project: dist-git-to-source-git. Thought this tool was mainly used by the packit team and was not meant to be used outside the team, please reach out and the team will be happy to assist you.\n"}),e.add({id:32,href:"/docs/cli/status/",title:"status",section:"Packit CLI",content:"packit status #  This command displays latest information related to the project - downstream pull requests, upstream releases, builds in Koji and Copr and updates in Bodhi.\nHelp #  Usage: packit status [OPTIONS] [PATH_OR_URL] Display status. - latest downstream pull requests - versions from all downstream branches - latest upstream releases - latest builds in Koji - latest builds in Copr - latest updates in Bodhi Options: -h, --help Show this message and exit.  "}),e.add({id:33,href:"/docs/cli/push-updates/",title:"push-updates",section:"Packit CLI",content:"packit push-updates #  Push the Bodhi updates that have been in testing for more than \u0026lsquo;Stable days\u0026rsquo; (7 by default) to the stable.\nIf you are not authenticated with the bodhi server, please make sure that you navigate in your browser to the URL provided by the bodhi-client and then paste the code=XX... to the terminal when prompted.\nIf you set fas_user and kerberos_realm in your \u0026ldquo;~/.config/packit.yaml\u0026rdquo; and have an active Kerberos TGT, you will be automatically authenticated.\nHelp #  Usage: packit push-updates [OPTIONS] [PATH_OR_URL] Find all Bodhi updates that have been in testing for more than 'Stable days' (7 by default) and push them to stable. Options: --update-alias TEXT For example FEDORA-2019-ee5674e22c -h, --help Show this message and exit.  "}),e.add({id:34,href:"/source-git/work-with-source-git/pull-upstream-fixes/",title:"Pull fixes from the upstream",section:"Working with source-git",content:"Pull fixes from the upstream #  One of the common tasks of being a downstream maintainer is to pull fixes from the upstream codebase. This usually happens when a problem is discovered downstream which is already resolved in the upstream code. There are two scenarios how to obtain the upstream code:\n The fix is not released yet by the upstream - this implies pulling the fix from the main development upstream branch. If the fix is already released, one can either update to that upstream release or only pull commits with the fix. Please consult Fedora Update Policy  if you are unsure how to proceed.  Adding changes #  Since your source-git repository shares git history with upstream, you can easily cherry-pick commits which you want to have in the downstream and Packit is then able to turn those commits into patch files with the ability to configure the whole process.\nAs an example, let\u0026rsquo;s try to do this with systemd, in the example below we\u0026rsquo;d be using https://gitlab.com/packit-service/src/systemd. The remote mimics how fedpkg fork works.\n$ git remote -v origin git@gitlab.com:packit-service/src/systemd.git (push) ttomecek git@gitlab.com:TomasTomecek/systemd-stable.git (push) upstream git@github.com:systemd/systemd-stable.git (push)  We have 3 remotes in the repo:\n origin — the official source-git repo where the downstream maintenance happens ttomecek — a fork of the source-git repo upstream — the official upstream repository  With this setup, we can fetch ref from the upstream remote, cherry-pick commits of our choice, push them to the fork ttomecek and open a merge request against the repository referenced as the origin remote.\nControlling the patch process #  Packit recognizes that the upstream commits are meant to be downstream patches:\n Packit generates patch files from the commits via git format-patch. It also adds them into the spec file as new PatchXYZ entries.  If that doesn\u0026rsquo;t work for you, you can tailor the patch process. The main downside is that with the default process you cannot name the patch file nor control where exactly should Packit place the Patch123: 123.patch line in the spec file. There is a way though how you can have more control over the process. You can add Git-trailers to the end of a commit message which Packit will then read and take into account:\n Patch-name — name of the patch (e.g. Patch-name: my-fancy.patch) Patch-id — numerical ID used in the patch-tag when adding the patch to the spec-file  See Controlling patch generation for detailed description of all trailers.\nExample of a commit in a source-git repo:\nAuthor: Packit \u0026lt;packit\u0026gt; AuthorDate: Wed Aug 19 11:55:14 2020 +0000 Commit: Packit \u0026lt;packit\u0026gt; CommitDate: Wed Aug 19 11:55:14 2020 +0000 add workaround for gcc7 on ppc64le temporary before it's fixed in gcc https://bugzilla.redhat.com/show_bug.cgi?id=1420350 Patch-name: drpm-0.3.0-workaround-ppc64le-gcc.patch Patch-id: 100 --- src/CMakeLists.txt | 2 +- test/CMakeLists.txt | 12 +----------- 2 files changed, 2 insertions(+), 12 deletions(-)  And this is how a corresponding spec file looks (shortened for brevity)\nName: drpm Version: 0.4.1 Release: 2.g959639c5%{?dist} URL: https://github.com/rpm-software-management/%{name} Source: %{url}/releases/download/%{version}/%{name}-%{version}.tar.bz2 # add workaround for gcc7 on ppc64le temporary before it's fixed in gcc # https://bugzilla.redhat.com/show_bug.cgi?id=1420350 Patch100: drpm-0.3.0-workaround-ppc64le-gcc.patch %prep %autosetup -p1  "}),e.add({id:35,href:"/docs/cli/build/in-image-builder/",title:"in-image-builder",section:"build",content:"packit build in-image-builder #  Create a VM image in Image Builder defined in your \u0026ldquo;packit.yaml\u0026rdquo; using your Copr builds.\nRequirements #   Be familiar with Red Hat Image Builder:  https://www.redhat.com/en/blog/using-hosted-image-builder-its-api https://console.redhat.com/docs/api/image-builder https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/composing_a_customized_rhel_system_image/index   Red Hat API token set as redhat_api_refresh_token in ~/.config/packit.yaml; the token can be obtained here Packit config with a vm_image_build job defined  Tutorial #    Place a config file for packit in the root of your upstream repository.\n  Add a vm_image_build job.\n  Submit a request to Red Hat Image Builder:\n$ cd my/ustream/project/ $ packit build in-image-builder my-new-fancy-image   Navigate to the Image Builder web interface to use your image once the build is complete.\n  As of December 2022, Packit Github app can now submit builds to Red Hat Image Builder, for more details see the vm_image_build job description.\nHelp #  Usage: packit build in-image-builder [OPTIONS] IMAGE_NAME [PATH_OR_URL] Create a VM image in Image Builder. ### EXPERIMENTAL ### This command is experimental and the integration with Image Builder will be changed in a backwards incompatible way in the future. Packit loads image build configuration from your packit.yaml file. When `--job-config-index` is not specified, the job configuration is loaded from your .packit.yaml and the first matching vm_image_build job is used. IMAGE_NAME is the name of the image to be created. Please pick something unique so it's easy to identify for you in the Image Builder interface and can be well associated with the image content. [PATH_OR_URL] argument is a local path or a URL to the upstream git repository, it defaults to the current working directory Options: --job-config-index INTEGER Use N-th job definition to load configuration for the image build. The type needs to be vm_image_build. --wait / --no-wait Wait for the build to finish -h, --help Show this message and exit.  "}),e.add({id:36,href:"/docs/cli/build/mock/",title:"in-mock",section:"build",content:"packit build in-mock #  Create RPMs in mock using content of the upstream repository.\nHelp #  Usage: packit build in-mock [OPTIONS] [PATH_OR_URL] Build RPMs in mock using content of the upstream repository. PATH_OR_URL argument is a local path or a URL to the upstream git repository, it defaults to the current working directory. Options: --upstream-ref TEXT Git ref of the last upstream commit in the current branch from which packit should generate patches (this option implies the repository is source- git). --release-suffix TEXT Specifies release suffix. Allows to override default generated:{current_time}.{sanitized_curren t_branch}{git_desc_suffix} --default-release-suffix Allows to use default, packit-generated, release suffix when some release_suffix is specified in the configuration. -r, --root TEXT Uses specified chroot configuration. If ends with '.cfg', then it is treated as full path to the mock configuration. -h, --help Show this message and exit.  "}),e.add({id:37,href:"/docs/cli/build/local/",title:"locally",section:"build",content:"packit build locally #  Create RPMs using content of the upstream repository.\nHelp #  Usage: packit build locally [OPTIONS] [PATH_OR_URL] Create RPMs using content of the upstream repository. PATH_OR_URL argument is a local path or a URL to the upstream git repository, it defaults to the current working directory Options: --upstream-ref TEXT Git ref of the last upstream commit in the current branch from which packit should generate patches (this option implies the repository is source- git). --release-suffix TEXT Specifies release suffix. Allows to override default generated:{current_time}.{sanitized_curren t_branch}{git_desc_suffix} --default-release-suffix Allows to use default, packit-generated, release suffix when some release_suffix is specified in the configuration. -h, --help Show this message and exit.  "}),e.add({id:38,href:"/source-git/work-with-source-git/control-patch-generation/",title:"Controlling patch generation",section:"Working with source-git",content:"Controlling patch generation #  When syncing the content of a source-git repo to dist-git, distribution commits from source-git are converted to patch files in dist-git using git format-patch, and the patch files are added to the spec-file with indexing starting from 1.\nThis process can be customized with the help of Git-trailers added to the end of commit messages. The value of these Git-trailers is expected to be a valid YAML value.\nWhen a source-git repo is initialized with packit source-git init, the Git-trailers bellow are used to capture the name, ID and patch-status from dist-git. This way existing distribution patches don\u0026rsquo;t produce any change in dist-git when they are transformed and synced back.\nControlling patch generation with Git-trailers deprecates the source-git patch metadata mechanism in flavor of a Git-native format. This old patch metadata format is still supported if none of the Git-trailers bellow are found in any of the distribution commits.\nPatch-name #  This can be used to change the name of a patch-file from the one generated by git format-patch. To merge multiple adjacent commits in a single patch file, specify an identical Patch-name for each of them.\nWhen merging multiple adjacent commits to a single patch file, Git-trailers which control the way in which patches are added to the spec-file (Patch-id, Patch-status, Patch-present-in-specfile) are ignored for all commits except the first (oldest) one.\nIf no Patch-name is present, the one generated by git format-patch is left unchanged.\nExample:\nPatch-name: downstream.patch Patch-id #  This is to control the numerical ID used in the patch-tag when adding the patch to the spec-file. If none is specified, the previous ID is incremented. The ID of the first distribution patch is 1, unless otherwise specified.\nThe number of digits used for the IDs can be controlled with the patch_generation_patch_id_digits configuration option.\nThe following Git-trailer\nPatch-id: 100 results in a following patch-tag in the spec-file:\nPatch100: distribution.patch Patch-status #  This is to specify the comment lines to be included before the patch-line in the spec-file, to serve as patch status (clarifying the purpose of the patch downstream).\nIf none is specified, the commit message of the distribution commit is going to be used, after all Git-trailers are stripped.\nTo specify a pre-wrapped multiline string, use a YAML block scalar. To include empty lines, prepend each line with # .\nFor example, the following Git-trailer:\nPatch-status: |# This is a patch status. # Having multiple lines. # # With some empty lines, even. Will be rendered as bellow in the spec-file:\n# This is a patch status. # Having multiple lines. # # With some empty lines, even. Patch2: downstream.patch Patch-present-in-specfile #  This tells whether the patch generated from the commit is already in the spec-file. The value is a YAML Boolean. If True, the spec-file is not updated with this patch. Defaults to False.\nIgnore-patch #  If True, no patch-file is generated from this commit. False if not specified.\nNo-prefix #  Strip source and destination prefixes from diffs. This is the same as running git format-patch --no-prefix.\n"}),e.add({id:39,href:"/docs/cli/validate-config/",title:"validate-config",section:"Packit CLI",content:"packit validate-config #  Validate the Packit configuration file.\nHelp #  Usage: packit validate-config [OPTIONS] [PATH_OR_URL] Validate PackageConfig validation. - checks missing values - checks incorrect types PATH_OR_URL argument is a local path or a URL to a git repository with packit configuration file Options: -h, --help Show this message and exit.  "}),e.add({id:40,href:"/docs/cli/build/copr/",title:"in-copr",section:"build",content:"packit build in-copr #  Submit a Copr build of the present content in the upstream repository.\nRequirements #   Upstream git repository on GitHub. Packit config file placed in the upstream repository. ~/.config/copr  A minimum copr configure file is:\n[copr-cli] copr_url = https://copr.fedorainfracloud.org gssapi = true This uses GSSAPI (see fkinit for more details). Alternatively you can use copr API token available here.\nTutorial #    Place a config file for packit in the root of your upstream repository.\n  The command below would create a SRPM from the present content of a repo and perform copr-cli build with it. If you need to specify a project name/owner or chroots, see the options in help.\n$ cd my/ustream/project/ $ packit build in-copr   Help #  Usage: packit build in-copr [OPTIONS] [PATH_OR_URL] Build selected upstream project in Copr. PATH_OR_URL argument is a local path or a URL to the upstream git repository, it defaults to the current working directory. Copr configuration needs to be set before usage. https://docs.pagure.org/copr.copr/user_documentation.html#quick-start Options: --nowait Don't wait for build --owner TEXT Copr user, owner of the project. (defaults to username from copr config) --project TEXT Project name to build in. Will be created if does not exist. (defaults to the first found project value in the config file or 'packit- cli-{repo_name}-{branch/commit}') --targets TEXT Comma separated list of chroots to build in. (defaults to 'fedora-rawhide-x86_64') --description TEXT Description of the project to build in. --instructions TEXT Installation instructions for the project to build in. --list-on-homepage Created copr project will be visible on copr's home-page. --preserve-project Created copr project will not be removed after 60 days. --additional-repos TEXT URLs to additional yum repos, which can be used during build. Comma separated. This should be baseurl from .repo file. E.g.: http://copr-be.cloud.fedoraproject.org/results /rhughes/f20-gnome-3-12/fedora-$releasever-$ba search/ --upstream-ref TEXT Git ref of the last upstream commit in the current branch from which packit should generate patches (this option implies the repository is source-git). --request-admin-if-needed Ask for admin permissions when we need to change settings of the copr project and are not allowed to do so. --enable-net / --disable-net Copr build is built with explicitly enabled network access or disabled --release-suffix TEXT Specifies release suffix. Allows to override default generated:{current_time}.{sanitized_cu rrent_branch}{git_desc_suffix} --default-release-suffix Allows to use default, packit-generated, release suffix when some release_suffix is specified in the configuration. -h, --help Show this message and exit.  "}),e.add({id:41,href:"/docs/cli/build/",title:"build",section:"Packit CLI",content:"packit build #  Subcommand that groups all RPM build related commands together.\nPossible ways to build an RPM #   locally in-mock in-copr in-koji in-image-builder  Help #  Usage: packit build [OPTIONS] COMMAND [ARGS]... Subcommand to collect build related functionality Options: --srpm FILE Build the SRPM from FILE instead of implicit SRPM build. -h, --help Show this message and exit. Commands: in-copr Build selected upstream project in Copr. in-image-builder Create a VM image in Image Builder. in-koji Build selected upstream project in Fedora. in-mock Build RPMs in mock using content of the upstream repository. locally Create RPMs using content of the upstream repository.  "}),e.add({id:42,href:"/source-git/work-with-source-git/build-locally/",title:"Build current checkout locally",section:"Working with source-git",content:"Build your current checkout locally #  Once you are comfortable with your local changes, you can build them before pushing them out. Just make sure that all code changes are committed, otherwise Packit won\u0026rsquo;t be able to create patch files out of them.\nWe are going to use Packit to achieve such a thing, so please make sure you have it installed locally.\nThe command to create source RPMs is called srpm and that\u0026rsquo;s how you can create one:\n$ packit srpm SRPM: /home/tt/g/systemd/systemd-stable/systemd-247.1-2.g68d22b32.fc33.src.rpm  Our changes worked! We can try building them, either in our local environment using Packit - this implies that all build dependencies are installed:\n$ packit build locally  \u0026hellip;or in mock:\nmock --rebuild -r fedora-rawhide-x86_64 ./systemd-247.1-2.g68d22b32.fc33.src.rpm  -r allows you to pick a chroot of your choice and these are exactly the same which you can specify for builds in your packit.yaml.\nIf the build is passing locally, it may be time to propose your changes to dist-git.\nHow Packit generates an SRPM from a source-git repo? #  These are the steps:\n Download archive specified in specfile\u0026rsquo;s Source directive. Create patch files from commits on top off upstream_ref where necessary. Bump release in the spec file. Generate new changelog entry in the spec file. Run rpmbuild and set paths so that rpmbuild can find patches, spec files, archive and additional sources.  "}),e.add({id:43,href:"/source-git/work-with-source-git/propose-to-dist-git/",title:"Propose your source-git content to dist-git",section:"Working with source-git",content:"Propose your source-git content to dist-git #  Once your changes are merged into a source-git repo, the final step is to propose those changes to dist-git and get a production build. Alternatively, you can open a dist-git merge request just to trigger the dist-git checks or see how the changes would look in dist-git.\nIf you want to change something in the spec file, this is the right time to bump release, add a %changelog entry or adjust macros. Packit will copy the content of the source-git spec to the dist-git repo.\nUpdate local dist-git checkout #  The first step is to update a local clone of a dist-git repo:\n$ packit source-git update-dist-git -m \u0026quot;a comment\u0026quot; $SOURCE_GIT_REPO_PATH $DIST_GIT_REPO_PATH  This command does not push any changes - everything happens only in your local environment. We advise you to inspect the changes done in your dist-git repo before pushing them out to be sure about them.\nIf you are satisfied with the changes, put them in a new branch, push them out and create a merge request:\n$ git switch -C resolve-bz-1234567 $ git push $USER_ID  The premise is that the remote of your fork is named $USER_ID as this is how centpkg fork does it. Once pushed, create the merge request in your browser.\nFrom this point, you should follow the standard dist-git contribution process.\nOur team is working on simplifying this workflow so some steps described above will be automated in the future.\n"}),e.add({id:44,href:"/posts/weekly/march-2023/",title:"Packit March 2023",section:"Weekly Status",content:"Week 10 (March 7th – March 13th) #   Parsing the spec file by RPM is now performed only if really necessary, greatly improving performance in certain scenarios. (specfile#212)  Week 11 (March 14th – March 20th) #   Packit now uses the get_current_version action defined by the user to retrieve version before updating the specfile %setup macro (if any). (packit#1886)  Week 12 (March 21st – March 27th) #   \u0026lsquo;upstream_tag_template\u0026rsquo; is now also used when looking for the latest version tag in Git. This allows upstream repositories to mix different tag-patterns in the same repository, but consider only one to tell the latest version. (packit#1891)  Week 13 (March 28th – April 3rd) #   Packit now preserves %autorelease during propose_downstream and pull_from_upstream. (packit#1904) Since in GitLab, it is not possible to overwrite the pending statuses, Packit now provides more generic descriptions and URLs when setting the first pending status. (packit-service#1975)  "}),e.add({id:45,href:"/posts/weekly/february-2023/",title:"Packit February 2023",section:"Weekly Status",content:"Weeks 5–6 (February 1st – February 13th) #   You can now use --srpm option with the packit build locally CLI command. (packit#1810) You will newly see news about Packit as a footer of the GitHub check runs summary. (packit-service#1881) Packit now groups related builds and test runs (e.g. triggered by the same event, just different chroots) together. In the future, this will allow better presentation of the overall pipelines (e.g. in the dashboard). We now also create database entries before sending requests to external service (e.g. Testing Farm), therefore failures will be more visible in the dashboard. (packit-service#1787)  Week 7 (February 14th – February 20th) #   Packit now provides PACKIT_PROJECT_VERSION environment variable when running changelog-entry action. (packit#1853) Packit CLI now requires bodhi in version 7.0.0 at minimum. (packit#1844) You can now specify branches for a job triggered by a commit with a regex. (packit-service#1909)  Week 8 (February 21st – February 27th) #   packit validate-config CLI command now provides details about errors when it cannot parse the config file. (packit#1861) --update-release/--no-update-release CLI flag now affects only Release, not Version. (packit#1857) Packit does fewer API calls when searching for the package configuration file in remote repositories. (packit#1846) Commit statuses/check names will now contain the name of the branch or release for the build and test jobs with commit or release trigger. This will prevent the collision of the names. (packit-service#1920)  Week 9 (February 28th – March 6th) #   Aliases logic was updated to account for the upcoming Fedora release (Bodhi now marks such release as frozen). From now on, Fedora 38 updates will be created even when the release is frozen. (packit#1863) packit validate-config now correctly checks glob-patterns in \u0026lsquo;files_to_sync\u0026rsquo; (packit#1865) and provides details about errors when it cannot parse a config file. (packit#1861) Pull-from-upstream jobs are now displayed on our dashboard 🥳 https://dashboard.packit.dev/jobs/pull-from-upstreams (packit-service#1951, packit-service#1939) Packit will no longer automatically request access to the forks on GitLab. This will prevent us from spamming one-time contributors with requesting the access, whereas the regular contributors can add Packit following the instructions from the comments on the MRs, so they can receive the results of Packit pipeline right from the commit statuses. (packit-service#1946) Packit will retry tasks that are interrupted by a worker shutdown. This should improve throughput and reduce cases where there is no outcome, i.e. \u0026ldquo;builds should have been done but nothing happened\u0026rdquo;. (packit-service#1935) OGR now understands a few community-hosted GitLab instances that could not be determined automatically from the hostname. Thanks to that, you don\u0026rsquo;t need to hardcode these instances to be mapped correctly. (ogr#775)  Thank you, @SpyTec for so many wonderful changes in our dasbhoard.\n"}),e.add({id:46,href:"/posts/weekly/january-2023/",title:"Packit January 2023",section:"Weekly Status",content:"Week 0 🌄 (December 20th 2022 – January 2nd 2023) #   ogr now raises GitForgeInternalError rather than PagureAPIException when getting 50x response from the Pagure API. This should increase usability as those tasks will be retried. (ogr#762) Packit now puts the correct release number into the changelog when the Release tag is reset during propose-downstream. (packit#1816))  Week 1 (January 3rd – January 9th) #   SRPMs for projects that installed the GitHub App before September 6th and don\u0026rsquo;t have srpm_build_deps defined are now built in Copr as well. (packit-service#1822) We have fixed a bug in dashboard that linked null as a Copr build for Testing Farm runs that do not require any Copr build. (dashboard#200) All classes including Specfile itself can now be copied using the standard copy() and deepcopy() functions from copy module. (specfile#176)  Week 2 (January 10th – January 16th) #   When configuring Copr chroot (target in Packit terminology) specific configuration, make sure to specify additional_modules as a string: module names separated with a comma, example: \u0026ldquo;httpd:2.4,python:4\u0026rdquo;. (packit#1826) We have fixed a bug which caused long Copr build end reporting time on a few occurrences. (packit-service#1838) A few fixes has been implemented to make it possible to use propose-downstream job on GitLab. (packit-service#1842, packit-service#1844, packit-service#1845, packit-service#1846)  Week 3 + 4 (January 17th – January 30th) #   Users can now re-trigger bodhi_update and koji_build jobs by /packit create-update and /packit koji-update comments in an issue opened by Packit in the configured issue_repository if anything went wrong during these jobs. (packit-service#1796) All Copr projects created by Packit now default to enable_net=False: our documentation stated this, but it wasn\u0026rsquo;t the case. This is now corrected. (packit#1825) You can now specify update_release: false in the configuration to tell Packit not to change the Version and Release in the spec file. It works the same as --no-update-release (renamed from now deprecated --no-bump) in the CLI. (packit#1827) Packit now supports setting module_hotfixes for Copr projects. (packit#1829) Packit now also allows passing in free-form parameters to Testing Farm in order to support all of its options immediately once they are added. The parameters can be passed through the tf_extra_params config option. The free-form dictionary must follow the structure of Testing Farm POST requests. See our documentation and examples for more information. (packit-service#1853) Fixed a bug in section parsing that caused sections to be ignored when there were macro definitions spread across the spec file and not cumulated at the top. (specfile#191) Also fixed the infinite loop that occurred when section options were followed by whitespace. (specfile#197)  "}),e.add({id:47,href:"/source-git/work-with-source-git/sync-from-dist-git/",title:"Sync back changes made in dist-git",section:"Working with source-git",content:"Sync back changes made in dist-git #  Although we recommend for all packaging work to be done in source-git once it was decided to adopt the source-git workflow, some changes are going to keep happening in dist-git, like the bumping of release numbers by provenpackagers during re-builds.\nIn order to prevent the content of the source-git repository from diverging from dist-git, these changes need to be synced back to source-git.\nUse the packit source-git update-source-git command to do this:\n$ packit source-git update-source-git \u0026lt;DIST_GIT_REPO_PATH\u0026gt; \u0026lt;SOURCE_GIT_REPO_PATH\u0026gt; \u0026lt;RANGE\u0026gt;  The command works offline, so it\u0026rsquo;s up to the developer to inspect and push the changes synced back to source-git (or open an MR).\nThe command above will refuse to update the source-git repository, if any of the dist-git commits in \u0026lt;RANGE\u0026gt; changed the source of the package or any of the patch-files. We expect such changes to be done in source-git, or if they need to happen in dist-git, to be synced back manually.\n"}),e.add({id:48,href:"/source-git/work-with-source-git/fix-diverged-history/",title:"Diverged history",section:"Working with source-git",content:"Diverged history #  It can easily happen that the history of the source-git and dist-git repositories get diverged. See this document for more info about how packit checks the sync status.\nPackit considers the histories of those repositories as diverged when both of them have as a HEAD commit one of the following changes:\n A change which has not been synced to the other repository. The change has been synced but the From-[source|dist]-git-commit git trailer is missing for some reason. The change couldn\u0026rsquo;t have been synced because it\u0026rsquo;s \u0026ldquo;empty\u0026rdquo;, i.e. it generates no change when synced to the other repo. Examples of such changes:  a change in .distro/source-git.yaml or other file which is not synchronized between repositories mass rebuild in a package which uses rpmautospec (results in an empty commit in the dist-git repo)    When you then try to synchronize those repositories either way, you get\nPackitException: '.../src/package' and '.../rpms/package' have diverged. Sync status needs to be reestablished manually. The first source-git commit to be synced is 'abc'. The first dist-git commit to be synced is 'xyz'.  To sync them manually try to re-run the command with the -f/--force switch, which doesn\u0026rsquo;t check the synchronization status.\nIf you need to synchronise the \u0026ldquo;empty\u0026rdquo; change, you have to manually add an empty commit to the other repository\n git commit --allow-empty -m \u0026quot;From-dist-git-commit HEAD\u0026quot; - to the source-git repo OR git commit --allow-empty -m \u0026quot;From-source-git-commit HEAD\u0026quot; - to the dist-git repo. Where HEAD is the sha of HEAD commit of the other repo. There will be an easier way once packit/packit#1884 is implemented.  "}),e.add({id:49,href:"/posts/2022-features/",title:"2022 for Packit",section:"Blog Posts",content:"Packit project in 2022 #  As you will see in the following paragraphs, the year 2022 was really fruitful for the Packit project. Without further ado, let’s take a look at what the Packit team accomplished last year:\nFedora automation #  We have made a huge improvement in downstream automation. At the beginning of the year, we finished the workflow and you are now able to use Packit to get your release from upstream via dist-git and Koji to Bodhi. As usual, you can pick just what you need. This workflow consists of three jobs:\n propose-downstream: as a reaction to an upstream release, the source archive is saved to a lookaside cache, specfile is updated and sent as a pull request to Fedora dist-git. koji-build: as a reaction to a new dist-git commit, a new Koji build is triggered (you can specify allowed authors of a commit or merged pull request). bodhi-update: as a reaction to a successfully finished Koji build, a new Bodhi update is created  But that wasn’t all. At the very end of the year, the Packit team implemented an alternative to the propose-downstream job that we call pull-from-upstream. The logic of the job is the very same: the source archive is saved to a lookaside cache, specfile is updated and sent as a pull request to Fedora dist-git. The only – and main – difference is that the job is defined downstream (in the default dist-git branch, rawhide or its main alias) so you don’t need to install Packit in the upstream repository. The information about a new release is received from the Upstream Release Monitoring. The pull-from-upstream job is mainly targeted to the Fedora maintainers without upstream access or with upstream not being supported by Packit. (This job works with any upstream using git.) The setup is nicely described in this blog post. And if you want a dedicated documentation page for the Fedora downstream automation, look at https://packit.dev/docs/fedora-releases-guide/.\nAnd that’s still not all, we’ve also added propose-downstream to our dashboard. You can now the jobs in the Pipelines view. Also, logs can be checked on a detail page (that can be accessed from a status of a release commit).\nStill not convinced we’ve done a lot? When using various downstream jobs, you can still hit an issue now and then. (Messages from Fedora infrastructure can get lost or some intermittent error can occur.) Packit automatically retries to overcome temporary issues, but sometimes it’s not enough or there is a real problem that needs to be fixed elsewhere. We can’t resolve the real problems for you, but we can help let you retry the job when needed. And you have two places where to do that.\nAs you might be used to with the propose-downstream job, you can use comments in an upstream issue to retrigger Bodhi updates and Koji builds as well. Just configure issue_repository so Packit knows where to create issues in case of problems. (This does not need to be an upstream issue and this repository can be used for multiple projects.) Alternatively, if you use dist-git pull requests (either made by Packit or other maintainers), you can use a pull request comment to retrigger Koji Build or Bodhi update.\nIf you are interested in what Packit has done for its users, you can take a look at the activity of the packit (or packit-stg) FAS user in dist-git, Koji or Bodhi.\nSRPM in Copr #  Throughout the 2022 we have implemented support for building SRPMs in the Copr and slowly started introducing newly-onboarded projects to use Copr right from the start. The definitive switch to Copr has been done at the beginning of 2023. For more details, take a look at the relevant blog post, but let’s shortly describe the benefits: Most importantly, you can now use srpm_build_deps config option to specify the dependencies needed for the build. With the old solution, this process was manual, global and had to be done by Packit maintainers. Another advantage of being able to use Copr for SRPM builds is access to the SRPM artifacts.\nSelf-mapping of FAS account #  From the beginning of the Packit project, for every Packit GitHub installation, we have required a Fedora account so we can be sure, that we are safe to use Fedora systems (like Copr or dist-git) on behalf of that user. Since we automate various tasks for you, we’ve made it possible for you to perform this yourself. (Thanks to the user config field in the Fedora Account System.) If you are interested in how this works, take a look at the blog post we’ve prepared for you: https://packit.dev/posts/fas-verification-automation/\nIf you wonder why we check permissions for the installation, we have good news for you. This year, we plan to improve the permission schema, do the checks for each job, and require only what is needed. But more about the plans for 2023 later.\nMultiple-project test runs #  If you have multiple connected projects (as we do) and work on a feature spanning more of them, the following feature might come in handy. You can use a commit command with a reference to the other pull request and Packit will use Copr builds from both pull requests during the tests. Want to know more? Check this blog post: https://packit.dev/posts/testing-farm-triggering/\nSpecfile library #  This one might not be relevant to most of our users, but we would still like to announce, that we’ve created a Python library for specfile manipulation. It can not only parse various weird spec files but also can edit them with as little diff as possible. Also, the code is really interesting so check it out. Now, it’s used by Packit and rebase-helper and you can watch this demo if you want to know more. In case you’ve missed that, this is not the first time we’ve extracted a part of our codebase for wider usage – another nice example is a forge-independent Python library for GitHub/GitLab/Pagure API called OGR.\nVM Image Builds #  Having Copr builds available for your pull-requests is really nice, but you can now have VM image builds as well. It would be really wasteful to do this for each and every commit so we decided to trigger this by a /packit vm-image-build  comment. Similarly to other jobs, Packit uses an external system to do the hard work. This feature is possible thanks to the Red Hat Image Builder. This feature is a fresh start on this journey and we are investigating the possibilities of Packit in this field. Check our documentation and let us know what you think.\nPlans for the next year #  Do you wonder what we plan for you for the year 2023? That is not a secret. For some time, we have been opening our planning and since the last year, you can check our Kanban board since it has become the primary place we use on daily bases. (It used to be half-manually and half-automatically synced.) Every quarter, our team sits down and discusses our plans for the next three months. We use MOSCOW (=MUST x SHOULD x COULD x WON’T) prioritisation method to group and compare all of our epics. The result of this time’s planning can be seen here.\nDo you want to know how we decide and how you can influence us? It’s pretty easy. Firstly, we need to know about a bug or feature request. Secondly, the task needs to be worth the work. (And should be related to our mission.) We can’t work on everything so we need to pick the work with a bigger impact (a lot of projects will benefit from that or a significant benefit for a smaller group). So shortly, if you want something to be done: create an issue, provide a clear reasoning why we should do that and find other projects that can benefit from that.\nAnd also, our project is open source. We are more than happy to help anyone contribute to our code base!\n With that, I, personally, would like to thank all of the Packit team members for their outstanding work during the year. And I also would like to thank you, our users, for using our project, being kind, helpful and patient! I wish you all a happy new year and less mundane work as possible!\nOn behalf of the Packit team, František\n"}),e.add({id:50,href:"/posts/pull-from-upstream/",title:"Automatic pulling of upstream releases to Fedora",section:"Blog Posts",content:"In the previous year, we automated the Fedora downstream release process in Packit. The first step of the release process, propagating the upstream release to Fedora, is covered by the propose_downstream job. This job updates the sources in Fedora, the spec file, and other needed files and creates pull requests with the changes in the dist-git repository.\nThe downside of this job is that for its execution, users need to install Packit Service GitHub/GitLab app since this job reacts only to GitHub/GitLab release webhooks. However, the person who maintains the package in Fedora may not be the upstream maintainer and may not have admin access to the upstream GitHub/GitLab repository.\nTo cover this case, we came up with a new job called pull_from_upstream, which aims to update Fedora dist-git similarly to propose_downstream, but is configured directly in the dist-git repository. Let\u0026rsquo;s now look at how to set it up and how it works.\nSetup #  Upstream release monitoring #  pull_from_upstream job reacts to a new bug in Bugzilla about a new upstream version of a project. The bug is automatically created by Upstream Release Monitoring. To enable the Upstream Release Monitoring:  Add the upstream project (if it is not there yet) to Anitya and configure the mapping to a Fedora package:    Enable the monitoring in the dist-git repository (Fedora Package Sources):    In Anitya, there are multiple backends you can configure the mapping for. Besides GitHub or GitLab, you can use e.g. PyPI, pagure, or many others. Also, be aware that there can be a delay in retrieving the new version, so the update to Fedora is usually not created instantly (e.g. for Python projects, it is better to configure PyPI backend rather than GitHub since the monitoring there is much less delayed).  Packit configuration #  To automatically pull the upstream release as a reaction to the bug in Bugzilla, pull_from_upstream job together with the upstream_project_url configuration option, needs to be defined in the default branch (rawhide) of the dist-git repository in the Packit configuration file (see our documentation). The upstream_project_url needs to be a URL pointing to a Git repository so that we can do git commands on it.\npull_from_upstream in action #  Let\u0026rsquo;s showcase the new job in action for the latest release of Packit itself.\nAs you can see in the Setup section above, the Upstream Release Monitoring is configured: there is a PyPI project packitos in Anitya with configured mapping to the Fedora package packit and the monitoring in the packit dist-git repository is enabled. We could configure the mapping in Anitya from the GitHub project directly instead, and it would work as well. Just be aware that for each Fedora package, there can be a mapping only from one project.\nIn Packit configuration file, we have configured the job and related options:\nupstream_project_url: https://github.com/packit/packit issue_repository: https://github.com/packit/packit copy_upstream_release_description: true  jobs:  - job: pull_from_upstream  trigger: release  dist_git_branches:  - fedora-all  - epel-8 You can see that version 0.66.0 of Packit (packitos in PyPI) was released: When Upstream Release Monitoring retrieved this new version, it created a new bug: This triggered Packit, and after checking the Packit configuration in dist-git and finding the pull_from_upstream job, this job was run.\nUsing the upstream_project_url from the configuration, Packit was able to get the needed information from the corresponding GitHub release: As a result, pull requests for configured branches were created. Here is an example of one of the created pull requests and part of its content: Since we have configured the issue_repository, we could be also notified about errors: Currently, retriggering is not possible, but it\u0026rsquo;s in our plan to implement it soon.\nAlso, if you need to do any change in the pull request, you need to locally fetch the source branch of the Packit\u0026rsquo;s pull request and push it (with a fix) to your fork (as it is not possible to push to the branch created in the Packit\u0026rsquo;s fork):\ngit fetch ssh://$USER.fedoraproject.org/forks/packit/rpms/$YOUR_PACKAGE.git refs/heads/*:refs/remotes/packit/* git cherry-pick packit/$VERSION-$BRANCH-update-pull_from_upstream  Few words in the end #  pull_from_upstream has just been implemented; therefore, we encourage you to help test it out and make it perfect! There are still some limitations (e.g. regarding upstreams, see documentation), which we are trying to resolve as soon as possible. We believe this functionality could be beneficial for maintainers of Fedora packages and could even be integrated further. Any suggestions and feedback are welcomed (see contacts).\nIf you are interested in details of customization of the pull_from_upstream job and in the whole downstream automation, make sure to check out our Fedora release guide as well!\n"}),e.add({id:51,href:"/posts/weekly/2022/",title:"2022",section:"Weekly Status",content:"Week 0 (December 13th - January 2nd) #   Dashboard shows a message when the SRPM build logs are not present instead of an empty page that might suggest logs are being loaded. (packit/dashboard#158)  Week 1 (January 3rd - January 7th) #   Packit service now discards old (currently, this means 3 months) SRPM builds logs. (packit/packit-service#1315) We have added target_branch_head_commit property to the PullRequest class in ogr that allows you to get commit hash of the HEAD of the target branch (i.e. base, where the changes are merged to). (packit/ogr#671) Service now passes PACKIT_TARGET_SHA variable, which holds commit hash of the HEAD of the target branch where the changes are supposed to be merged, to the Testing Farm environment. This should help solving the issue of running tests from non-merged codebase on the Testing Farm side. (packit/packit-service#1319)  Week 2 (January 10th - January 14th) #   Packit no longer ignores --no-bump and --release-suffix options for source-git repos. packit/packit#1452 Packit now names local branch pr/{pr_id} when checking out a PR, even when it\u0026rsquo;s not being merged with the target branch. This results into NVR of the build containing pr{pr_id} instead of pr.changes{pr_id}. packit/packit#1445  Week 3 (January 17th - January 21st) #   %changelog sections in dist-git using the %autochangelog macro are preserved when running propose-downstream, except when sync_changelog is set to true. When checking if directories hold a Git-tree, Packit now also allows .git to be a file with a gitdir reference, not only a directory.  Week 4 (January 25th - January 28th) #   SRPM build view contains info about build start and finished time. packit/dashboard#163 When submitting a distgit PR during propose-downstream job, we create a README.packit file with some info about the sync the packit version used. To avoid this you can add create_sync_note: false to conig file. packit/packit#1465  Week 5 (January 31th - February 7th) #   A new option --no-require-autosetup for source-git init command has been introduced. Please note that source-git repositories not using %autosetup may not be properly initialized. (packit#1470) Packit-service now supports re-triggering against failed task using comment on pull request /packit rebuild-failed and similarly for testing farm: /packit retest-failed. (packit-service#1303)  Week 6 (February 8th - February 14th) #   Packit now correctly handles colons in git trailer values in source-git commits. (packit#1478)  Week 7 (February 14th❤️ - February 18th) #   Synchronization of default files can now be disabled using a new config files_to_sync. Key sync_files is now deprecated. (packit#1483) (packit.dev#390) python3-setuptools_scm is now available by default in the sandbox.  Week 8 (February 18th - February 28th) #   Packit now allows specifying more test distros for one build target to test on in Testing Farm in the configuration. The checks for the test job will also contain the name of the actual test distro (and not the build target as previously). A new option, srpm_build_deps, in the packit configuration file\ncan be used. Which is a list of RPM dependencies that are needed for the actions to be run when building SRPM and is an indicator to build the SRPMs in Copr.  Week 9 (March 1st - March 7th) #   When a specfile is being generated, and both specfile_path and downstream_package_name are not set, Packit now correctly resolves this situation and sets specfile_path to the name of the upstream repo suffixed with \u0026quot;.spec\u0026quot;. (packit#1499) A new command packit source-git status has been introduced for checking the synchronization of a source-git and a dist-git repository based on the used git trailers. The command outputs a range of commits which need to be synchronized from dist-git to source-git or the other way around. If possible, the command also provides instructions on how to synchronize the repositories. (packit#1500) We have added a new enable_net configuration option for Copr builds that allows you to disable network access during Copr builds. It is also complemented by --enable-net/--disable-net CLI options if you use Packit locally. (packit#1504) Packit now adds 👀 instead of 👍 as a reaction to /packit command (packit-service#1372) Progress of propose-downstream is now saved in the database and is available via API. Visualization in the dashboard is to follow next week, stay tuned. (packit-service#1292) When running tests for the pull-request job, we now expose environment variables for commit hash, branch and URL both for pull-request source and target. In the test environment, you can use the following variables: PACKIT_SOURCE_SHA, PACKIT_TARGET_SHA, PACKIT_SOURCE_BRANCH, PACKIT_TARGET_BRANCH, PACKIT_SOURCE_URL and PACKIT_TARGET_URL. These variables are not set for test runs of releases and branch pushes. (packit-service#1382)  Week 10 (March 8th - March 14th) #   You can view information about ongoing propose-downstream jobs via our dashboard. (dashboard#168) We have switched the cache for dist-git branches and Copr targets to TTL cache that gets discarded once in 12 hours, in case there is a change in targets, the changes shall propagate to both of our deployments without the need to redeploy within 12 hours. (packit#1513) Packit now comments when it fails to find Copr project specified in the config. (packit#1395) Packit now reacts to dist-git pushes to either rawhide or main when configured to do Koji builds for rawhide. (packit#1393) You can specify an identifier for your job to be able to configure one job multiple times. For example, you can build multiple projects from one repository (known as monorepo concept) or try multiple build options. Using identifiers allows Packit to avoid naming collisions in commit statuses and default Copr project names. (packit-service#1385) Packit no longer provides a misleading comment when it fails to update a set of targets on its own Copr projects. (packit-service#1397)  Week 11 (March 15th - March 21st) #   When using Packit CLI for creating Bodhi updates, you can now set fas_username and fas_password in your Packit user config to not be asked about that when the command is executed. Also, this allows Packit GitHub application to use this as well so you can look forward to Bodhi updates created by Packit (will be announced and described in a dedicated post). (packit#1517)  Week 12 (March 22nd - March 28th) #   We have updated contact information to Packit \u0026lt;hello@packit.dev\u0026gt;. (packit-service#1410) Interactions with Bodhi should be now more reliable when creating Bodhi updates. (packit#1528) Packit will no longer error out when trying to create a new Copr repository when it is already present. (packit#1527) There is a new packit_instances key that you can use to specify the Packit instances you want to use for working on your jobs. Nothing will change for our production users, but users of our stage instance need to use this key to preserve the support of the stage instance \u0026ndash; they can set both stg and prod in the packit_instances list to use both, or use just one. Just be careful with the downstream jobs where both instances work with the same services. This new option works like other Packit options so you can set it on the top level and/or (re)define it on the job level. More information about our staging instance can be found here: packit#1530. (packit#1417)  Week 13 (March 29th - April 4th) #   We have implemented get_contributors function in ogr that can be used for getting contributors to the project on GitHub (set of logins) and GitLab (set of authors). (ogr#692) When multiple propose downstream attempts for the same PR fail, the error messages are sent to to the same issue (as comments), instead of creating multiple new issues. (packit#1427) Downstream synchronization of the Packit configuration file (aka packit.yaml) is now working properly again. (packit#1532) packit source-git update-dist-git and packit source-git update-source-git now check the synchronization of source-git and dist-git repositories prior to doing the update. If the update can\u0026rsquo;t be done, for example, because the histories have diverged, the command provides instructions on how to synchronize the repositories. A --force option is available to try to update the destination repository anyway. (packit#1534) When using post_upstream_clone to generate your spec-file, Packit now correctly checks out a release before the action is run. (packit#1542)  Week 14 (April 5th - April 11th) #   We have introduced two new build and test target aliases: fedora-latest-stable resolves to the latest stable Fedora Linux release, while fedora-branched resolves to all branched releases (all Fedora Linux release, except rawhide). (packit#1546) We have reverted the functionality of Packit that allowed you to have set only specific targets for Copr repositories. This functionality was introduced a while ago and was found to be not very beneficial in cases of differently configured Copr jobs building in parallel in the same Copr repository. This is an implementation detail in the end, but Copr project chroots are now only added and never subtracted (every build has precisely specified targets based on the copr_build job definition). (packit#1551) If you are using our stage instance, we make it listen only on /packit-stg comment commands so you can now differentiate between the instances when commanding Packit via pull-request or issue comments. For the production instance, you can continue using /packit prefix as you are used to. (packit-service#1432) A new configuration option downstream_branch_name has been added, which is meant to be used in source-git projects and allows users to customize the name of the branch in dist-git which corresponds to the current source-git branch. (packit#1555) revision-range argument of the source-git update-source-git command is now optional. If not specified, dist-git commits with no counterpart in source-git are synchronized. (packit#1547)  Week 15 (April 12th - April 14th) #   We have implemented reporting of status for the propose-downstream job which means that you can now see the progress of the job via check runs/commit statuses on the particular release commits. (packit-service#1435)  Week 16 (April 19th - April 25th) #   The bug in our service about not setting GitHub and Gitlab statuses in case of lack of permissions was fixed. (packit/packit-service#1457) Packit\u0026rsquo;s CLI source-git update-* commands now check whether the target repository is pristine and in case not raise an error. (packit/packit#1562)  Week 17 (April 26th - May 2th) #   We have fixed an issue affecting Pipelines view on Dashboard. Currently you should be able to see pipelines again; we are also working on fixing empty rows for propose-downstream jobs. (packit-service#1461) Packit now shows the specific info when it does not have permissions to create a Bodhi update of your package. When you configure issue_repository in your Packit config file, Packit will create an issue in that project and link the dist-git page where you can give Packit FAS user the correct permissions. (packit-service#1465) Packit now exports PACKIT_PR_ID environment variable to the Testing Farm. (packit-service#1467) The bug in the Copr permission request is now fixed. (After the release of a new Copr client, Packit didn\u0026rsquo;t catch that permission problem and didn\u0026rsquo;t request the permissions to build in a custom Copr project.) (packit-service#1472) We have fixed a bug that caused Packit to fail when submitting Testing Farm on commit trigger. (packit-service#1474) Packit now builds RPMs in Copr triggered by release event with correct NVR (without the artificial release suffix). You can use it for distributing RPM packages via Copr.\n(packit-service#1478) From the security perspective, we have decided to disable the create_pr option for our service, from now on Packit will unconditionally create PRs when running propose-downstream. We have also updated the propose-downstream CLI such that it is possible to use create_pr from configuration or override it via --pr/--no-pr options. (packit#1563) Packit now supports release_suffix configuration option that allows you to override the long release string provided by Packit that is used to ensure correct ordering and uniqueness of RPMs built in Copr. (packit#1568)  Week 18 (May 3rd - May 9th) #   packit source-git commands learnt to replace Git-trailers in commit messages if they already exist. (packit#1577) When initializing source-git repos, the author of downstream commits created from patch files which are not in a git-am format is set to the original author of the patch-file in dist-git, instead of using the locally configured Git author. (packit#1575) Packit now correctly inform users about downstream errors only on the last try. (Previously, Packit informed for all tries even the last try succeded.) (packit-service#1485) Dashboard now also shows propose-downstream jobs in pipelines view. We have also merged all jobs to one column to minimize dead space on the page. (dashboard#178)  Week 19 (May 10th - May 16th) #   Metadata dictionary is no longer required when specifying a job. Keys which used to belong to the yaml metadata dictionary are now keys of the job dictionary itself. (packit#1569) Packit now correctly removes patches during packit source-git init when the preamble does not contain blank lines. (packit#1582) Packit now supports --release-suffix parameter in all of the related CLI commands. Also we have added a support for the release_suffix option from configuration to the CLI. With regards to that we have introduced a new CLI switch --default-release-suffix that allows you to override the configuration option to Packit-generated default option that ensures correct NVR ordering of the RPMs. (packit#1586) Resolved an SRPM build problem caused by a new version of git that refuses to fetch in a git repo when it\u0026rsquo;s owned on the OS level by someone else. (packit#1497) Packit now passes PACKIT_COPR_PROJECT and PACKIT_COPR_RPMS variables to the Testing Farm. PACKIT_COPR_PROJECT holds Copr project in format owner/project and PACKIT_COPR_RPMS space-separated RPMs that were built in Copr. (packit-service#1486) Packit now builds only its own dist-git commits. Other commits are not being acted upon. For reasoning, see packit-service#1490. (packit-service#1498) We have automated our allowlisting process via a new Packit comment command /packit verify-fas. You can find more info in our requirements. (packit-service#1487)  Week 20 (May 17th - May 23rd) #   We have fixed an issue with the handling of messages from Copr on release builds, which has resulted in not setting the correct statuses on commits. (packit-service#1513) When doing an automatic FAS account verification, Packit now suggests the URL where the GitHub account needs to be set. (packit-service#1508)  Week 21 (May 24th - May 30th) #   Packit will not raise an exception anymore when creating a SRPM with dangling symlinks. (packit#1592) You can now override which dist-git commits will be built in Koji by specifying FAS accounts of authors and committers using allowed_pr_authors or allowed_committers in the job metadata (see the documentation). (packit-service#1520)  Week 22 (May 31st - June 6th) #   Packit shows basic information about allowlisting in the status description when your namespace is not allowed. (packit-service#1533)  Week 23 (June 7th - June 13th) #   The creation of Bodhi updates should not time out anymore, because we no longer get the latest build of a package via Bodhi. (packit#1612) We have fixed a regression where string values for the targets and dist_git_branches configuration keys were not accepted. (packit#1608) We improved the reporting for the test job if we are not able to find any FMF metadata and the skip_build option is enabled. (packit-service#1539)  Week 24 (June 14th - June 21st) #   Git ref name that Packit works with during propose-downstream is now made more obvious in logs. (packit#1626) Packit now correctly handles creation of custom archives in root while a specfile is in a subdirectory. (packit#1622) There is a new check for git projects that are allowed to use a custom Copr project. There will be a better integration in the form of a new config field in Copr settings that Packit can use. In the meantime, the mapping is defined and maintained by the Packit team. Let us know if you need a project to be allowed. (packit-service#1556) A link to Copr build logs was updated: it now points to a place where logs are available once a build starts. (packit-service#1554)  Week 25 (June 21st - June 27th) #   Packit Bash completion file is no longer needlessly executable. (packit#1634) Packit now works with Bodhi 5 and Bodhi 6 authentication mechanism. (packit#1629) Git ref name that Packit works with during propose-downstream is now made more obvious in logs. (packit#1626) We have fixed the incorrect displaying of propose downstream results in our dashboard. (packit-service#1553)  Weeks 26–27 (June 27th–July 11th) #   We adjusted the way we check the author of the PR for PRs related to dist-git commits that trigger Koji build jobs. This should fix the race condition causing not creating Koji builds in some cases. (packit-service#1573) Results from Testing Farm are now correctly reported when multiple jobs with different identifier are defined. (packit-service#1565) On a Bodhi authentication error, Packit will retry the task multiple times in ten-minute intervals to be able to fix the issue in the meantime. (packit-service#1564)  Week 28 (July 12th–July 18th) #   Packit now guides everyone better when a FAS account is private and updates the internal information about installations correctly when the app is reinstalled. (packit-service#1575) Packit can now correctly create Bodhi updates using the new Bodhi 6 client. (packit#1651) RPM build commands of Packit CLI have been merged into one build subcommand, for more information see the updated documentation. We have also introduced a new \u0026ndash;srpm option to the new build subcommand that can be used to trigger local, Copr or Koji build from an already built SRPM rather than the one implicitly created by Packit. (packit#1611)  Week 29 (July 19th–July 25th) #   Packit now correctly supports tmt_plan and tf_post_install_script in the configuration. (packit#1659) We have reverted to Bodhi 5 client since Packit couldn\u0026rsquo;t create bodhi updates with the new version 6 client: fedora-infra/bodhi#4660 (packit-service#1590). Packit also provides a more helpful error message when it hits this. (packit#1660) During creating Copr builds, on Copr errors, Packit will retry the task multiple times in case there is a Copr outage. (packit-service#1579)  Week 30 (July 26th–August 1st) #   Packit has switched to python-specfile library for handling spec files. This may cause some issues to pop up. (packit#1588) Packit CLI can now build RPMs in mock. For more information see https://packit.dev/docs/cli/build/mock (packit#1662) When using Packit before being allowed, Packit newly links an approval issue where the self-approval can be performed. (packit-service#1596) A downstream koji-build can now be re-triggered by adding a comment containing /packit koji-build into a dist-git pull request with target branch corresponding to the branch the build should be acted upon. (packit-service#1586)  Week 31 (August 2nd – August 8th) #   Action fix_spec_file can change a spec file - Packit now preserves that change. (packit#1679) BREAKING CHANGE: fixed an issue where the repo was searched for the specfile before checking if downstream_package_name is set, and \u0026lt;downstream_package_name\u0026gt;.spec can be used as the specfile_path. (packit#1663)  Week 32 (August 9th – August 15th) #   We have fixed an issue when propose downstream didn\u0026rsquo;t retry to download sources that were not yet available at the time of the first attempt. (packit-service#1609) When creating Copr builds, Packit will now retry multiple times in case there is a GitHub outage or an internal error. (packit-service#1589)  Week 33 (August 16th – August 22nd) #   Packit CLI can now submit VM images in Red Hat Image Builder. All build-related commands have now consistent --wait / --no-wait options. (packit#1666) Packit prepare-sources command now has a --create-symlinks / --no-create-symlinks option, which enables copying the archive instead of symlinking. This will be used in the Copr environment, where symlinking the archive previously caused issues. (packit#1682) We have fixed the handling of the situation when Packit lacks permission to update a Copr project. (packit#1684) Dashboard should now load data for jobs faster because the database querying has been improved and also queries are done only when needed. (packit-service#1617, dashboard#189)  Week 34 (August 23rd – August 29th) #   packit propose-downstream is now more informative when sources cannot be downloaded. (packit#1698) No more annoying issues will be created after a successful propose downstream. (packit#1693) We have fixed an issue with reporting results when multiple Testing Farm jobs with identifiers are configured. (packit-service#1634)  Week 35 (August 30th – September 5th) #   SRPMs for Copr builds are built in Copr by default for Packit GitHub app installations since September 6, 2022. For older installations, you can set the srpm_build_deps config option to use Copr as a builder. Let us know if you hit any issue with the new implementation. We are going to slowly decommission the old implementation and are happy to help with the transition. (packit-service#1636) More indexes added to the database have further improved API/dashboard response times. (packit-service#1639) When submitting Testing Farm tests, Packit will now retry multiple times in case there is a failure. (packit-service#1605) We have implemented checking the available composes before submitting the tests for both internal and public Testing Farm. (packit-service#1628)  Week 36 (September 6th – September 12th) #   When querying Bodhi for information about Fedora/EPEL releases to resolve aliases, packit now correctly handles pagination of API results. This resolves an issue that caused Fedora 37 not to be pointed to from any alias. (packit#1704)  Week 37 (September 13th – September 19th) #   Added support for filenames specified in source URL fragments, for example: https://example.com/foo/1.0/download.cgi#/%{name}-%{version}.tar.gz (specfile#100) Some more underlying improvements to our libraries and deployment.  Week 38 (September 20th – September 26th) #   Propose downstream job now pushes changes even when it\u0026rsquo;s not creating a new pull request. This allows updating existing pull requests. (packit#1725) Packit now deduces Copr targets for Copr builds when you have set your custom Copr project to be used. (packit-service#1673) Retriggering tasks via re-run button in Github commit checks when there are configured identifiers for jobs should now work correctly. (packit-service#1671) Packit now reports a pending state rather than an error on Testing Farm runs in case the related copr build has not finished yet. (packit-service#1669) Users can now allow building in a custom Copr project from a git-forge project. User has to add manually the git-forge project reference to the Copr project settings. As an example, we should add github.com/packit/ogr to the list named Packit forge project allowed in our packit-dev Copr project settings: https://copr.fedorainfracloud.org/coprs/packit/packit-dev/edit#packit_forge_projects_allowed. (packit-service#1638)  Week 39 (September 27th – October 3rd) #   We have improved mapping of Testing Farm Composes, if you have set your own custom mapping and the TF Compose is available, it will be used as is without any additional modifications we do (version, etc.). (packit-service#1675) We have added support for running the tests with Copr builds built by Packit in another pull request (in a different repository). You can read more about this feature in our documentation. (packit-service#1658)  Week 40 (October 4th – October 10th) #   Packit now correctly selects a Testing Farm compose when it\u0026rsquo;s specified correctly in the configuration without an architecture suffix. (packit-service#1689) We have fixed an issue that prevented Packit to work correctly on merge requests on GitLab instances. (packit-service#1683) Packit Service will now replace invalid characters for the Copr projects using the default naming scheme. (packit-service#1684) When we report to set Packit allowed forge projects in the Copr projects, the link for the group projects is now correct. (packit-service#1680) It is now possible to filter changelog entries by specifying lower bound EVR, upper bound EVR or both. (specfile#104)  Week 41 (October 11th – October 17th) #   Packit now correctly authenticates with Bodhi 6 and therefore creates Bodhi updates. 🚀 (packit#1746, packit-service#1704) There are two changes in the naming of the service jobs: The build job type name has been deprecated. It aimed to be an alias when Packit supported just one build type. There are currently more types of builds and just build can be misleading. Please, be explicit and use copr_build instead. The production_build name for upstream Koji build is misleading because it is not used to run production/non-scratch builds and because it can be confused with the koji_build job that is triggered for dist-git commits. (The koji_build job can trigger both scratch and non-scratch/production builds.) To be explicit, use upstream_koji_build for builds triggered in upstream and koji_build for builds triggered in downstream. Users will get a neutral status describing the change when the old names are in use. The status will become a warning starting in November and the old names will be removed by the end of the year. (packit-service#1656) We\u0026rsquo;ve fixed the Markdown table format in the GitHub checks page, which was broken when the user\u0026rsquo;s repo was not allowed to use Packit. (packit-service#1688)  Week 42 (October 17th – October 23rd) #   Packit now won\u0026rsquo;t repeatedly comment in pull requests about the need to migrate configuration of allowed forge projects to Copr. (packit-service#1716)  Week 43 (October 25th – October 31th) #   Fixed an issue with version and release in a spec file being updated even if --no-bump flag was specified. Also fixed an issue when None appeared in release instead of a number. (packit#1753) We have improved the handling of test jobs which should fix related issues with reporting and triggering that occurred when multiple test jobs were configured. (packit-service#1717)  Week 44 (November 1st – November 7th) #   Fixed an issue due to which the repository was never searched for a specfile if specfile_path was not specified, and specfile_path was always set to \u0026lt;repo_name\u0026gt;.spec. (packit#1758) Packit is now able to generate automatic Bodhi update notes including a changelog diff since the latest stable build of a package. (packit#1747) Description of Bodhi updates now contains a changelog diff. (packit-service#1713)  Week 45 (November 8th – November 14th) #   You can re-trigger a Bodhi update via dist-git PR comment /packit create-update. (packit-service#1729) Packit now correctly finds an SRPM when rpmbuild reports warnings while it parses a spec file. (packit#1772) When packit.yaml is present in the repo but is empty, Packit now produces a better error message instead of an internal Python exception. (packit#1769) Retriggering of tests when there is a build job and a test job with an identifier configured was fixed. (packit-service#1731) Packit GitHub app will not modify a package version when release_suffix configuration option is empty. (packit-service#1738) Our specfile parser now supports localized tags (e.g. Summary(fr)) and tags with qualifiers (e.g. Requires(post)). (specfile#132) SRPM build logs are now deleted after 30 days instead of 90 days. This doesn\u0026rsquo;t apply to SRPM builds done in Copr, which deletes the logs after 14 days. (packit/packit-service#1745)  Week 46 (November 15th – November 21st) #   srpm_build_deps can be now configured also on the job configuration level. (packit-service#1757)  Week 47 (November 22nd – November 28th) #   We have changed the limit for our SLO1: it was increased from 15s to 30s to account for setting all statuses. (packit-service#1776) The job names deprecated in October (build alias of copr_build and production_build replaced by upstream_koji_build) newly lead to an error state (was neutral ) of the deprecated status created by Packit. The old names will be removed by the end of the year. (packit-service#1777) The Copr build logs URL now points to logs that are available even while building. (packit-service#1767) Fixed an issue that caused empty lines originally inside changelog entries to appear at the end. (specfile#140)  Week 48 (November 29th – December 5th) #   packit propose-downstream now uploads all remote sources (those specified as URLs) and the source specified by spec_source_id (whether remote or not) to lookaside. Previously, only Source0 was uploaded. Source0 is no longer treated specially, but as spec_source_id is Source0 by default, Source0 is still being uploaded by default unless spec_source_id is overriden. (packit#1778) A VM image build can be triggered inside a PR via a comment command /packit vm-image-build (the job needs to be defined in the configuration). This feature is experimental and is still being tested. (packit-service#1761) Section and Tag objects in specfile library now have normalized_name property for more convenient comparison. There is a new method, Specfile.get_active_macros(), to get active macros in the context of the spec file. The underlying rpm.spec instance is now exposed as Specfile.rpm_spec property. There is a new utility class for parsing NEVRA strings. (specfile#141)  Week 49 (December 6th – December 12th) #   Packit now correctly handles a race condition when it tries to create bodhi updates for builds that are not yet tagged properly. CLI exprience was also improved for this case. (packit#1803) Packit now resets the Release tag during propose-downstream if the version is updated and the Release tag has not explicitly been overridden in the upstream specfile. (packit#1801) If you still don\u0026rsquo;t build SRPMs in Copr you\u0026rsquo;ll get a warning status that you should use srpm_build_deps to be sure that we don\u0026rsquo;t break your workflow once we switch to building all SRPMs in Copr in January. (packit-service#1804) We\u0026rsquo;ve increased internal task retry backoff time in Packit GitHub app from 3 to 7 seconds. We hope this will increase success for network flakes and random infrastructure issues. Creation of bodhi updates should be now more reliable too as Packit will try more times (from 2 to 5). (packit-service#1800) Tags enclosed in conditional macro expansions are not ignored anymore. (specfile#156) Context managers (Specfile.sections(), Specfile.tags() etc.) can now be nested and combined together (with one exception - Specfile.macro_definitions()), and it is also possible to use tag properties (e.g. Specfile.version, Specfile.license) inside them. It is also possible to access the data directly, avoiding the with statement, by using the content property (e.g. Specfile.tags().content), but be aware that no modifications done to such data will be preserved. You must use with to make changes. (specfile#153)  Week 50 (December 13th – December 19th) #   Context managers are no longer shared between Specfile instances, making it possible to work with more than one Specfile instance at a time. (specfile#157)  "}),e.add({id:52,href:"/posts/testing-farm-triggering/",title:"Running tests with builds from another PR",section:"Blog Posts",content:"Do you contribute to projects which depend on each other? Would you like to test changes spanning multiple repositories together before merging them to the main branch? Then look no further, Packit\u0026rsquo;s new feature of the Testing Farm integration is what you are looking for!\nHow it works #  To enable such testing, there is no additional configuration required in your packit.yaml, the typical Testing Farm configuration is sufficient. Once you open a pull request with some changes, tests are going to run as usual with all dependencies being installed based on the test definition, e.g. from Fedora repositories. To trigger tests with builds from a pull request in another repository, add a comment to the pull request of the form:\n/packit test \u0026lt;namespace\u0026gt;/\u0026lt;repo\u0026gt;#\u0026lt;pr-id\u0026gt;  Based on this comment, Testing Farm will first install the recent successful builds created by Packit in the given pull request and then run the tests. In order for this to work, there must be successful builds for the targets that you are running tests for. For example, if you are testing against Fedora 36, the pull request that you want to install builds from must contain a successful Fedora 36 build by Packit.\nLet\u0026rsquo;s look at a simple example to demonstrate this feature better. The Packit CLI uses a library called specfile to modify RPM spec files. Recently, specfile has added a new feature which makes accessing the Epoch field in the spec file more convenient and we would like to make use of this feature. However, the changes have not made it to a Fedora release yet, trying to use this feature will result in an error:\nAs we can see in the screenshots, during artifact installation, the latest specfile release from Fedora was installed, however it lacks the feature that we are looking to test. Let\u0026rsquo;s now retrigger the tests, but specify that we want to install builds from the pull request in specfile which introduced the changes:\nHooray! The copr builds from PR 165 were installed before the tests were run in Testing Farm which enabled us to test the feature inside Packit CLI.\nWrapping up #  We hope that this new feature makes upstream testing even more convenient than it previously was. The feature is still quite new and we would love to hear what you think about it. As always, if you run into any trouble or have any ideas how to improve this functionality, do not hesitate to reach out to us. We will be happy to help.\n"}),e.add({id:53,href:"/posts/weekly/2021/",title:"2021",section:"Weekly Status",content:"Week 1 (January 4th - January 8th) #   Name of the job/command/comment to propose update of downstream package has been synced between CLI and service to propose-downstream. propose-update is now deprecated. (packit#1065, packit-service#913)  Week 2 (January 11th - January 15th) #   Branch deletions are now correctly ignored. (packit-service#919) Multiple internal improvements have been done. (packit#1072, packit-service#922, packit-service#923)  Week 3 (January 18th - January 22th) #   We have temporarily disabled the testing-farm support because the cluster with old runner has died and the new runner is not ready. The tests are now skipped and you get Testing farm is temporarily disabled. status until we have the new runner available. (packit-service#929)  Week 4 (January 25th - January 29th) #   The CLI and the service now detect name of the default branch of a repository instead of assuming it to be called master. (packit#1074, packit-service#924) Build status page now points to the built SRPM uploaded to COPR. (packit-service#889) propose-downstream on source-git repositories now always uses --local-content. (packit#1093) Hunor fixed bug packit#1089 which caused a wrong revision to be used for certain jobs in Packit Service. Tomas improved the reliability of our sandboxing service. (sandcastle#95) Default branches in all our repositories have been renamed from master to main.  Week 5 (February 1st - February 5th) #   The service uses new Testing Farm (API). We are still working on better user experience and fixing bugs. (packit-service#875) MatejF refactored permission system on pull requests and issues comments and renamed whitelist to allowlist. (packit-service#936) The service now retries failed tasks. (packit-service#931) --koji-target option of the CLI\u0026rsquo;s build command now accepts aliases. (packit#1052) The service runs on Fedora 33 now.  Week 6 (February 8th - February 12th) #   --dist-git-branches option in the CLI\u0026rsquo;s propose-downstream command was fixed, it now respects set branches. (packit#1094) The way Packit adds patches to spec-file in source-git repo was improved, now it shouldn\u0026rsquo;t fail if patches are sparsely numbered. (packit#1100)  Week 7 (February 15th - February 19th) #   The service now handles issue/MR comments on Gitlab. (packit-service#985) packit init command now works with CentOS packages. (packit#1106)  Week 8 (February 22th - February 25th) #   Sandcastle can run multiple commands in one sandbox, kudos to Tomas. (sandcastle#93) MatejF \u0026amp; MatejM improved CLI\u0026rsquo;s create-update to work with EPEL and add password prompt. (packit#1122, packit#1127) Service runs builds for targets from build + test jobs, kudos to Laura. (packit-service#996) MatejF did a lot of small fixes and improvements of packit-service. (packit-service#989, packit-service#993, packit-service#994)  Week 9 (March 1st - March 5th) #   Tomas improved the performance of sandcastle, all the user-defined actions now run in one sandbox. This should also speed up the SRPM builds. (packit#1129) You can view the results of jobs directly in our dashboard, kudos to Anchit. (dashboard#73) Jirka implemented setting of the environment context when running the Testing farm tests. (packit-service#1008) In Packit there is a new configuration option sources which overrides the URLs defined in specfiles. (packit#1131, packit#1143)  Week 10 (March 8th - March 12th) #   Jirka worked on setting up GitHub Workflows across all of the Packit repositories to build the container images for Packit Service and push them to Quay.io. Tomáš fixed a bug in the linearization mechanism used when generating patch files from a series of Git commits. (packit#1144) Hunor implemented a way for packit to detect if patch-files generated from Git are identical with the ones already in dist-git. This should help avoiding superfluous changes done by propose-downstream. (packit#1133) Jirka increased the delay (to 3 minutes in total) for Packit Service when retrying downloading the sources during a propose-downstream job. This should give more time for the sources to become available after a release is created. (packit-service#1019) Matěj fixed an ugly bug which caused Packit Service not to react to installation events. (packit-service#1018)  Week 11 (March 15th - March 19th) #   Laura fixed a bug in the processing of GitHub App installations. (packit-service#1020) Jirka fixed a bug that caused improper numbering of patches for source-git. (packit#1164)  Week 12 (March 22th - March 26th) #   Franta improved database schema. It will help us match builds and tests together more easily and solve some UX problems. (packit-service#954) packit init CLI command has been updated to  place downstream packaging files in a subdirectory .distro instead of fedora. (packit#1165) enable using Stream 9 dist-git as a source. (packit#1177)   Laura reworked how specfiles are being synced from downstream dist-git repositories and we are running a PoC for packit\u0026rsquo;s projects to test the new approach. (packit-service#1023) It\u0026rsquo;s possible to specify a distinct test repository for tests in a test job. (packit#1155) (packit-service#1021) centos-stream target is temporarily resolved to centos-stream-8 to reflect a change in Copr. (packit#1167)  Week 13 (March 29th - April 1st) #   Jirka fixed a bug in packit push-update (packit#1191). Matěj introduced the fedora-latest alias for build and test targets, which resolves to the latest branched Fedora Linux (packit#1187). A custom path for the package config (aka packit.yaml) can be specified using a new, top-level -c, --config option (packit#1184).  Week 14 (April 4th - April 9th) #   Honza converted packit\u0026rsquo;s test suite from STI to FMF and configured packit to synchronize the suite to Fedora dist-git (packit#1192). Franta fixed a bug in packit which kept only appending targets to an existing COPR project which is no longer a case - dropped targets are now being removed (packit#1197).  Week 15 (April 12th - April 16th) #   Tomáš fixed an issue in chaining variable definitions in the RPM macros used to set up source-git repositories with packit init (packit#1206). Jirka improved the error message Packit Service emits when the request to start a test in Testing Farm fails (packit-service#1055). Laura made Packit Service to set a status for jobs as soon as the requests are received, and before starting any of the jobs (packit-service#1046). This way users will receive a more immediate feedback about the Service handling their requests.  Week 16 (April 19th - April 23th) #   The current_version_command and create_tarball_command config options are being deprecated in favour of actions. An issue will be created in the affected repositories if we find those options in use. (packit-service#1064) The result pages have been replaced by the views on our dashboard. Let us know what do you think about that and what information do you want to see there. You can expect more changes on this field.  The result views have been implemented by @IceWreck (dashboard#73). The integration on packit-service side has been done by Maťo (packit-service#1056, dashboard#95).    Week 17 (April 26th - April 30th) #   When initiating a new source-git repo, packit adds info about sources to packit.yaml. Also dist-git sources from the lookaside cache are not commited. (packit#1208, packit#1216). Franta added support for git repository cache into packit. The service part is yet to be done (packit#1214). Service reacts to /packit commands only when they appear alone on a line (packit-service#1065, packit-service#1083). Service doesn\u0026rsquo;t create duplicate issues when configuration is invalid (packit-service#1075). We deprecated current_version_command and create_tarball_command in packit config (packit#1212).  Week 18 (May 3rd - May 7th) #   Laura fixed the problem with fedora-latest alias (packit#1222). We now have separate workers for short and long running tasks. This should lead to better responsiveness (packit-service#1059, deployment#202).  Week 19 (May 10th - May 14th) #   Jirka added support for creating Bugzilla bugs for newly created MRs on GitLab (packit-service#1087). The installation instructions for failed or unfinished COPR builds are not displayed on the results page (dashboard#104).  Week 20 (May 17th - May 21st) #   Hunor created an update-dist-git command (packit#1228). Jan: use packit config as a place to create reference to tests (packit#1245).  Week 21 (May 24th - May 28th) #   Jirka added attribute for update-dist-git command to specify the packaging tool (e.g. centpkg). By default, fedpkg is used. (packit#1257, packit-service#1105). Tomáš added support for patch_id in the metadata of source-git commits. (packit#1252) Hunor improved the strategy of checking Copr results when we don\u0026rsquo;t receive that information over message-bus. (packit-service#1104)  Week 22 (May 31st - June 4th) #   We have a new status page, kudos to Jirka! Franta fixed a bug that if some action during propose-downstream caused an upstream git repository to be dirty, the sync for other branches failed. (packit-service#1111) packit generate is not supported anymore. (packit#1269) Tomáš improved the patch ordering. (packit#1263)  Week 23 (June 7th - June 11th) #   Tomáš improved the way changelog is passed from source-git repo to dist-git. (packit#1265) Hunor created a new subcommand source-git to group source-git related commands init and update-dist-git. (packit#1273) František improved API by adding submitted_time to the test result. (packit-service#1113)  Week 24 (June 14th - June 19th) #   Franta started working on packit-service being able to submit test jobs to internal testing farm so teams can test upstream changes against RHEL. (packit-service#1124 packit#1280) Hunor continues working on packit source-git init: CLI is now more streamlined and simplified, and the command produces source-git repos matching our documentation. (packit#1277) Maťo Focko finished his refactoring of the Upstream class - should not have impact on our users, but make the code easier to work with. (packit#1157)  Week 25 (June 21st - June 26th) #   Hunor made several improvements to source-git init\u0026rsquo;s CLI. (packit#1284) Thanks to Frantisek there is now one COPR project/repo used for all releases. (packit-service#1128) Laura fixed a bug in syncing downstream to upstream. (packit#1285)  Week 26+27 (June 28th - July 9th) #  Summer is here and vacations with it. Most of the work done in this sprint is either internal (not user facing) or not finished yet.\n Thanks to MaťejM Packit Service now triggers a new Copr build if no suitable build has been found. That fixes an issue that the service sometimes did not react to /packit test. (packit-service#1132)  Week 28 (July 12th - July 16th) #   We have a new API endpoint for obtaining projects of a given forge. (packit-service#1159) The bug causing that some projects couldn\u0026rsquo;t be loaded in our dashboard was fixed. (packit-service#1161)  Week 29 (July 19th - July 23th) #   Various improvements on our dashboard were done; mainly:  Projects can be filtered by a forge. (dashboard#124) Table with jobs was unified and cleaned. (dashboard#121)   Newly, we use the Checks API to show results on GitHub. You can still see the results on the bottom of the pull-request page, but also in the Checks tab. This gives us more options like status with a neutral state (e.g. currently, for permission errors) or a place for showing more details. Don\u0026rsquo;t forget to give our GitHub application permissions to use it. You can expect more improvements in this field. (packit-service#1167)  Week 30 (July 26th - July 30th) #   Source-git patch metadata: the squash_commits key is deprecated. Instead of using this, set the same patch_name in the commit message of adjacent commits, which should end up in the same patch file. (packit#1309) packit init can now find a spec file inside of a git repository and set it in .packit.yaml. (packit#1313) A lot of work has been done on our dashboard:  Status labels on dashboard have been reworked. New pipelines view for dashboard has been released, where you can see all builds and tests that were recently run for your pull request, release or branch push. Each row represents one pipeline of builds and tests from SRPM all the way to the Testing Farm.\n(dashboard#128)    Week 31 (August 2nd - August 6th) #   sync_release in API allows specifying a suffix for the newly created branch in a dist-git repo fork, so that there can be more open update PRs for the same dist-git branch at the same time. (packit#1326) The behaviour of running tests triggered by /packit test comment was improved. If there is no existing Copr build when the tests are triggered, Packit service should now react and create a new build. Also when the last Copr build status is failed, tests are not submitted and users are informed about this. (packit-service#1188) You can use oraclelinux-7/oraclelinux-8 chroots for build and test of your package on Oracle Linux. (packit-service#1186)  Week 32 (August 9th - August 13th) #   status command of Packit\u0026rsquo;s CLI has been refactored and now provides much cleaner output. (packit#1329)  Week 33 (August 16th - August 20th) #   When reacting to /packit test, Packit service sets a status before starting the job to unify the behaviour with reacting to triggering builds. (packit-service#1187) packit validate-config now checks also the value of the specfile_path configuration option and shows warning if the specified file is not present in the repository. (packit#1342)  Week 34 (August 23rd - August 27th) #   Packit by default locally merges checked out pull requests into target branch. Logging for checking out pull requests was improved to contain hashes and summaries of last commit on both source and target branches. (packit#1344) Packit Service now runs Copr and Koji builds and following tests on Testing Farm for pull requests on the code that would be a result of merging into the target branch. In case merge conflicts occur during preparation of SRPM, you can find more info in the SRPM logs. (packit-service#1206) Packit\u0026rsquo;s CLI source-git update-dist-git now supports using Git trailers to define patch metadata, which will control how patches are generated and added to the spec-file. source-git init uses this format to capture patch metadata when setting up a source-git repo, instead of the YAML one. To maintain backwards compatibility, the YAML format is still parsed, but only if none of the patches defines metadata using Git trailers. (packit#1336) These changes will be applied next week (not this week as usual).  Week 35 (August 30th - September 3rd) #   A bug in Packit that caused purging or syncing upstream changelog (when not configured) from specfile when running propose-downstream was fixed. New behavior preserves downstream changelog and in case there are either no entries or no %changelog section present, it is created with a new entry. (packit#1349)  Week 36 (September 6th - September 10th) #   packit source-git init was updated to try to apply patches with git am first, and use patch only when this fails, in order to keep the commit message of Git-formatted (mbox) patch files in the source-git history. (packit#1358)  Week 37 (September 13th - September 17th) #   Now you can find URL pointing directly to testing farm results on GitHub Checks page. (packit-service#1215) Ogr now supports reacting to the comment with a given reaction, getting them in list and deleting them (only when reaction is added by using ogr API). (ogr#636) Packit now provides PACKIT_RPMSPEC_RELEASE environment variable in actions. (packit#1363) Dashboard no longer shrinks Copr/Koji icons when being open in narrow view. (dashboard#140)  Week 38 (September 20th - September 24th) #   Dashboard now shows more readable format of time, e.g. \u0026ldquo;just now\u0026rdquo;, \u0026ldquo;a minute ago\u0026rdquo;, etc. If you wish to see exact date-time of the run, you can either hover over the time and tooltip with details appear. In case of result pages more readable format is present in the tooltip rather than by default. Also times are now shown in your local time zone. (dashboard#142) Packit can now read commit messages from a patch to support characters which cannot be encoded with UTF-8. (packit#1372) EPEL targets are now being mapped to CentOS Linux inside the internal Testing Farm runs. (packit-service#1225)  Week 39 (September 27th - October 1st) #   Clicking on logo on dashboard no longer opens a new page, but rather reloads the current one. We consider Pipelines view on dashboard to be ready for production use. We\u0026rsquo;re planning to improve the user experience when using pipelines with easier navigation and filtering options. Building the latest development versions of packit and ogr was moved to the packit/packit-dev Copr repo.  Week 40 (October 4th - October 8th) #   A bug in Packit causing issues with local build when the branch was named with prefix rpm has been fixed. To fulfill requests regarding updating targets on Copr repositories, Packit Service will sync targets for the projects created by Packit Service (e.g. pull requests, or non-set Copr repository for releases and branch builds) and for Copr repositories not owned by Packit will try to extend the list if necessary. If you trigger packit jobs with one of /packit _ commands, our bot gives you a 👍 reaction to let you know that we are working on it. Rerunning of failed tasks via GitHub Checks interface is now supported. You are now free to click those \u0026ldquo;Re-run\u0026rdquo; links. ogr documentation is converted to Google-style docstrings. In case there are any discrepancies, missing docs or docstrings in different format, please open an issue.  Week 41 (October 11th - October 15th) #   We have added a new option to Packit CLI when creating Bodhi updates, you can use -b or --resolve- bugzillas and specify IDs (separated by comma, e.g. -b 1 or -b 1,2,3) of bugzillas that are being closed by the update. (packit#1383) Packit will deduce the version for SRPM from the spec file, if there are no git tags or action for acquiring current version defined. (packit#1388) It is possible to use aarch64 architecture in the Testing Farm. (packit-service#1247) Running tests via Testing Farm now supports centos-6 target. (packit-service#1244)  Week 42 (October 18th - October 22th) #   We have introduced new options for generating SRPM packages: (packit#1396)  --no-bump that prevents changing of the release in the SRPM, which can be used for creating SRPMs on checked out tags/releases. --release-suffix that allows you to customize the suffix after the release number, e.g. reference bugzilla or specific branch of the build.   Copr build installation instructions now contain detailed info about the built packages, so you can install the precise build from your pull request. (dashboard#149)  Week 43 (October 25th - November 1st) #   We have introduced a new configuration option merge_pr_in_ci that allows you to disable merging of PR into the base branch before creating SRPM in service. (packit#1395, packit-service#1261) If the upstream spec file is located in a subdirectory (such as packaging/fedora/pkg.spec), it is now correctly synced to the root of the downstream repository, since that\u0026rsquo;s where rpmbuild will look for it. (packit#1402) The \u0026ldquo;Congratulations!\u0026rdquo; comment no longer has a disclaimer about our intentions to stop posting it by default. We have already made that move earlier this year, so the disclaimer is no longer relevant. (packit-service#1260) Deprecated configuration options current_version_command and create_tarball_command have been removed and are no longer supported. They are superseded by actions get-current-version and create-archive. (packit#1397)  Week 44 (November 1st - November 5th) #   We have fixed several issues in packit when it\u0026rsquo;s periodically checking statuses of jobs. You should now reliably see up to date check statuses for Copr RPM builds and Testing Farm runs. (packit-service#1267), (packit-service#1265) Fixed an issue, which raised a UnicodeEncodingError, when working with dist-git patch files with an encoding other than UTF-8. (packit#1406) Backup alias definitions now reflect the official release of Fedora 35. (packit#1405)  Week 45 (November 8th - November 12th) #   You can now specify skip_build option in the test job metadata in the Packit configuration file. This will cause no Copr build to be built and installed into the testing environment, but only trigger the tests in Testing Farm (the selected components to be installed should be part of the TMT definitions). (packit-service#1256) Packit supports changelog-entry action that is used when creating SRPM. The action is supposed to generate whole changelog entry (including -  at the start of the lines) and has a priority over any other way we modify the changelog with. (packit#1367)  Week 46 (November 15th - November 19th) #   A new env config option has been added for specifying environment variables, which are then passed to Testing Farm along with some more pre-defined variables (e.g. name of the project, URL, etc). (packit#1411) (packit-service#1275) The GitHub check run names are now shorter and easier to read. (packit-service#1281)  Week 47 (November 22th - November 26th) #   You can set up a new koji_build job using the commit trigger to submit a Koji build for a new commit in a dist-git branch. The configuration file needs to be present in the dist-git for now (the state for the new commit is used). (packit-service#1278)  Week 48 (November 29th - December 3rd) #   External contributors can\u0026rsquo;t trigger internal tests initially. Project maintainers need to trigger the action via /packit test comment to run the job. (packit-service#1302) (packit-service#1305) A new packit prepare-sources command has been implemented for preparing sources for an SRPM build using the content of an upstream repository. (packit#1424) Packit now visibly informs about an ongoing cloning process to remove potential confusion. (packit#1431) The upstream_package_name config option is now checked for illegal characters and an error is thrown if it contains them. (packit#1434)  Week 49 (December 6th - December 12th) #   Packit now correctly finds the release event if you don\u0026rsquo;t use the version as a release title. (packit#1437)  "}),e.add({id:54,href:"/posts/fas-verification-automation/",title:"Automation of FAS verification in Packit Service",section:"Blog Posts",content:"As you may already know, for using Packit Service GitHub App we require our users to have a valid Fedora Account System account. We were verifying the newcomers until now manually, but in recent weeks, we have implemented an automated solution for it. Let\u0026rsquo;s take a closer look at how it is done currently and what have we improved!\nFormerly, the process of verification by us started by waiting for the users to provide us their FAS username, then checking whether the provided FAS account exists and matches, and finally, manually adding the account to our allowlist in the database. For the communication with new users, we have used our packit/notifications repository on GitHub where we created an issue for each new installation.\nAlthough in general, this worked, it required human interaction and since we are not available 24/7, the verification wasn\u0026rsquo;t immediate. We wanted to simplify the process for both users and us. Since in FAS, everyone can set their GitHub login that is then publicly available, we decided to utilize this setting.\nSo how does the verification work now?\nFor each new GitHub installation, we first check whether there isn\u0026rsquo;t a FAS account with the same login as the one that triggered the installation. If we find such an account, we check whether the GitHub Username in this FAS account matches the GitHub login of the one that triggered the installation. To get the information about the FAS accounts, we use the fasjson-client library. If this check doesn\u0026rsquo;t prove any match, we create an issue in the packit/notifications repository as previously. This is what it looks like:\nAs you can see, it contains instructions on how to trigger the verification automatically. So, everything the person who installed the app needs to do is set the GitHub Username field in their FAS account (if they don\u0026rsquo;t have it set already) and then provide the FAS login via Packit comment command /packit verify-fas the-fas-account.\nOnce the user does this, our service runs the same verification again (with the FAS username provided in the command) and informs users about the status via a comment in the same issue. The successful verification looks like this:\nThis should save both users and our time and hopefully make the onboarding process smoother for the newcomers. Since this is a pretty new feature, let us know whether there is something that is not clear so that we can improve it.\n"}),e.add({id:55,href:"/posts/weekly/2020/",title:"2020",section:"Weekly Status",content:"Week 1 #  packit #   Correctly updates version on srpm build. (#642) Downloads all URL sources before srpm build. (#643)  packit service #   Runs on Fedora 31. (#303, #304) Correctly checks list of whitelisted repositories when issue comment is added. (#309)  Week 2 #  packit #   Incorporates lots of SRPM related improvements. (#646, #650, #651, #652, #653) Better handles when Copr owner is not set. (#648)  packit service #   Fixes SRPM exceptions/errors handling. (#311, #317) Has loading of config fixed. (#318)  Week 3 #  packit #   Uses Marshmallow for configuration schema. (#657) Is able to build in Koji from upstream/source-git. (#658) Doesn\u0026rsquo;t download remote sources when \u0026ldquo;sources\u0026rdquo; path exists in upstream. (#659) Configuration file allows list syntax in action commands. (#663) Configuration can use a new option to exclude paths from patching. (#666) Has few less bugs. (#660, #661, #664, #667)  packit service #   Uses Marshmallow for configuration schema. (#320) Runs build for test job even when it\u0026rsquo;s not explicitly configured. (#324) Reports invalid or missing packit config. (#328) Status workflow has been changed and simplified. (#338) Minor fixes. (#323, #326, #329, #331, #335, #336)  Week 4 #  packit #   0.8.1 has been released. CLI has bash auto completion. (#654) Few bugs have been squashed. (#668, #670, #676, #677, #678, #680, #682)  packit service #   More checks messages have been unified. (#355) One more testing-farm status is now shown before the tests are submitted. (#343) No-fmf scenario has better messages. (#362) Minor fixes and improvements. (#339, #340, #342, #345, #346, #347, #348, #352, #353, #350, #357, #358, #361, #364)  Week 5 #  packit #   CLI has a new command for local build. (#687) Logs less. (#685)  packit service #   Minor fixes and improvements. (#365, #371, #373, #376)  Week 6 #  Both Packit and Packit Service pre-commit hooks were updated to include prettier and setup-cfg-fmt, in order to have a more consistent formatting of markup, YAML, JSON and setup.cfg files.\nIt became easier for developers to build the Packit base image locally, and tests in Zuul were configured to run on Fedora 31.\nPackit learned how to look for RPM spec files on its own, so specifying specfile_path in the configuration is not mandatory anymore. Packit will recursively search the tree and use the first spec file found.\nThe Redis pod in Packit Service uses an up to date image now, based on Fedora 31. Kudos to hhorak for the help!\nWeek 7 #  The default configuration generated by Packit has test jobs enabled from now on. This should simplify configuring Packit in new repositories.\nFixed a bug which was causing SRPM-build failures in Packit Service for projects which had their spec files stored in a subdirectory.\nAs a result of keys.fedoraproject.org being turned off, Packit now tries a list of GPG keyservers when downloading keys to check commit signatures.\nWhen enabling Packit Service for new GitHub repositories, instead of checking if the requester is a Fedora packager, we\u0026rsquo;ll check if they signed the Fedora Project Contributor Agreement.\nWhile proposing an update to Fedora, Packit Service will report a failure now when there are no releases found in the upstream GitHub repository.\nTest results became serializable, we will not block when no test results are received, and Packit Service received some initial code to enable using PostgreSQL as a data backend.\nWeek 8 #  Postgresql database was introduced in production environment to improve performance and enable implementation of new features, e.g. storing logs to reduce amount of messages sent directly to pull request (#406), (#420).\nCleanup in configuration files was performed, so no longer needed values were removed from .packit.yaml (#709). User experience was improved by adding new --upstrem-ref option to copr-build command in command-line interface (#718) and making error reporting more robust by adding new fedpkg clones related error message (#714).\nFollowing bugs were fixed:\n bug in copr-build command fixed (#713) get_local_package_config() duplicate entries in \u0026lsquo;directories\u0026rsquo; bug fixed (#715)  Week 9 #  packit #   Dist-git patches are now applied in source-git repos with -p1 to resolve an issue when they are generated with git and patch program fails to apply them (#730). Fedora 32 was added to \u0026lsquo;fedora-all\u0026rsquo; and \u0026lsquo;fedora-development\u0026rsquo; aliases (#731). We have put more links to our documentation (README, deprecation warning in packit) so that people can easily correct their configuration files (#726).  packit-service #   targets key in copr job definition in the packit.yaml is no longer a required field (it defaults to fedora-stable) (#431). Builds are now correctly linked to their actual GitHub projects (this can be seen in the logs view) (#441).  Week 10 (March 2nd - March 6th) #  packit #   The generate command is now deprecated in favour of the init command (#728), contributed by @shreyaspapi.  packit-service #   When a non-collaborator creates a PR, packit says that only \u0026ldquo;Collaborators can trigger packit-service\u0026rdquo; - this message has been improved to better match the reality (#445). Packit service no longer posts comments on pull requests when a SRPM can\u0026rsquo;t be created - the logs should be now aviable in the service\u0026rsquo;s logs view available when clocking on the commit status check URL (#447). Commands to control packit service can now be embedded in a comment (previously, the whole comment was treated as a command) - hence you can now create a comment to give an update and also trigger packit (#433), contributed by @IceWreck. We have improved monitoring of packit-service by using more sentry.io\u0026rsquo;s features (#458). You can now disable the functionality when packit service comments on a PR when it gets built for the first time (notifications: {pull_request: {successful_build:: false}} in your packit.yaml), hi Lars! (#455).  Week 11 (March 9th - March 13th) #  packit #   We have changed how packit treats version and release in the spec file (#748).  We handle the git-describe output better which should help when tags contain dashes (#759).   When packit adds source-git patches into a spec file it adds them outside of rpm macros now (#760). In pull request pipelines we run the packit-service tests so that we are sure we do not break the service (#752).  packit-service #   Comments from packit-service about successful propose-update in the issue which triggered the update now include the URL of the new pull-request in Fedora (#472). We have done some major refactoring how jobs are processed (#476), (#746), (#453). Development and debugging of the packit-service should be easier now, we documented how to run packit-service locally (#473).  Week 12 (March 16th - March 20th) #  packit #   When you are executing copr-build command, you do not need to set the project name if this value is defined in the copr_build job in the configuration file (#763). All patches generated from a source-git repo are now prefixed with a number so they are easy to sort (#765). We improved the behaviour when loading the authentication in the config file - users are warned only if deprecated keys are used, no more confusing messages when you do not have authentication key in the configuration (#754).  packit-service #   We periodically check the status of the copr-build so that we do not need to rely on the Fedora message bus. This should avoid failures in build status reporting (#490). Propose-update triggered by comment in GitHub now recognizes also pre-releases (#498). Several bugs in how we report results from Testing farm have been fixed and Testing farm results should now appear correctly in commit status checks (#496), (#505), (#510), (#513).  Week 13 (March 23th - March 27th) #   New Packit version 0.9.0 was released. Packit Service now mostly uses PostgreSQL instead of Redis as a backend, which will result in more responsive API and Dashboard.  Week 14 (March 30th - April 3rd) #  packit #   Fix web URLs for Copr builds owned by groups (#778). Create downstream spec if it\u0026rsquo;s not there (propose-update) - this used to happen when using packit on a newly created package in Fedora which did not have spec fille added yet. (#779) Packit no longer inspects archive extension set in Source and creates .tar.gz by default - this should be more flexible and prevent issues for \u0026ldquo;non-standard\u0026rdquo; archive names. (#781)  packit-service #   Several fixes and improvements after switching data store from Redis to PostgreSQL. Use the configured COPR project when triggering Testing Farm (tests no longer fail for projects which are built in their own COPR namespace) (#524).  Week 15 (March 6th - April 9th) #  packit #   Tomáš finished teaching packit srpm to linearise extremely complex Git histories, in order to get patches that can be applied when building the SRPM. Jirka made the schema validation code Marshmallow3 compatible. This enables building packit in Fedora 32 and Rawhide.  packit-service #   Franta fixed an issue with parsing release events. Jirka made code Marshmallow3 compatible in this project, too.  Week 16 (April 14th - April 17th) #  packit \u0026amp; packit-service #   Job metadata field dist-git-branch is now marked as deprecated, to be replaced by dist_git_branches to match the naming of other metadata fields and to accept multiple branch names where Packit should work. (#797, #788 and #564). A great deal of refactoring, CI work and general code improvements which will make Packit and Packit Service run smoother and development easier.  Week 17 (April 20th - April 24th) #  packit-service #  In this week we mostly focused on CentOS Stream and some under the hood improvements, none of which are available for GitHub projects.\n Jano did a lot of work on initial CentOS Stream integration. Hunor added a Pagure build status reporting. Anchit added first API tests and improved build statuses given by the API. Laura and Rishav improved how data about Copr builds are stored in our db.  Week 18 (April 27th - April 30th) #  packit-service #   Franta did a great deal of service \u0026amp; worker refactoring related to CentOS (#586) and to forks usage in GitHub. (#589) Hunor fixed confusing GitHub status messages while building in Copr. (#588)  Week 19 (May 4th - May 6th) #  packit #   The image now uses ogr from git master instead of from Fedora stable RPM.  packit-service #   Franta Fixed a previous week introduced bug, which prevented users from being whitelisted. (#599) Hunor Made improvements to avoid a race condition in getting app access token. (#601)  Week 20+21 (May 11th - May 22th) #  packit #   The debug logs in the CLI are now much more consistent. (#824) A bug in the propose-update causing problems with the synchronization of the spec-file content was fixed. (#830) You can now use epel-all alias in the arguments and also in the configuration. (#835)  packit-service #   In job definition for packit-service you can use epel-all alias as well. (#835)  Week 22 (May 25th - May 29th) #  packit #   The problem with kerberos initialization was fixed. (#838) We released a new version of the packit package. (release 0.11.0) We have been also working on some smaller issues and preparation steps for our future work. (#841, #843, #846, #847)  packit-service #   Jirka implemented creating a new bug in Bugzilla for CentOS Stream pull-requests (#627). This will be triggered when the label \u0026ldquo;accepted\u0026rdquo; is added to a PR in the (near) future. You will be able to use aliases also for koji builds. (packit:#839, #632) Laura fixed a problem with missing builds when triggering Packit Service with /packit test. Now, we trigger the build first if there are no builds for the pull-request yet. (#631)  Week 23 (June 1st - June 5th) #  Hello everyone, during this week we didn\u0026rsquo;t manage to implement any significant new features - most of the work happened under the hood.\npackit #   We have fixed a formatting issue when packit prints installation instructions for using builds from a copr repo (by @lachmanfrantisek, #852). You are able to set up builds when you push to a branch, we have set this up for master branch of packit, feel free to get inspired (by @lachmanfrantisek, #851).  packit-as-a-service #   We have run into multiple problems when you set up jobs for PRs and branch pushes - there were multiple fixes for this, packit-service wasn\u0026rsquo;t able to work well with the fact that there are multiple jobs defined for the same job type - e.g. build.  Week 24 (June 8th - June 11th) #  packit #   Tomas re-implemented overriding of package config per job. This will enable overriding configuration for builds and releases once the corresponding changes are merged in Packit-as-a-Service. (#858, #859).  packit-as-a-service #   We are now parsing events from Koji about the progress of the builds and report them (by Franta, #657). We are now able to listen to Gitlab hooks and parse the (comment \u0026amp; push) events (by Shreyas, #629, #671). Log pages have been restructured by linking SRPM build logs instead of including them (by Hunor, #641).  Week 25 (June 15th - June 19th) #  packit #   Packit logs more information for RebaseHelper errors (by @csomh, #865).  packit-as-a-service #   Obtaining builds via packit API endpoint is now significantly quicker (by @IceWreck, #674). We now have an API endpoint for obtaining results from testing farm (by @IceWreck, #678). We finished the implementation of the trigger to create bugs in Bugzilla. Therefore packit is now able to create bugzilla for accepted PR\u0026rsquo;s in CentOS (by @jpopelka, #662).  Week 26 (June 22th - June 26th) #  packit #   packit now supports using custom repositories and packages when building in Copr and has options to preserve the project and to list it in on the Copr home page @lachmanfrantisek, #872. Custom commands defined by user in packit config now are run in the shell, no more bash -c required (by @TomasTomecek, #871). packit now includes pull request ID in version of rpm. (by @sturivny and @TomasTomecek, #870).  packit-as-a-service #   We added support for copr builds in gitlab (by @shreyaspapi, #683). packit-service utilizes the new options introduced in packit (by @lachmanfrantisek, #694).  Week 27 (June 29th - July 3rd) #  packit #   We introduced a new command packit validate-config which validates the contect of a package configuration file in your project (contributed by @TomasJani, #826).  packit-as-a-service #   You are now able to override configuration for builds, releases and other jobs (by @TomasTomecek, #676). Read more about this feature here.  Week 28 (July 6th - July 10th) #  packit #   Command validate-config works properly now and does not produce odd error messages, by @TomasTomecek and @csomh, #894 and #895 You will now properly see git-describe metadata in the %release field in spec file when using srpm command, by @TomasTomecek, #894 git-log is being used to get a list of commits between HEAD and latest tag to pick up commit messages and add those to %changelog, by @TomasTomecek, #889 packit is now able to load metadata from commits of a source-git repo and utilize them when creating patch files, by @lachmanfrantisek, #875  packit-as-a-service #   We now have a new API endpoint: /api/projects/, by @IceWreck, #716 Over the last few weeks, @lbarcziova was very busy with refactoring how jobs and tasks are being executed in packit-service. This work is now complete which allows us to scale the deployment up while giving us better introspection in what\u0026rsquo;s happening inside, by @lbarcziova, #704  Week 29 (July 13th - July 17th) #  Copyright (c) Dominika Hodovska. This work is licensed under a Creative Commons Attribution 4.0 International License.\nWeek 30 (July 20th - July 24th) #   Anchit added a few new API endpoints to Packit-as-a-Service to retrieve project information. This is used in the Dashboard, to provide an overview of the projects served by Packit.  Week 31 (July 27th - July 31st) #   Jano did a lot of work on our deployment. The installation of all our dependencies is much simpler now. (packit-service#747, packit-service#753, packit-service#756, packit-service#757, packit#919), Packit now puts a link to our documentation in a pull request status when a contributor is not allowed to build the PR, thanks to Tomáš. (packit-service#758)  Week 32 (August 3rd - August 7th) and 33 (August 10th - August 13th) #   We renamed our GitHub organisation to packit. That user had been inactive for a long time and Hunor\u0026rsquo;s request was successful. The Copr project settings are now changed only if needed. If we can\u0026rsquo;t edit the settings, we ask for the admin access to the Copr project and the service shows you a table with the changes if you want to do the edit manually. (packit#921, packit-service#764) Matej fixed an old bug with the custom command for creating archives. The archive was not found when building SRPM because of the incorrect processing of the paths from the command output. (packit#923)  Week 34 (August 17th - August 20th) #   Tomas tought packit how to merge related commits, which were previously created by git-am applying of a multiple commit patch. (packit#933) Anchit added new /api/srpm-builds/ endpoint. Service now requests \u0026lsquo;builder\u0026rsquo; permission for custom projects if needed. Franta fixed a problem with only one job executed executed for 2 build definitions for the same trigger.  Week 35 (August 24th - August 28th) #   Tomas improved logging of the Packit actions\u0026rsquo; output. (packit#950) Anchit fixed and enhanced the /api/srpm-builds endpoint. (packit-service#788)  Week 36 (August 31th - September 4th) #   We store the submission time of SRPM builds now (packit-service#795 by Anchit). Shreyas improved implementation of the build status reporting (packit-service#740). Anchit enhanced the /koji-builds endpoint to be more consistent with /copr-builds endpoint (packit-service#791).  Week 37 (September 7th - September 11th) #   Stage now uses Tokman to get access tokens for GitHub, which should resolve race condition when running parallel jobs (Tokman by Hunor, ogr integration by Matej). Franta has addressed problems with Testing-Farm cluster with custom response on PRs that links to more information (pinned info, packit-service#798).  Week 38 (September 14th - September 18th) #   The combination of the source-git patches with existing patches now works well (packit#963). Service now mostly supports also GitLab as you can see here or here. A lot of small issues were fixed in the last week (packit-service#806, packit-service#812, packit-service#814, packit-service#815, packit-service#816 ). Created Copr projects are now prefixed with the hostname for non-GitHub services and also support multipart namespaces (packit-service#819). Laura fixed two testing-farm related issues (packit-service#808, packit-service#809). You can now use test job also on Pagure and GitLab thanks to that.  Week 39 (September 21st - September 25th) #   Packit-service can be configured to work with private namespaces. This is plumbing work which we need right now for CentOS Stream. We are not planning to enable this for GitHub - packit-service will still work only for public repositories, private ones are ignored. packit-service#831 If git tag contains more information than just version (e.g. pkg_name-v1.2.3), it is possible to use upstream_tag_template to extract version from the tag, which will be used in a subsequent task. doc packit#959 Added support for globbing pattern in upstream_ref. doc packit#960 Packit --remote is global option now and available for all commands. Because of this sync-from-downstream --remote was renamed to --remote-to-push. Remote can now be specified in the user\u0026rsquo;s config (via upstream_git_remote parameter). packit#977  Following bugs were fixed:\n Packit dropping leading zeros in version. packit#814 Packit CLI issue caused by picking incorrect copr project name. packit#971  Week 40 (September 28th - October 2nd) #   Packit-service is now explicitly checking if requested copr-build targets exist and if not, the user is informed about it. packit-service#835 We have improved the way how packit updates %setup line in a spec file - you are now able to set content of -n option via archive_root_dir_template config option, it defaults to {upstream-pkg-name}. doc packit#834 Packit is able to generate a patch file with format-patch without leading a/ and b/ in the patch diff. Required for patches in dist-git which are applied with -p0. Contribution guidelines were updated, now we have one shared link.  Week 41 (October 5th - October 9th) #   franta made triggering of jobs more reliable and in correct situations (packit-service#837)  Week 42 (October 12th - October 16th) #  Nothing significant happened during this week. The only change was that Hunor resolved a problem when sentry client library (the alert service we use) caused errors in stage environment and hence the problem didn\u0026rsquo;t make it to production.\nWe have also released a new version of packit: 0.18.\nWeek 43 (October 19th - October 24th) #  We finally had a week with plenty updates!\n We found out the hard way that one cannot build in Fedora koji directly from SRPM unless it\u0026rsquo;s a scratch build. The discussion with Fedora rel-eng is happening at pagure.io/releng/issue/9801 and in the meantime, all koji builds will be halted on our side since we know they cannot succeed. Do scratch: true for koji builds before this gets resolved. Packit creates a symlink for a generated archive at the root of the project. So far it only did it from a relative path and now absolute paths are supported as well. This is useful when your specfile is placed in a subdirectory and rpmbuild can\u0026rsquo;t find the archive. There is a new usability improvement to proposing a new downstream update. If the PR is already created, packit won\u0026rsquo;t create it again. You will no longer receive duplicate downstream PRs in dist-git. When doing a new downstream update, packit doesn\u0026rsquo;t sync %changelog since those are usually out of sync between upstream and downstream. Packit creates a new entry for the new release in the downstream. There is a new packit.yaml configuration option sync_changelog which bypasses this behaviour and copies the %changelog from upstream and overwrites the downstream changelog. Please use this option only when your changelogs are in sync. Documentation  Week 44 (October 26th - October 30th) #  No user-facing changes in packit(-service) this week.\nWeek 45 (November 2nd - November 6th) #   Laura implemented an option for packit to copy description from a release into a changelog when running propose-update. Also the default message has been changed to the list of commit messages from last release. (packit#1004) Jano improved handling of build targets in packit. (packit#986) Tomas improved an experience of a contributor to source-git in case the contributor doesn\u0026rsquo;t follow git-am patches style that is used. (packit#1000)  Week 46 (November 9th - November 13th) #   Tomas improved the UX of logging in the CLI. (packit#1014) Jano improved logic of acquiring current version in the CLI. (packit#1013) We appreciate getting feedback from our users, if you could find some time to do so, there is an open issue for it.  Week 47 (November 16th - November 20th) #   Matej fixed an issue with Packit CLI, enabling recursive search for spec-files (packit#1005). It turned out, this change made it very easy to deplete GitHub API quota, so it was reverted. Laura made Copr builds to be part of the default jobs. This will cause build jobs to explicitly run, and display their own result flags in PRs, next to the test results. We hope this to be a more friendly behaviour for our new users (packit#1024).  Week 48 (November 23rd - November 27th) #   Laura fixed a bug, where Packit Service failed to trigger Copr builds before triggering the tests in case triggering Copr builds was configured for a different event. Thanks to Matej, Packit Service will now comment on commits in case Copr builds fail after a merge, in order to indicate the reason for the failure. Packit Service will soon stop commenting on PRs after the first successful build. The installation instructions from these comments were moved to the result page by Laura, while Matej added a warning to inform users about this upcoming change.  Week 49 (November 30th - December 4th) #   Jano fixed a bug in sync_release method of Packit API. (packit#1043) Jiri Konecny contributed a fix for how Packit creates COPR urls. (packit#1039) Laura updated instructions how to retrigger a job. (packit-service#892)  Week 50 (December 7th - December 11th) #   Tomas implemented the --upstream-url option of packit init command. When specified, init also sets up a source-git repository next to creating a configuration file.  Week 51 (December 14th - December 18th) #   Congratulations comments are now disabled by default, unless enabled in config. A bug, which prevented npm to be run during SRPM build, has been fixed. (sandcastle#86)  "}),e.add({id:56,href:"/posts/downstream-automation/",title:"Downstream automation is here",section:"Blog Posts",content:"Downstream automation is here #  Finally, it\u0026rsquo;s here. Now, you can do the whole Fedora release with the help of Packit. Let\u0026rsquo;s take a look at how it works on an example of OGR, the Python library we develop.\nUpstream #  The process of releasing a new version starts in the upstream repository. Here, we can see an upstream release:\nPropose downstream #  As the first step on our way to Fedora users, we need to get the new upstream release to the Fedora dist-git. This is what we call propose-downstream job. Here is a snippet from the config file of OGR:\ndownstream_package_name: python-ogr copy_upstream_release_description: true  jobs:  - job: propose_downstream  trigger: release  dist_git_branches:  - fedora-all  - epel-8 How does the propose-downstream work? As a first step, the archive is saved to lookaside cache and after that, Packit updates the dist-git content (mainly sources file and spec-file) via pull-requests for the specified branches. (Direct push is possible only for CLI by setting a create_pr option to false.)\nIf you use copy_upstream_release_description: true, as in the config above, the changelog entry will use the GitHub release description field. (Just make sure the formatting is compatible with spec-file. E.g. use - instead of * for lists to not create multiple changelog entries.)\nAnd how is it triggered? Packit gets the information about the newly created release from GitHub (via webhook), loads the config from the release commit and if there is a propose-downstream job defined, the workflow begins.\nHere are the pull-requests created by Packit:\nAnd here are the details of the one created for f35 branch:\nNow, it\u0026rsquo;s on downstream CI systems and maintainer to check the changes and merge the pull-request.\nKoji #  If Packit sees a new commit in the configured dist-git branch, it submits a new build in Koji like maintainers usually do. (The commits without any spec-file change are skipped.)\nHere is a job definition for the package we use as an example:\njobs:  - job: koji_build  trigger: commit  dist_git_branches:  - fedora-all  - epel-8 There is no UI provided by Packit for the job, but it is visible across Fedora systems (like you can see in the following image) like a manually created Koji build and you can utilise Fedora Notifications to get informed about the builds.\nBodhi #  Once Packit is informed (via fedora-messaging bus) about the successful Koji build, it creates a new update in Bodhi for you.\nHere is a job definition:\njobs:  - job: bodhi_update  trigger: commit  dist_git_branches:  - fedora-branched # rawhide updates are created automatically  - epel-8 The packit config is loaded from the commit the build is triggered from.\nHere is an example of the resulting Bodhi update:\nAnd that\u0026rsquo;s all. The rest is on the users and maintainers to give the update enough Karma so the update gets to the users.\nConclusion #  Does it look simple? Yes, it is. We try to automate as much as possible but still leave the space for human intervention where it is needed \u0026ndash; pull-request review and verification of the Bodhi update. Of course, in case of some errors, a human can (and should) replace the work of a bot. Other manual, mundane and waiting tasks are replaced by Packit.\nPlease, try it yourself and let us know what do you think. Those jobs are really new and some issues might occur. But we will try to fix those and if you have any suggestions for improvement, please, create an issue so we can see if the request is doable and we can try to implement it. And of course, code contribution is more than welcome as well.\n"}),e.add({id:57,href:"/posts/weekly/2019/",title:"2019",section:"Weekly Status",content:"Initial version 0.1.0 of packit is out! (2019-03-08) #  We would like to announce general availability of the initial version of packit, titled \u0026lsquo;0.1.0\u0026rsquo;.\nSince this is our first release, we would like to ask you to be patient if you encounter any issues. We work hard on packit\u0026rsquo;s usability. If you feel like that packit is doing something weird or if anything is unclear, don\u0026rsquo;t hesitate and reach out to us by creating a new GitHub issue.\nThe initial release contains two commands:\n packit propose-update — Opens a pull request in dist-git for the latest upstream release of a selected repository. packit watch-releases — Watches events for all the upstream releases and performs propose-update for those who use packit.  Installation #  $ dnf install --enablerepo=updates-testing packit Or\n$ pip3 install --user packitos Or (if you\u0026rsquo;re brave)\n$ pip3 install --user git+https://github.com/packit-service/packit Requirements #  Present features have strict requirements on the upstream projects:\n  You need to have a packit config file present in the upstream repo.\n  You need to have spec file present in the upstream repo.\n  This workflow is suitable for people who are both upstream and downstream maintainers of the particular project. If you don\u0026rsquo;t fit into that bucket, then packit might not be ready for you, yet. Please wait till we land more source-git related functionality into packit.\npropose-update #  I\u0026rsquo;m going to demonstrate this functionality on ogr, our library for git forges, which powers packit.\nIt was recently approved for Fedora, so we can use packit to bring the initial version of ogr into Fedora Rawhide, 30 and 29.\nDo we have everything? #  Let\u0026rsquo;s see guide for the propose-update command on what we need:\n0. The upstream repository with a valid upstream release. #  $ git remote -v origin git@github.com:TomasTomecek/ogr.git (fetch) origin git@github.com:TomasTomecek/ogr.git (push) upstream https://github.com/packit-service/ogr.git (fetch) upstream https://github.com/packit-service/ogr.git (push) Yup.\n$ git tag --list 0.0.1 0.0.2 0.0.3 $ git checkout 0.0.3 Note: checking out \u0026#39;0.0.3\u0026#39;. And the tag name is matching the version in a spec file:\n$ grep Version python-ogr.spec Version: 0.0.3 1. Packit config file placed in the upstream repository. #  $ ll .packit.yaml -rw-rw-r--. 1 tt tt 177 Mar 1 17:44 .packit.yaml Check.\n2. Spec file present in the upstream repository. #  $ ll python-ogr.spec -rw-rw-r--. 1 tt tt 1.3K Mar 1 17:43 python-ogr.spec :+1:\n3. Pagure API tokens for Fedora Dist-git. #  $ env | grep TOKEN PAGURE_USER_TOKEN=will PAGURE_FORK_TOKEN=not GITHUB_TOKEN=share, sorry 4. Valid Fedora Kerberos ticket. #  $ kinit ttomecek@FEDORAPROJECT.ORG Password for ttomecek@FEDORAPROJECT.ORG: $ klist Ticket cache: KEYRING:persistent:1024:krb_ccache_g0t1Ty3Ah Default principal: ttomecek@FEDORAPROJECT.ORG Valid starting Expires Service principal 03/01/2019 18:12:25 03/02/2019 18:12:19 krbtgt/FEDORAPROJECT.ORG@FEDORAPROJECT.ORG renew until 03/08/2019 18:12:19 We\u0026rsquo;re all set!\nTime to shine #  We are still in the \u0026ldquo;ogr\u0026rdquo; upstream git repository.\n$ packit propose-update INFO: Running \u0026#39;anitya\u0026#39; versioneer ERROR: Failed to determine latest upstream version! Check that the package exists on https://release-monitoring.org. using \u0026#34;master\u0026#34; dist-git branch syncing ./python-ogr.spec INFO: Downloading file from URL https://files.pythonhosted.org/packages/source/o/ogr/ogr-0.0.3.tar.gz 100%[=============================\u0026gt;] 17.95K eta 00:00:00 downloaded archive: /tmp/tmp2e65b0xt/ogr-0.0.3.tar.gz uploading to the lookaside cache PR created: https://src.fedoraproject.org/rpms/python-ogr/pull-request/1 Mind-blowing, isn\u0026rsquo;t it? Now we have latest python-ogr in Fedora Rawhide by running only a single command.\nI have also added ogr into release-monitoring as packit suggests.\nOnce we are okay with the changes, we have to merge the pull request. That\u0026rsquo;s our responsibility, as maintainers.\nBuilding in koji #  Time to build the package (packit doesn\u0026rsquo;t support building in koji, yet)\n$ fedpkg clone python-ogr Cloning into \u0026#39;python-ogr\u0026#39;... remote: Counting objects: 8, done. remote: Compressing objects: 100% (5/5), done. remote: Total 8 (delta 0), reused 5 (delta 0) Receiving objects: 100% (8/8), done. $ cd python-ogr $ git log commit c298df5e540ba1d010366e102c1c75d4f5b0b0cc (HEAD -\u0026gt; master, origin/master, origin/HEAD) Author: Tomas Tomecek \u0026lt;ttomecek@redhat.com\u0026gt; Date: Fri Mar 1 18:15:00 2019 +0100 [packit] 0.0.3 upstream release more info Signed-off-by: Tomas Tomecek \u0026lt;ttomecek@redhat.com\u0026gt; commit 7d5ab1471ca0ee2a6c0254410b83beaa83b80f0b Author: Gwyn Ciesla \u0026lt;limb@fedoraproject.org\u0026gt; Date: Fri Mar 1 15:18:34 2019 +0000 Added the README Yup, that\u0026rsquo;s our commit. more info was added there by accident, this is already fixed in packit.\n$ fedpkg build Building python-ogr-0.0.3-1.fc31 for rawhide Created task: 33125435 Task info: https://koji.fedoraproject.org/koji/taskinfo?taskID=33125435 Watching tasks (this may be safely interrupted)... 33125435 build (rawhide, /rpms/python-ogr.git:c298df5e540ba1d010366e102c1c75d4f5b0b0cc): free 33125435 build (rawhide, /rpms/python-ogr.git:c298df5e540ba1d010366e102c1c75d4f5b0b0cc): free -\u0026gt; open (buildvm-14.phx2.fedoraproject.org) 33125451 buildArch (python-ogr-0.0.3-1.fc31.src.rpm, noarch): open (buildvm-14.phx2.fedoraproject.org) 33125436 buildSRPMFromSCM (/rpms/python-ogr.git:c298df5e540ba1d010366e102c1c75d4f5b0b0cc): closed 33125435 build (rawhide, /rpms/python-ogr.git:c298df5e540ba1d010366e102c1c75d4f5b0b0cc): open (buildvm-14.phx2.fedoraproject.org) -\u0026gt; closed 0 free 1 open 2 done 0 failed 33125464 tagBuild (noarch): closed 33125451 buildArch (python-ogr-0.0.3-1.fc31.src.rpm, noarch): open (buildvm-14.phx2.fedoraproject.org) -\u0026gt; closed 0 free 0 open 4 done 0 failed 33125435 build (rawhide, /rpms/python-ogr.git:c298df5e540ba1d010366e102c1c75d4f5b0b0cc) completed successfully That was rough, can\u0026rsquo;t wait to do this with packit.\nLet\u0026rsquo;s do Fedora 30 now:\n$ packit propose-update --dist-git-branch f30 INFO: Running \u0026#39;anitya\u0026#39; versioneer using \u0026#34;f30\u0026#34; dist-git branch syncing ./python-ogr.spec INFO: Downloading file from URL https://files.pythonhosted.org/packages/source/o/ogr/ogr-0.0.3.tar.gz 100%[=============================\u0026gt;] 17.95K eta 00:00:00 downloaded archive: /tmp/tmpl5xxq22x/ogr-0.0.3.tar.gz uploading to the lookaside cache PR created: https://src.fedoraproject.org/rpms/python-ogr/pull-request/3 And so on\u0026hellip;\nConclusion #  As you can see, packit is useful for us right away.\nWe\u0026rsquo;ll be delighted if you try it out and let us know what you think.\nPackit 0.2.0 is here! (2019-03-19) #  Our sprint nears an end which means we have released a new version of packit - 0.2.0! You can expect a new release after every sprint (i.e. every 2 weeks).\nThe 0.2.0 version has a bunch of new features and improvements: you can find a complete list in the changelog. We also have a detailed documentation for all the workflows packit covers.\nLet\u0026rsquo;s get through what\u0026rsquo;s new:\n We have decided to rename two keys in our config file so they are more descriptive. Old names still work but they are deprecated:  package_name → downstream_package_name upstream_name → upstream_project_name   You don\u0026rsquo;t need to touch dist-git at all when getting your new upstream release into Fedora, you can stay in your upstream repository and just fire off a bunch of packit calls:  packit propose-update to create a pull request in Fedora dist-git with the selected upstream release packit build to build the new upstream release once the pull request is merged and finally, packit create-update creates a new bodhi update (if you chose a stable Fedora release)   Packit now has a srpm command which creates an SRPM out of the local content of your upstream repository. You can now use packit to sync files from your dist-git repo back into upstream (mainly to keep spec files in sync). sync-from-downstream is the command. Command propose-update received numerous improvements:  You can pick upstream version to use. Packit will NOT check out the git ref with the upstream release if you specify --local-content It\u0026rsquo;s possible to force packit to execute fedpkg new-sources using --force-new-sources and bypass the caching mechanism.    Installation #  Please make sure you are installing 0.2.0:\n$ dnf install --enablerepo=updates-testing packit Or\n$ pip3 install --user packitos You can also install packit from master branch, if you are brave enough:\n$ pip3 install --user git+https://github.com/packit-service/packit How are we using packit? #  I\u0026rsquo;d like to show you how we used packit to bring a new upstream release of ogr into Fedora, a library which packit is using.\nOnce we have performed an upstream release of ogr, we can propose an update in dist-git:\n$ git clone https://github.com/packit-service/ogr \u0026amp;\u0026amp; cd ogr/ $ packit propose-update INFO: Running \u0026#39;anitya\u0026#39; versioneer Version in upstream registries is \u0026#39;0.0.3\u0026#39;. Version in spec file is \u0026#39;0.0.3\u0026#39;. Picking version of the latest release from the upstream registry over spec file. Checking out upstream version 0.0.3 Using \u0026#39;master\u0026#39; dist-git branch Cloning repo: https://src.fedoraproject.org/rpms/python-ogr.git -\u0026gt; /tmp/tmpb9xlvdhj Syncing /home/tt/g/user-cont/ogr/python-ogr.spec Archive ogr-0.0.3.tar.gz found in lookaside cache (skipping upload). ERROR Cmd(\u0026#39;git\u0026#39;) failed due to: exit code(1) cmdline: git commit -s -m [packit] 0.0.3 upstream release -m Upstream tag: 0.0.3 Upstream commit: 059d21080a7849acff4626b6e0ec61830d537ac4 stdout: \u0026#39;On branch 0.0.3-master-update nothing to commit, working tree clean\u0026#39; Whoops, it seems that I have messed up, I forgot to bump the spec file in the upstream repo when doing the release. I will bump it locally and utilize --local-content argument:\n$ rpmdev-bumpspec -n 0.1.0 -c \u0026#39;New upstream release: 0.1.0\u0026#39; *.spec $ packit propose-update --local-content INFO: Running \u0026#39;anitya\u0026#39; versioneer Version in upstream registries is \u0026#39;0.0.3\u0026#39;. Version in spec file is \u0026#39;0.1.0\u0026#39;. Picking version of the latest release from the upstream registry over spec file. Using \u0026#39;master\u0026#39; dist-git branch Cloning repo: https://src.fedoraproject.org/rpms/python-ogr.git -\u0026gt; /tmp/tmpd9j4se27 Syncing /home/tt/g/user-cont/ogr/python-ogr.spec Archive ogr-0.1.0.tar.gz found in lookaside cache (skipping upload). INFO: Downloading file from URL https://files.pythonhosted.org/packages/source/o/ogr/ogr-0.1.0.tar.gz 100%[=============================\u0026gt;] 20.25K eta 00:00:00 Downloaded archive: \u0026#39;/tmp/tmpd9j4se27/ogr-0.1.0.tar.gz\u0026#39; About to upload to lookaside cache won\u0026#39;t be doing kinit, no credentials provided PR created: https://src.fedoraproject.org/rpms/python-ogr/pull-request/6 Once the scratch build is done and tests passed we merged and built it:\n$ packit build Using \u0026#39;master\u0026#39; dist-git branch Cloning repo: https://src.fedoraproject.org/rpms/python-ogr.git -\u0026gt; /tmp/tmprp3cmdjy Building python-ogr-0.1.0-1.fc31 for rawhide Created task: 33616980 Task info: https://koji.fedoraproject.org/koji/taskinfo?taskID=33616980 We have done the same for F30 and F29.\nThe previous commands were run in the directory of the upstream repository. Packit also accepts path to your upstream clone, or even URL. So let\u0026rsquo;s create a bodhi update for python-ogr by specifying the upstream repo URL:\n$ cd $HOME $ packit create-update --dist-git-branch f29 https://github.com/packit-service/ogr Cloning repo: https://github.com/packit-service/ogr -\u0026gt; /tmp/tmpdkdadmn_ Koji builds for package python-ogr and koji tag f29-updates-candidate: - python-ogr-0.1.0-1.fc29 Cloning repo: https://src.fedoraproject.org/rpms/python-ogr.git -\u0026gt; /tmp/tmpn1809ec9 Bodhi update FEDORA-2019-78948e62d2: - https://bodhi.fedoraproject.org/updates/FEDORA-2019-78948e62d2 - stable_karma: 3 - unstable_karma: -3 - notes: New upstream release: 0.1.0 And that\u0026rsquo;s it, no need to access dist-git any more.\nPlease give packit a try and let us know what you think.\nPackit 0.3.0 (2019-04-11) #  In the previous post we promised to provide a new release every 2 weeks and we are already breaking this promise as it\u0026rsquo;s been 3 weeks since then. We decided to wait with the release to merge several pull requests related to source-git support.\nNow the good news. You can find a complete list of new features and improvements of version 0.3.0 in the changelog.\nFeatures #   You can now specify your own hooks or actions to replace default packit behaviour. (More information can be found in the documentation). Packit supports pagure.io-based upstream projects. Commands propose-update and sync-from-downstream supports copying directories. A new command status! It displays useful upstream/downstream info. Packit now supports Source-git. The functionality is not available, yet - we will add a CLI interface for it in the next release. You can now have a config file for packit in your home directory(~/.config/packit.yaml). Packit installed from an RPM now has manpages.  packit status example #  $ packit status Cloning repo: https://src.fedoraproject.org/rpms/packit.git -\u0026gt; /tmp/tmp84we_6n8 Downstream PRs: No open PRs. f29: 0.2.0 f30: 0.2.0 master: 0.2.0 Packit 0.4.0 \u0026amp; 0.4.1 (2019-05-18) #  It\u0026rsquo;s been over a month since we released packit \u0026ldquo;0.3.0\u0026rdquo;. Here comes packit 0.4.0 (and patch release 0.4.1) and as always they bring a lot of new features and improvements.\nYou can find a complete list in the changelog.\nPackit as a service #   We have Packit as a service running in OpenShift and also a GitHub App, which uses it. Unfortunately it\u0026rsquo;s still not in the Marketplace, so we have been the only one using it so far. The service/app submits builds in copr and once they\u0026rsquo;re done it adds a GitHub status and comment with instructions how to install the builds. The service is now configurable via jobs defined in configuration file. Packit is now able to check GPG signatures of the upstream commits against configured fingerprints.  CLI #   srpm command now works also with Source-git. status command now access remote APIs asynchronously in parallel, which should speed up the execution. CLI has new --dry-run option to not perform any remote changes (pull requests or comments). Fedmsg parsing has been unified into a single listen-to-fedmsg command.  Packit 0.4.2 (2019-06-26) #  Another relase after a month since 0.4.1, this time mostly with bug fixes.\nWe\u0026rsquo;ve been busy polishing our GitHub App recently, therefore we had no resources for new features.\nSee CHANGELOG for more details.\nSeptember 2020 #  Week 36 (August 31th - September 4th) #   We store the submission time of SRPM builds now (packit-service#795 by Anchit). Shreyas improved implementation of the build status reporting (packit-service#740). Anchit enhanced the /koji-builds endpoint to be more consistent with /copr-builds endpoint (packit-service#791).  Week 37 (September 7th - September 11th) #   Stage now uses Tokman to get access tokens for GitHub, which should resolve race condition when running parallel jobs (Tokman by Hunor, ogr integration by Matej). Franta has addressed problems with Testing-Farm cluster with custom response on PRs that links to more information (pinned info, packit-service#798).  Week 38 (September 14th - September 18th) #   The combination of the source-git patches with existing patches now works well (packit#963). Service now mostly supports also GitLab as you can see here or here. A lot of small issues were fixed in the last week (packit-service#806, packit-service#812, packit-service#814, packit-service#815, packit-service#816 ). Created Copr projects are now prefixed with the hostname for non-GitHub services and also support multipart namespaces (packit-service#819). Laura fixed two testing-farm related issues (packit-service#808, packit-service#809). You can now use test job also on Pagure and GitLab thanks to that.  Week 39 (September 21st - September 25th) #   Packit-service can be configured to work with private namespaces. This is plumbing work which we need right now for CentOS Stream. We are not planning to enable this for GitHub - packit-service will still work only for public repositories, private ones are ignored. packit-service#831 If git tag contains more information than just version (e.g. pkg_name-v1.2.3), it is possible to use upstream_tag_template to extract version from the tag, which will be used in a subsequent task. doc packit#959 Added support for globbing pattern in upstream_ref. doc packit#960 Packit --remote is global option now and available for all commands. Because of this sync-from-downstream --remote was renamed to --remote-to-push. Remote can now be specified in the user\u0026rsquo;s config (via upstream_git_remote parameter). packit#977  Following bugs were fixed:\n Packit dropping leading zeros in version. packit#814 Packit CLI issue caused by picking incorrect copr project name. packit#971  Week 40 (September 28th - October 2nd) #   Packit-service is now explicitly checking if requested copr-build targets exist and if not, the user is informed about it. packit-service#835 We have improved the way how packit updates %setup line in a spec file - you are now able to set content of -n option via archive_root_dir_template config option, it defaults to {upstream-pkg-name}. doc packit#834 Packit is able to generate a patch file with format-patch without leading a/ and b/ in the patch diff. Required for patches in dist-git which are applied with -p0. Contribution guidelines were updated, now we have one shared link.  Week 44-48 (November) 2019 #  With this blog post we\u0026rsquo;d like to continue with the idea of openly communicating changes in Packit. Since most of the developers use Packit as the GitHub App (which uses code from this repository - Packit Service), this blog will be about changes in all the parts, i.e. the GitHub App, the Packit Service and Packit itself.\nContinuous Deployment (CD) #  At the moment the workflow is that one of us manually triggers production container image build at the end of a week. This image is then automatically deployed into our production instance of the service over a weekend (Sun/Mon night) so that everyone can start a week with all the amazing stuff we added the previous week. In case an issue makes it through our staging instance into production uncaught, we can easily rollback on Monday. The same person also writes down what\u0026rsquo;s changed in Packit (service/app) since previous deployment.\nChanges in production (since the end of November) #  Previous post is almost half a year old so we won\u0026rsquo;t list all the changes since then, but only since last deployment, i.e. since end of December.\nPackit #  Previous deployment was running packit-0.7.1. We haven\u0026rsquo;t released a newer version since then, but in the service we install Packit from the Git repository (we have a separate stable git branch for our production deployment). From the most visible changes, Packit now:\n better handles Create-archive action is able to work in a repo with detached head logs output from subprocesses in realtime syncs config file and spec file by default in Propose-update action hadles patches with undecodable chars  Packit Service #  Now:\n better reports Copr builds  uses separate commit status for srpm build and every chroot clears test farm commit statuses when new build is triggered better handles failed Copr builds   gracefully handles no config file in the repo better handles when no (copr build) targets are specified in config file better checks whitelist of users does not create duplicate tickets in our notification repo when a new user install the app  Changes not visible to end users:\n using Requre for integration/E2E tests Fedora messaging consumer part of the service has been improved and moved to separate repo/image using FAS instead of Fedora Badges for checking whether a user is Fedora packager many improved logs many bugs squashed lot\u0026rsquo;s of code refactored  December 2019 #  Week 49 #  ogr \u0026amp; packit #   ogr-0.9.0 has been released greatly restructured. (#291) packit status (CLI) now shows also latest Copr builds. (#579) Target aliases (currently fedora-development, fedora-stable, fedora-all) can now be used in the packit config file. (#619) When doing a new update in Fedora dist-git, packit now by default creates a new pull request instead of pushing directly to dist-git. (#622)  packit service #   Does not set test checks when tests are not configured. (#275) Supports target aliases and dist-git branches aliases. (#277, #285) Nicely formats errors from OpenShift API. (#283) Runs Copr build when user adds a /packit build comment into a PR. (#290)  Week 50 #  packit #   If there is no upstream_package_name/downstream_package_name given in .packit.yaml, they now default to the name of the GitHub repo. (#624) If no jobs are defined in .packit.yaml packit by default runs build job on fedora-stable targets and propose_downstream on fedora-all branches. (#625) build command has nicer output. (#630) Smaller fixes. (#630, #636)  packit service #   Creates a new issue when propose-update fails. (#300) Better reports failed submitting of a Copr build. (#301)  "}),e.add({id:58,href:"/posts/copr-srpms/",title:"Building SRPMs in Copr",section:"Blog Posts",content:"Introduction #  If you use Packit to build RPMs for your upstream code changes, likely, you have already read about how does Packit build your SRPMs. If not, then just a short recap: Each time an RPM build is triggered, Packit builds an SRPM and then submits the created SRPM file to Copr where Copr takes care of building the actual RPMs. Since you can modify the behaviour of building SRPMs by defining actions, this process needs to be run in an isolated environment. For this, we implemented our sandboxing mechanism, which simply runs the provided commands in an Openshift pod freshly created for each build.\nProblems of the previous workflow for SRPM builds #  This is a pretty good-functioning workflow, but it has some downsides which have become more and more annoying with the growing user base. Because of the resources, we have set limits for Openshift pods running at one time. This directly affects how many SRPM builds can run in parallel. As a result, when there are too many requests for (S)RPM builds, some can get stuck in the queue while waiting for other builds to finish. Another inconvenience coming with pods being always freshly created is copying the needed data into and from the pod. This has also cost us some months of desperate debugging of weird errors. Another disadvantage is that users cannot easily configure dependencies for their actions run during building SRPMs. We have to install the dependencies manually on-demand, but of course, which is not flexible.\nWe were thinking about improving the process for a long time but never reached any clear conclusion. Then in one of our architecture meetings, when we tried to solve another issue related to our sandboxing solution, Pavel Raiskup from Copr team asked us why didn\u0026rsquo;t we build the SRPMs directly in Copr. We knew that there is a way of building SRPMs in Copr, but weren\u0026rsquo;t aware of the details and how would this fit our use case.\nImplementation of the Copr SRPMs #  After some research of the Copr custom source method, we decided to give it a try. To make Copr build the SRPMs, Copr needs to be provided with a script that will prepare the sources used to build an SRPM. Therefore, we created the packit prepare-sources command, which mostly reuses existing code that is run also in the sandbox workflow. It prepares the specfile, archive and other sources and then moves them to a separate directory. So with the new implementation, with each request to run (S)RPM build, Packit sends a dynamically created \u0026ldquo;script\u0026rdquo; to Copr that invokes our new command. Here is what the script can look like:\n#!/bin/sh git config --global user.email \u0026quot;hello@packit.dev\u0026quot; git config --global user.name \u0026quot;Packit\u0026quot; resultdir=$PWD packit -d prepare-sources --result-dir \u0026quot;$resultdir\u0026quot; --pr-id 676 --job-config-index 2 https://github.com/packit/ogr  You can see that a pull request should be checked out or which job defined in your Packit job config is the trigger of this action. And that\u0026rsquo;s it! Copr finds the sources and builds SRPM from them. Packit listens to the messages about the start and end of the build and similarily as for RPM builds, reports the state via commit statuses/checks and provides the URL with the logs.\nDeployment phases #  Since this change is pretty significant, we wanted to start using this workflow gradually and catch all the problems before we get rid of the previous workflow for SRPMs. At first, we tested how does the new solution work in our projects. The only disadvantage was that the actual build process takes a little longer than in sandcastle as we get an isolated environment where all the packages are installed for each new build. On the other hand, Copr usually starts the build very soon after it is submitted, so no long wait time until some other build is finished. In the initial implementation, we installed a list of dependencies which are present in our sandbox which also increased the build time a bit.\nSo as the following step we added the functionality to define dependencies for actions in the Packit config file with srpm_build_deps key.\nExample of how the configuration of srpm_build_deps can look like:\nactions:  create-archive:  - \u0026#34;python3 setup.py sdist --dist-dir .\u0026#34;  - \u0026#34;sh -c \u0026#39;echo packitos-$(python3 setup.py --version).tar.gz\u0026#39;\u0026#34;  get-current-version:  - \u0026#34;python3 setup.py --version\u0026#34;  srpm_build_deps:  - python3-pip  - python3-setuptools_scm We also decided that presence of this key in the config will be for some period an indicator to build the SRPMs in Copr. With this approach, anyone can configure their dependencies and play with adding and adjusting them as needed without directly breaking the builds in their repository. When the builds in the PR pass, the configuration change can be merged and the new approach will be used for the whole repository. We wanted to kick off this process and therefore started opening PRs with dependencies configuration for projects that use the RPM builds functionality the most. During this phase, you can reach out to us with your feedback, so we can improve it even more!\nAs a next step, we use the new approach for GitHub app installations made since September 6, 2022.\nAnd as of January 10th 2023, we switched to building all SRPMs in Copr and thus got rid of using our sandbox for building SRPMs entirely.\nSince we don\u0026rsquo;t want to break your CI results because of missing dependencies, we will use the previously linked list of deps. As the list is pretty long, we encourage you to define your dependencies on your own. If you bump into any troubles with setting up SRPM builds in Copr, please, reach out to us, we will be glad to help!\n"}),e.add({id:59,href:"/posts/2021-features/",title:"2021 for Packit",section:"Blog Posts",content:"Packit project in 2021 #  The previous year 2021 wasn\u0026rsquo;t interesting only because of the increased usage of Packit (you can see more in the previous post). The whole Packit team made a lot of improvements during the year. Some small, some really big. So, let\u0026rsquo;s take a look at the most important ones:\nDashboard #  The idea of having a dashboard for Packit service started as a Google Summer of Code 2020 project to provide a basic view of our service. Thanks Anchit for starting this! Nowadays, it\u0026rsquo;s a core part of the project and it has replaced the result pages in plain HTML. Do you remember them?\nThe dashboard can be found at dashboard.packit.dev.\nFollowing picture shows a more convenient and visually-appealing view of builds and test runs. For better context, the relevant pages are a connected to each other.\nIf you want to see the overall picture, use our pipelines view that was created exactly for that:\nFuture of the dashboard #  We consider our dashboard an important part of our service and are working on or planning more improvements:\n We are working on personalised pages for a user or git-forge namespace. We are planning to show info about other job types we support by the service as well; especially the propose-downstream one. We are doing some database schema updates to be able to better interconnect various pages. Do you have an idea for an improvement? Let us know by creating an issue here.  Development #  From the very start, Packit is developed publicly in an open-source way. We participate in various projects like Google Summer of Code, Red Hat Open Source Contest and Hacktoberfest. But we are also very glad if anyone from our users contributes and fixes some pain point. To help with that, we\u0026rsquo;ve renamed all our branches to main and rapidly enhanced our contribution guide(s). We would like to encourage you not to be afraid of contributing to any of our projects. We are prepared to help you with that.\nIf you want to keep an eye on what we are currently working on, check our Packit upstream work board on GitHub.\nTesting Farm #  The year 2021 was a tough one for our test workflow. For those who don\u0026rsquo;t know, we use Testing Farm as our test runner. At the beginning of the year, we switched to the new Testing Farm API version (because the old one had died with the infrastructure it had been running on). Unlike the old version, the new one fully supports tmt as a test definition.\nDuring the year, a set of supported environments was enhanced by centos-6, oraclelinux and aarch64. For Red Hat teams, we added support for using the internal instance of the Testing Farm. Let us know if you are interested in this. But no worries, you can use centos-stream and other publicly available environments.\nOriginally, the tests were run after the installation of the packages built using Copr from the source repository. Newly, you can skip this step and run the tests without any build. This allows you to use Packit\u0026amp;TestingFarm for repositories containing only test definitions (e.g. QE teams).\nLastly, we send some environment variables to the test environment and you can define your own if you want.\nAs we see, testing is a key feature for some teams and we still want to improve test use-cases \u0026ndash; let us know if you are missing anything (here or in the Testing Farm issue tracker).\nService #  To get users quickly know that we accepted the task and started working on it, we added two nice features \u0026ndash; :1 reaction for the comment that we are reacting on and task accepted commit status.\nSpeaking of statuses, we switched to a more feature-rich API called GitHub Check Runs. It allows us to create a separate result page where we can show more information \u0026ndash; e.g. more links when needed and more space for hints when there is a problem. You can also find the run results on a separate Checks tab of the pull-requests page. The check run page contains only the basic info and we don\u0026rsquo;t want to replace a dashboard with this. (Because of the consistency between git-forges and to be able to link the related dashboard pages.) Another feature of check runs you might find useful is being able to re-run the failed test with just one click (see the Re-run button in the following screenshot).\nInspired by other systems (like Zuul), for pull-requests we started using merge state so you can be sure the state we use is the same as the one with the pull-request being merged. We are working with the Testing Farm team to add the support there as well so the test definition is consistent with the build. But no worries, you can disable this if you don\u0026rsquo;t want this behaviour.\nDownstream #  One of our current initiatives is to help maintainers in the downstream part of the workflow as well. We had the first part of that for some time in a form of propose-downstream job (you can expect more enhancements on this front), but we newly support triggering Koji builds for new commits in dist-git.\nWhen there is a new dist-git commit that contains Packit config with the defined koji_build job, Packit will trigger the Koji build for you. It\u0026rsquo;s fresh and basic so far so give us some time to announce this with more details. The next step will be to create a Bodhi update when the build successfully finishes and that is what is currently being worked on.\nStatus Page #  Yes, we have a status page where you can check if everything is ok with our service. It can be found at status.packit.dev On the page, you can find a list of incidents we resolved or are trying to fix. If you don\u0026rsquo;t see any incident and still think the service isn\u0026rsquo;t working as expected, please, let us know (see contacts). Another useful source of information is the pipelines view on our dashboard.\nFuture #  As you see, we managed to accomplish a lot last year. And what you can expect this year? Let us know if you have some ideas and want to influence that!\n"}),e.add({id:60,href:"/posts/2021-in-numbers/",title:"2021 in Numbers",section:"Blog Posts",content:"2021 for Packit in numbers #  Let\u0026rsquo;s take a look on the year 2021 through some numbers. We would like to show you some interesting statistics and charts that can describe the work of Packit during the year 2021. If you are more interested in new features, let\u0026rsquo;s take a look on our second post.\nGitHub Application #  As of now, we have 169 installations of our GitHub application and 41 of them is from the year 2021. Looking at the monthly numbers below, it looks like we are getting back to shape.\nBuilds #  Compared to the year 2020 when we made 28 430 Copr builds for our users, we made 4.6 times more in the year 2021: 133 222 Copr builds. For those who remember the start of our project, we had a goal of 5 thousand for the FLOCK 2019. We are now two digits ahead! And if you are wondering how active is our user on Copr, we\u0026rsquo;ve created 2/3 of all the new Copr projects during the year.\nTo made this happen, we\u0026rsquo;ve created 36 133 source RPM files in the year 2021.\nTest runs #  Sadly, we started saving the submit time of the test runs in June so we have numbers only for the second half of the year. The numbers are not so high as for the builds but still 18 498 test runs.\nTop 20 projects in the number of PR Copr Builds #  Top 20 projects in the number of PR test runs #  "}),e.add({id:61,href:"/posts/fedora-eln/",title:"Working on the next major RHEL release, in your upstream repo",section:"Blog Posts",content:"Fedora EL Niño (ELN) is such an awesome idea. It enables building rawhide packages in two distinct buildroots:\n the standard Fedora Rawhide buildroot and a second one, which mimics Red Hat Enterprise Linux  This way you can make sure that your new upstream release builds fine in the next RHEL.\nBut this feedback might be a little bit too late: the upstream release already happened and the code was imported in Fedora dist-git, so fixing an issue will require repeating the whole process. Wouldn\u0026rsquo;t it be better to know if the upstream change builds fine in ELN while working on the code?\nOh, wait!\nYou can do this easily with Packit #  If your GitHub project is not using Packit yet, here\u0026rsquo;s a guide how to start.\nOnce it\u0026rsquo;s set up, you need to make sure that your pull requests are also being built in the fedora-eln target:\njobs: - job: copr_build trigger: pull_request metadata: targets: - fedora-development - fedora-eln With this config, changes from every pull request will be built in all development versions of Fedora (at the time of writing this, it\u0026rsquo;s Rawhide and Fedora 33) and in Fedora ELN.\nEasy, right?\nPackit can also trigger builds when you push to a branch. If you want to have up to date builds of your main branch for ELN and development versions of Fedora, here\u0026rsquo;s how to set it up:\njobs: - job: copr_build trigger: commit metadata: targets: - fedora-development - fedora-eln branch: main A real-life example #  If you got here and you\u0026rsquo;re still not sure why you\u0026rsquo;d need this, I can give you a real-life example.\nRecently, Jirka Konecny from the RHEL Installer team reached out to us that they would love to use Packit as a CI system. He set it up and now all the anaconda PRs are being built and tested on Fedora Rawhide x86_64.\nJirka continued and added Fedora ELN as an additional target. The build failed because one of build requirements was not available in ELN:\nFedora ELN - Developmental modular packages for the next Enterprise Linux release 2.7 kB/s | 2.3 kB 00:0 No matching package to install: \u0026#39;metacity\u0026#39; Not all dependencies satisfied Error: Some packages could not be found. Since the team discovered this during their upstream development process, they can react to the issue right away. It would have been pretty late if they found this while the next major RHEL is reaching alpha - at this moment they should have enough time to fix the problem and make sure anaconda builds fine in ELN.\nSo, are you convinced? Let us know if you need help setting up Packit in your upstream repositories :)\n"})})()